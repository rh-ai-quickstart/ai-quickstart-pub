[DEPRECATION WARNING]: ANSIBLE_COLLECTIONS_PATHS option. Reason: does not fit 
var naming standard, use the singular form ANSIBLE_COLLECTIONS_PATH instead 
Alternatives: none. This feature will be removed in version 2.19. Deprecation 
warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.

PLAY [Step 0000 Install Galaxy roles and collections] **************************

TASK [Set output_dir if not defined] *******************************************
Monday 04 August 2025  12:56:43 +0000 (0:00:00.009)       0:00:00.009 ********* 
skipping: [localhost]

TASK [Create output_dir if it does not exists] *********************************
Monday 04 August 2025  12:56:43 +0000 (0:00:00.015)       0:00:00.025 ********* 
changed: [localhost]

TASK [Use requirements_content] ************************************************
Monday 04 August 2025  12:56:44 +0000 (0:00:00.284)       0:00:00.310 ********* 
ok: [localhost]

TASK [Copy requirements content to output_dir] *********************************
Monday 04 August 2025  12:56:44 +0000 (0:00:00.041)       0:00:00.352 ********* 
changed: [localhost]

TASK [Use requirements_path from the config] ***********************************
Monday 04 August 2025  12:56:44 +0000 (0:00:00.469)       0:00:00.822 ********* 
skipping: [localhost]

TASK [Check if requirements.yml exists] ****************************************
Monday 04 August 2025  12:56:44 +0000 (0:00:00.025)       0:00:00.847 ********* 
ok: [localhost]

TASK [Set final requirements path] *********************************************
Monday 04 August 2025  12:56:44 +0000 (0:00:00.143)       0:00:00.991 ********* 
ok: [localhost]

TASK [Install roles from requirements.yml] *************************************
Monday 04 August 2025  12:56:44 +0000 (0:00:00.032)       0:00:01.023 ********* 
changed: [localhost]

TASK [Install collections from requirements.yml (Not EE)] **********************
Monday 04 August 2025  12:56:45 +0000 (0:00:00.612)       0:00:01.636 ********* 
skipping: [localhost]

TASK [Install collections (EE)] ************************************************
Monday 04 August 2025  12:56:45 +0000 (0:00:00.036)       0:00:01.673 ********* 
included: /runner/project/ansible/install_collections_ee.yml for localhost

TASK [Get the list of installed collections (EE)] ******************************
Monday 04 August 2025  12:56:45 +0000 (0:00:00.038)       0:00:01.711 ********* 
changed: [localhost]

TASK [Create temporary file for requirements.yml (EE)] *************************
Monday 04 August 2025  12:56:46 +0000 (0:00:00.532)       0:00:02.244 ********* 
changed: [localhost]

TASK [Rewrite requirements, filter out installed collections (EE)] *************
Monday 04 August 2025  12:56:46 +0000 (0:00:00.297)       0:00:02.541 ********* 
changed: [localhost]

TASK [Ensure Cloud provider collection is added to requirements] ***************
Monday 04 August 2025  12:56:46 +0000 (0:00:00.321)       0:00:02.863 ********* 
changed: [localhost]

TASK [Read temporary collections file] *****************************************
Monday 04 August 2025  12:56:46 +0000 (0:00:00.283)       0:00:03.146 ********* 
changed: [localhost]

TASK [Debug contents of temporary collections file] ****************************
Monday 04 August 2025  12:56:47 +0000 (0:00:00.169)       0:00:03.315 ********* 
skipping: [localhost] => (item=collections:) 
skipping: [localhost] => (item=# BEGIN ANSIBLE MANAGED BLOCK - cloud provider collection) 
skipping: [localhost] => (item=# Cloud Provider Collection for aws) 
skipping: [localhost] => (item=- name: https://github.com/agnosticd/cloud_provider_aws.git) 
skipping: [localhost] => (item=  type: git) 
skipping: [localhost] => (item=  version: main) 
skipping: [localhost] => (item=# END ANSIBLE MANAGED BLOCK - cloud provider collection) 
skipping: [localhost] => (item=- {name: 'https://github.com/agnosticd/core_workloads.git', type: git, version: main}) 
skipping: [localhost] => (item=- {name: 'https://github.com/agnosticd/ai_workloads.git', type: git, version: main}) 
skipping: [localhost]

TASK [Get COLLECTIONS_PATHS] ***************************************************
Monday 04 August 2025  12:56:47 +0000 (0:00:00.053)       0:00:03.369 ********* 
ok: [localhost]

TASK [Debug COLLECTIONS_PATHS] *************************************************
Monday 04 August 2025  12:56:47 +0000 (0:00:00.018)       0:00:03.387 ********* 
skipping: [localhost]

TASK [Install collections from requirements.yml (EE)] **************************
Monday 04 August 2025  12:56:47 +0000 (0:00:00.012)       0:00:03.400 ********* 
changed: [localhost]

TASK [Cleanup tempfile (EE)] ***************************************************
Monday 04 August 2025  12:56:48 +0000 (0:00:01.290)       0:00:04.690 ********* 
changed: [localhost]

TASK [Install dynamic sources] *************************************************
Monday 04 August 2025  12:56:48 +0000 (0:00:00.166)       0:00:04.857 ********* 
included: agnosticd_dynamic for localhost

TASK [agnosticd_dynamic : Create dynamic-cache and dynamic-roles directories] ***
Monday 04 August 2025  12:56:48 +0000 (0:00:00.021)       0:00:04.878 ********* 
changed: [localhost] => (item=/runner/project/ansible/dynamic-cache)
changed: [localhost] => (item=/runner/project/ansible/dynamic-roles)

TASK [agnosticd_dynamic : Install ansible-galaxy sources to dynamic roles dir] ***
Monday 04 August 2025  12:56:48 +0000 (0:00:00.326)       0:00:05.205 ********* 
skipping: [localhost]

TASK [agnosticd_dynamic : Install ansible-galaxy sources to cache] *************
Monday 04 August 2025  12:56:48 +0000 (0:00:00.029)       0:00:05.235 ********* 
skipping: [localhost]

TASK [agnosticd_dynamic : Install git sources] *********************************
Monday 04 August 2025  12:56:49 +0000 (0:00:00.026)       0:00:05.261 ********* 
skipping: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=17   changed=11   unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   

TASKS RECAP ********************************************************************
Monday 04 August 2025  12:56:49 +0000 (0:00:00.011)       0:00:05.272 ********* 
=============================================================================== 
Install collections from requirements.yml (EE) -------------------------- 1.29s
Install roles from requirements.yml ------------------------------------- 0.61s
Get the list of installed collections (EE) ------------------------------ 0.53s
Copy requirements content to output_dir --------------------------------- 0.47s
agnosticd_dynamic : Create dynamic-cache and dynamic-roles directories --- 0.33s
Rewrite requirements, filter out installed collections (EE) ------------- 0.32s
Create temporary file for requirements.yml (EE) ------------------------- 0.30s
Create output_dir if it does not exists --------------------------------- 0.28s
Ensure Cloud provider collection is added to requirements --------------- 0.28s
Read temporary collections file ----------------------------------------- 0.17s
Cleanup tempfile (EE) --------------------------------------------------- 0.17s
Check if requirements.yml exists ---------------------------------------- 0.14s
Debug contents of temporary collections file ---------------------------- 0.05s
Use requirements_content ------------------------------------------------ 0.04s
Install collections (EE) ------------------------------------------------ 0.04s
Install collections from requirements.yml (Not EE) ---------------------- 0.04s
Set final requirements path --------------------------------------------- 0.03s
agnosticd_dynamic : Install ansible-galaxy sources to dynamic roles dir --- 0.03s
agnosticd_dynamic : Install ansible-galaxy sources to cache ------------- 0.03s
Use requirements_path from the config ----------------------------------- 0.03s
[DEPRECATION WARNING]: ANSIBLE_COLLECTIONS_PATHS option. Reason: does not fit 
var naming standard, use the singular form ANSIBLE_COLLECTIONS_PATH instead 
Alternatives: none. This feature will be removed in version 2.19. Deprecation 
warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
Vault password (gpte_vault_0): 

PLAY [Step 0000 Set Action] ****************************************************

TASK [Set ACTION to provision when undefined] **********************************
Monday 04 August 2025  12:56:49 +0000 (0:00:00.007)       0:00:00.007 ********* 
skipping: [localhost]

PLAY [Step 0000 Setup runtime] *************************************************

TASK [Ensure cloud provider is supported] **************************************
Monday 04 August 2025  12:56:49 +0000 (0:00:00.017)       0:00:00.025 ********* 
ok: [localhost]

PLAY [Step 0000 Setup Output Directory] ****************************************

TASK [Set output_dir if not defined] *******************************************
Monday 04 August 2025  12:56:49 +0000 (0:00:00.015)       0:00:00.040 ********* 
skipping: [localhost]

TASK [Create output_dir if it does not exists] *********************************
Monday 04 August 2025  12:56:49 +0000 (0:00:00.012)       0:00:00.052 ********* 
ok: [localhost]

TASK [Attempt to restore output_dir contents] **********************************
Monday 04 August 2025  12:56:50 +0000 (0:00:00.291)       0:00:00.344 ********* 
included: agnosticd_restore_output_dir for localhost

TASK [agnosticd_restore_output_dir : Get output_dir archive from s3] ***********
Monday 04 August 2025  12:56:50 +0000 (0:00:00.032)       0:00:00.376 ********* 
ok: [localhost]

TASK [agnosticd_restore_output_dir : Decrypt archive] **************************
Monday 04 August 2025  12:56:51 +0000 (0:00:01.008)       0:00:01.384 ********* 
skipping: [localhost]

TASK [agnosticd_restore_output_dir : Restore output_dir from archive] **********
Monday 04 August 2025  12:56:51 +0000 (0:00:00.032)       0:00:01.417 ********* 
skipping: [localhost]

TASK [agnosticd_restore_output_dir : Remove archive file from output_dir] ******
Monday 04 August 2025  12:56:51 +0000 (0:00:00.029)       0:00:01.446 ********* 
ok: [localhost]

TASK [agnosticd_restore_output_dir : Remove encrypted archive file from output_dir] ***
Monday 04 August 2025  12:56:51 +0000 (0:00:00.189)       0:00:01.635 ********* 
ok: [localhost]

TASK [Touch file provision-user-data.yaml and provision-user-info.yaml] ********
Monday 04 August 2025  12:56:51 +0000 (0:00:00.197)       0:00:01.833 ********* 
changed: [localhost] => (item=user-info.yaml)
changed: [localhost] => (item=user-data.yaml)

TASK [Create empty user-info.yaml and user-data.yaml in output dir] ************
Monday 04 August 2025  12:56:51 +0000 (0:00:00.350)       0:00:02.183 ********* 
changed: [localhost] => (item=user-info.yaml)
changed: [localhost] => (item=user-data.yaml)

TASK [Create symlink user-data.yaml -> provision-user-data.yaml] ***************
Monday 04 August 2025  12:56:52 +0000 (0:00:00.882)       0:00:03.066 ********* 
changed: [localhost] => (item=user-info.yaml)
changed: [localhost] => (item=user-data.yaml)

PLAY [Step 0000 Include Vars] **************************************************

TASK [Set output_dir for all hosts] ********************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.373)       0:00:03.440 ********* 
ok: [localhost]

TASK [Include variables files] *************************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.019)       0:00:03.459 ********* 
skipping: [localhost] => (item=/runner/project/ansible/cloud_providers/aws/default_vars.yaml) 
skipping: [localhost] => (item=/runner/project/ansible/cloud_providers/aws/default_vars.yml) 
skipping: [localhost] => (item=/runner/project/ansible/configs/openshift-cluster/default_vars.yaml) 
ok: [localhost] => (item=/runner/project/ansible/configs/openshift-cluster/default_vars.yml)
skipping: [localhost] => (item=/runner/project/ansible/configs/openshift-cluster/aws/default_vars.yaml) 
ok: [localhost] => (item=/runner/project/ansible/configs/openshift-cluster/aws/default_vars.yml)

TASK [Set passthrough user data] ***********************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.058)       0:00:03.518 ********* 
skipping: [localhost]

PLAY [Step 000 - Pre Infrastructure] *******************************************

TASK [Print debug message] *****************************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.020)       0:00:03.538 ********* 
ok: [localhost] => {
    "msg": "Step 000 Pre Infrastructure"
}

TASK [Ensure variables are set] ************************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.011)       0:00:03.550 ********* 
ok: [localhost]

TASK [Set availability zone for bastion, control_plane, and worker nodes] ******
Monday 04 August 2025  12:56:53 +0000 (0:00:00.048)       0:00:03.599 ********* 
skipping: [localhost]

TASK [Run add user to GCP project role] ****************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.038)       0:00:03.637 ********* 
skipping: [localhost]

TASK [Create GCP Credentials File] *********************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.013)       0:00:03.650 ********* 
skipping: [localhost]

TASK [Get Google Cloud SDK] ****************************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.012)       0:00:03.663 ********* 
skipping: [localhost]

TASK [Azure Pre Infrastructure tasks (generate Windows password if not defined)] ***
Monday 04 August 2025  12:56:53 +0000 (0:00:00.011)       0:00:03.675 ********* 
skipping: [localhost]

PLAY [Step 001.1 Deploy Infrastructure] ****************************************

TASK [Test aws command] ********************************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.014)       0:00:03.689 ********* 
ok: [localhost]

TASK [Fail if AWS command CLI if not available] ********************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.293)       0:00:03.982 ********* 
skipping: [localhost]

TASK [Run infra_images] ********************************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.010)       0:00:03.993 ********* 
included: infra_images for localhost

TASK [infra_images : Include tasks] ********************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.014)       0:00:04.008 ********* 
included: /runner/project/ansible/roles/infra_images/tasks/aws.yaml for localhost

TASK [infra_images : Loop images] **********************************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.038)       0:00:04.047 ********* 
included: /runner/project/ansible/roles/infra_images/tasks/aws_loop_images.yaml for localhost => (item={'name': 'bastion', 'count': 1, 'unique': True, 'public_dns': True, 'image': 'RHEL96GOLD-latest', 'flavor': {'ec2': 't3a.small'}, 'tags': [{'key': 'AnsibleGroup', 'value': 'bastions'}, {'key': 'Purpose', 'value': 'development'}, {'key': 'project', 'value': 'openshift-cluster-76x7m'}, {'key': 'user', 'value': 'lab-user'}], 'rootfs_size': 30, 'security_groups': ['BastionSG']})

TASK [infra_images : Include loop image file] **********************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.041)       0:00:04.089 ********* 
included: /runner/project/ansible/roles/infra_images/tasks/aws_loop_image.yaml for localhost => (item={'owner': 309956199498, 'name': 'RHEL-9.6.*_HVM_*Access*', 'architecture': 'x86_64', 'aws_filters': {'is-public': False}})

TASK [infra_images : Lookup image for bastion] *********************************
Monday 04 August 2025  12:56:53 +0000 (0:00:00.057)       0:00:04.146 ********* 
ok: [localhost]

TASK [infra_images : Fail if no image found for bastion] ***********************
Monday 04 August 2025  12:56:54 +0000 (0:00:00.987)       0:00:05.133 ********* 
skipping: [localhost]

TASK [infra_images : Save image in agnosticd_images, use latest if multiple found] ***
Monday 04 August 2025  12:56:54 +0000 (0:00:00.037)       0:00:05.171 ********* 
ok: [localhost]

TASK [infra_images : debug agnosticd_image] ************************************
Monday 04 August 2025  12:56:54 +0000 (0:00:00.045)       0:00:05.217 ********* 
skipping: [localhost]

TASK [infra_images : Print images found for each instance] *********************
Monday 04 August 2025  12:56:54 +0000 (0:00:00.025)       0:00:05.243 ********* 
ok: [localhost] => (item=bastion) => {
    "msg": "bastion - RHEL-9.6.0_HVM_GA-20250423-x86_64-0-Access2-GP3 - ami-037e488c5d0f0468f - Red Hat BYOL Linux - us-east-2"
}

TASK [Run aws_capacity_reservation] ********************************************
Monday 04 August 2025  12:56:55 +0000 (0:00:00.050)       0:00:05.293 ********* 
included: agnosticd.cloud_provider_aws.aws_capacity_reservation for localhost

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Include pre-checks] ***
Monday 04 August 2025  12:56:55 +0000 (0:00:00.020)       0:00:05.313 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/cloud_provider_aws/roles/aws_capacity_reservation/tasks/pre_checks.yml for localhost

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Ensure mandatory variables are set] ***
Monday 04 August 2025  12:56:55 +0000 (0:00:00.049)       0:00:05.363 ********* 
ok: [localhost] => (item=agnosticd_aws_capacity_reservations dictionary is empty)
ok: [localhost] => (item=agnosticd_aws_capacity_reservation_regions list is empty)

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Create reservation] ***
Monday 04 August 2025  12:56:55 +0000 (0:00:00.081)       0:00:05.444 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/cloud_provider_aws/roles/aws_capacity_reservation/tasks/create.yml for localhost

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Retrieve stack_deployed from provision-user-data.yml] ***
Monday 04 August 2025  12:56:55 +0000 (0:00:00.056)       0:00:05.501 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Retrieve the region from user-data.yml] ***
Monday 04 August 2025  12:56:55 +0000 (0:00:00.051)       0:00:05.552 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Create on-demand capacity reservations and save result] ***
Monday 04 August 2025  12:56:55 +0000 (0:00:00.105)       0:00:05.658 ********* 
Reservation created: cr-00935824d44d58698 (us-east-2b)
Reservation created: cr-0d5dce7c282508acd (us-east-2b)
Reservation created: cr-088a7f317b0e7f647 (us-east-2b)
Reservation created: cr-02e17b77234a7d90a (us-east-2b)
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Set AZ and region] ***
Monday 04 August 2025  12:56:56 +0000 (0:00:01.353)       0:00:07.012 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Ensure aws_region is not passed as extra vars and different] ***
Monday 04 August 2025  12:56:56 +0000 (0:00:00.041)       0:00:07.054 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Set default aws_availability_zone (single AZ)] ***
Monday 04 August 2025  12:56:56 +0000 (0:00:00.039)       0:00:07.093 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Save region in user-data] ***
Monday 04 August 2025  12:56:56 +0000 (0:00:00.041)       0:00:07.134 ********* 
ok: [localhost] => {
    "changed": false,
    "data": {
        "aws_region": "us-east-2"
    }
}

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Save AZ in user-data] ***
Monday 04 August 2025  12:56:56 +0000 (0:00:00.060)       0:00:07.195 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_capacity_reservation : Delete reservation] ***
Monday 04 August 2025  12:56:56 +0000 (0:00:00.041)       0:00:07.236 ********* 
skipping: [localhost]

TASK [Empty the agnosticd_images and run the detection again] ******************
Monday 04 August 2025  12:56:57 +0000 (0:00:00.037)       0:00:07.273 ********* 
skipping: [localhost]

TASK [Run infra-images again to use the proper region selected by the reservations] ***
Monday 04 August 2025  12:56:57 +0000 (0:00:00.027)       0:00:07.300 ********* 
skipping: [localhost]

TASK [Run aws_open_environment role] *******************************************
Monday 04 August 2025  12:56:57 +0000 (0:00:00.027)       0:00:07.328 ********* 
skipping: [localhost]

TASK [Create SSH provision key] ************************************************
Monday 04 August 2025  12:56:57 +0000 (0:00:00.025)       0:00:07.353 ********* 
included: infra_create_ssh_provision_key for localhost

TASK [infra_create_ssh_provision_key : Ensure key_name is not defined] *********
Monday 04 August 2025  12:56:57 +0000 (0:00:00.053)       0:00:07.406 ********* 
skipping: [localhost]

TASK [infra_create_ssh_provision_key : Generate SSH keys] **********************
Monday 04 August 2025  12:56:57 +0000 (0:00:00.019)       0:00:07.426 ********* 
changed: [localhost]

TASK [infra_create_ssh_provision_key : Slurp public key] ***********************
Monday 04 August 2025  12:56:57 +0000 (0:00:00.395)       0:00:07.821 ********* 
ok: [localhost]

TASK [infra_create_ssh_provision_key : Save all facts for SSH] *****************
Monday 04 August 2025  12:56:57 +0000 (0:00:00.290)       0:00:08.112 ********* 
ok: [localhost]

TASK [infra_create_ssh_provision_key : Report user info for SSH provision key as user data] ***
Monday 04 August 2025  12:56:57 +0000 (0:00:00.041)       0:00:08.153 ********* 
skipping: [localhost]

TASK [Include save output dir role] ********************************************
Monday 04 August 2025  12:56:57 +0000 (0:00:00.029)       0:00:08.182 ********* 
included: agnosticd_save_output_dir for localhost

TASK [agnosticd_save_output_dir : Create output_dir archive] *******************
Monday 04 August 2025  12:56:57 +0000 (0:00:00.025)       0:00:08.208 ********* 
included: /runner/project/ansible/roles/agnosticd_save_output_dir/tasks/create_output_dir_archive.yml for localhost

TASK [agnosticd_save_output_dir : Create tempfile for archive] *****************
Monday 04 August 2025  12:56:57 +0000 (0:00:00.024)       0:00:08.233 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Set agnosticd_save_output_dir_archive_tempfile] ***
Monday 04 August 2025  12:56:58 +0000 (0:00:00.286)       0:00:08.519 ********* 
ok: [localhost]

TASK [agnosticd_save_output_dir : Create output_dir archive] *******************
Monday 04 August 2025  12:56:58 +0000 (0:00:00.020)       0:00:08.540 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Encrypt tarball using password] **************
Monday 04 August 2025  12:56:58 +0000 (0:00:00.203)       0:00:08.743 ********* 
skipping: [localhost]

TASK [agnosticd_save_output_dir : Upload output_dir archive to S3] *************
Monday 04 August 2025  12:56:58 +0000 (0:00:00.017)       0:00:08.760 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Remove output_dir archive tempfile] **********
Monday 04 August 2025  12:56:59 +0000 (0:00:00.923)       0:00:09.684 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Remove output_dir encrypted archive tempfile] ***
Monday 04 August 2025  12:56:59 +0000 (0:00:00.167)       0:00:09.852 ********* 
skipping: [localhost]

TASK [Locate environment SSH key] **********************************************
Monday 04 August 2025  12:56:59 +0000 (0:00:00.019)       0:00:09.871 ********* 
included: locate_env_authorized_key for localhost

TASK [locate_env_authorized_key : Set env_authorized_key_path] *****************
Monday 04 August 2025  12:56:59 +0000 (0:00:00.117)       0:00:09.988 ********* 
ok: [localhost]

TASK [locate_env_authorized_key : Set env_authorized_key_path_pub] *************
Monday 04 August 2025  12:56:59 +0000 (0:00:00.078)       0:00:10.067 ********* 
ok: [localhost]

TASK [locate_env_authorized_key : Generate SSH pub key content if it doesn't exist] ***
Monday 04 August 2025  12:56:59 +0000 (0:00:00.076)       0:00:10.144 ********* 
ok: [localhost]

TASK [locate_env_authorized_key : Save SSH pub key content as fact] ************
Monday 04 August 2025  12:57:00 +0000 (0:00:00.267)       0:00:10.411 ********* 
ok: [localhost]

TASK [Create keypair in AWS] ***************************************************
Monday 04 August 2025  12:57:00 +0000 (0:00:00.024)       0:00:10.436 ********* 
included: agnosticd.cloud_provider_aws.aws_ssh_key for localhost

TASK [agnosticd.cloud_provider_aws.aws_ssh_key : Include create tasks] *********
Monday 04 August 2025  12:57:00 +0000 (0:00:00.043)       0:00:10.479 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/cloud_provider_aws/roles/aws_ssh_key/tasks/create.yml for localhost

TASK [agnosticd.cloud_provider_aws.aws_ssh_key : Stat local infra key] *********
Monday 04 August 2025  12:57:00 +0000 (0:00:00.018)       0:00:10.498 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_ssh_key : Generate SSH pub key content] ***
Monday 04 August 2025  12:57:00 +0000 (0:00:00.162)       0:00:10.661 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_ssh_key : Debug pub key] ****************
Monday 04 August 2025  12:57:00 +0000 (0:00:00.022)       0:00:10.683 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_ssh_key : Slurp public key] *************
Monday 04 August 2025  12:57:00 +0000 (0:00:00.019)       0:00:10.702 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_ssh_key : Save all facts for SSH] *******
Monday 04 August 2025  12:57:00 +0000 (0:00:00.017)       0:00:10.720 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_ssh_key : Create infra key] *************
Monday 04 August 2025  12:57:00 +0000 (0:00:00.016)       0:00:10.736 ********* 
changed: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_ssh_key : Include destroy tasks] ********
Monday 04 August 2025  12:57:01 +0000 (0:00:00.784)       0:00:11.520 ********* 
skipping: [localhost]

TASK [Run aws_template_generate role] ******************************************
Monday 04 August 2025  12:57:01 +0000 (0:00:00.012)       0:00:11.533 ********* 
included: agnosticd.cloud_provider_aws.aws_template_generate for localhost

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Detect all possible Availability Zones that can host all the instance types and pick one] ***
Monday 04 August 2025  12:57:01 +0000 (0:00:00.034)       0:00:11.568 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/cloud_provider_aws/roles/aws_template_generate/tasks/locate_availability_zones.yml for localhost

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Get all the instance types] ***
Monday 04 August 2025  12:57:01 +0000 (0:00:00.040)       0:00:11.608 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Get the ec2 value] ***
Monday 04 August 2025  12:57:01 +0000 (0:00:00.097)       0:00:11.706 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Check if the AWS CLI has the 'describe-instance-type-offerings' feature] ***
Monday 04 August 2025  12:57:01 +0000 (0:00:00.058)       0:00:11.764 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Get all subnets or networks in 'instances'] ***
Monday 04 August 2025  12:57:02 +0000 (0:00:00.996)       0:00:12.761 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Locate Availability Zones] ***
Monday 04 August 2025  12:57:02 +0000 (0:00:00.050)       0:00:12.811 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/cloud_provider_aws/roles/aws_template_generate/tasks/locate_availability_zones_tasks.yml for localhost

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Get the possible AZs] ***
Monday 04 August 2025  12:57:02 +0000 (0:00:00.038)       0:00:12.850 ********* 
ok: [localhost] => (item=t3a.small)

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Debug possible availability zones] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.859)       0:00:13.710 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Fail if return code is not 0] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.013)       0:00:13.723 ********* 
skipping: [localhost] => (item=['aws', 'ec2', 'describe-instance-type-offerings', '--location-type', 'availability-zone', '--filters', 'Name=instance-type,Values=t3a.small', '--query', 'InstanceTypeOfferings[].Location', '--output', 'json']) 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Set fact of the possible Availability Zones] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.035)       0:00:13.759 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Calculate intersection of all AZs and set_fact] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.049)       0:00:13.809 ********* 
ok: [localhost] => (item=['us-east-2b', 'us-east-2a', 'us-east-2c'])

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Abort if no AZ is found] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.031)       0:00:13.840 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Print possible availability zones] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.029)       0:00:13.870 ********* 
ok: [localhost] => {
    "aws_template_generate_possible_azs": [
        "us-east-2b",
        "us-east-2c",
        "us-east-2a"
    ]
}

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Select the first AZ in the possible AZs and set fact aws_availability_zone] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.014)       0:00:13.884 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Debug] **************
Monday 04 August 2025  12:57:03 +0000 (0:00:00.039)       0:00:13.924 ********* 
ok: [localhost] => {
    "aws_availability_zone": "us-east-2b"
}

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Check if template exists for the environment] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.016)       0:00:13.940 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Use CloudFormation template from the environment] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.154)       0:00:14.095 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Use the default CloudFormation template] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.013)       0:00:14.108 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Print cloudformation_template_src] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.014)       0:00:14.123 ********* 
ok: [localhost] => {
    "cloudformation_template_src": "templates/cloud_template.j2"
}

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Determine the security groups used in 'instances' dictionary] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.014)       0:00:14.137 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Set fact for cloudformation template] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.066)       0:00:14.204 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Print cloudformation_template path] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.016)       0:00:14.221 ********* 
ok: [localhost] => {
    "cloudformation_template": "/tmp/output-3edbde49-1615-51e3-b1d0-5962c605057b/openshift-cluster.76x7m.aws_cloud_template"
}

TASK [agnosticd.cloud_provider_aws.aws_template_generate : AWS Generate CloudFormation Template] ***
Monday 04 August 2025  12:57:03 +0000 (0:00:00.017)       0:00:14.238 ********* 
changed: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Stat CloudFormation template] ***
Monday 04 August 2025  12:57:04 +0000 (0:00:00.386)       0:00:14.625 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Get Caller Identity] ***
Monday 04 August 2025  12:57:04 +0000 (0:00:00.162)       0:00:14.788 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Save AWS account user] ***
Monday 04 August 2025  12:57:04 +0000 (0:00:00.013)       0:00:14.802 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Set bucket templates] ***
Monday 04 August 2025  12:57:04 +0000 (0:00:00.012)       0:00:14.814 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Create bucket] ******
Monday 04 August 2025  12:57:04 +0000 (0:00:00.010)       0:00:14.825 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Copy Template to S3] ***
Monday 04 August 2025  12:57:04 +0000 (0:00:00.010)       0:00:14.835 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Check for !Ref in CF template] ***
Monday 04 August 2025  12:57:04 +0000 (0:00:00.010)       0:00:14.846 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Assert that cloudformation template is valid] ***
Monday 04 August 2025  12:57:04 +0000 (0:00:00.246)       0:00:15.092 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "Cloudformation template is syntactically valid"
}

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Copy original !Ref CF template back in place] ***
Monday 04 August 2025  12:57:04 +0000 (0:00:00.035)       0:00:15.127 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Validate cloudformation template with validate-template (local)] ***
Monday 04 August 2025  12:57:04 +0000 (0:00:00.012)       0:00:15.140 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_generate : Validate cloudformation template with validate-template (S3)] ***
Monday 04 August 2025  12:57:05 +0000 (0:00:00.816)       0:00:15.957 ********* 
skipping: [localhost]

TASK [Check if Cloudformation has been deployed already] ***********************
Monday 04 August 2025  12:57:05 +0000 (0:00:00.012)       0:00:15.970 ********* 
ok: [localhost]

TASK [Debug cloudformation] ****************************************************
Monday 04 August 2025  12:57:06 +0000 (0:00:00.517)       0:00:16.487 ********* 
ok: [localhost] => {
    "r_cloudformation": {
        "changed": false,
        "cloudformation": {},
        "failed": false
    }
}

TASK [Set cloudformation already deployed fact to true] ************************
Monday 04 August 2025  12:57:06 +0000 (0:00:00.014)       0:00:16.501 ********* 
skipping: [localhost]

TASK [Set cloudformation already deployed fact to false] ***********************
Monday 04 August 2025  12:57:06 +0000 (0:00:00.026)       0:00:16.527 ********* 
ok: [localhost]

TASK [Run aws_template_create role] ********************************************
Monday 04 August 2025  12:57:06 +0000 (0:00:00.028)       0:00:16.556 ********* 
included: agnosticd.cloud_provider_aws.aws_template_create for localhost

TASK [agnosticd.cloud_provider_aws.aws_template_create : Retrieve stack_deployed from provision-user-data.yaml] ***
Monday 04 August 2025  12:57:06 +0000 (0:00:00.063)       0:00:16.619 ********* 
skipping: [localhost]

TASK [Include infra_cloud_tags role] *******************************************
Monday 04 August 2025  12:57:06 +0000 (0:00:00.014)       0:00:16.634 ********* 
included: infra_cloud_tags for localhost

TASK [infra_cloud_tags : Set cloud_tags_final (string)] ************************
Monday 04 August 2025  12:57:06 +0000 (0:00:00.038)       0:00:16.673 ********* 
skipping: [localhost]

TASK [infra_cloud_tags : Set cloud_tags_final (dictionary)] ********************
Monday 04 August 2025  12:57:06 +0000 (0:00:00.023)       0:00:16.696 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Set cloudformation_template] ***
Monday 04 August 2025  12:57:06 +0000 (0:00:00.047)       0:00:16.743 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Wait a bit for the previous stack and child resources to be deleted] ***
Monday 04 August 2025  12:57:06 +0000 (0:00:00.020)       0:00:16.764 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Launch CloudFormation from local template] ***
Monday 04 August 2025  12:57:06 +0000 (0:00:00.015)       0:00:16.779 ********* 
changed: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Debug cloudformation] ***
Monday 04 August 2025  12:59:44 +0000 (0:02:37.646)       0:02:54.426 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Debug cloudformation] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.017)       0:02:54.444 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Save cloudformation_out into cloudformation_out_final] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.017)       0:02:54.462 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Launch CloudFormation template from S3] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.024)       0:02:54.486 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Debug cloudformation] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.020)       0:02:54.507 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Debug cloudformation] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.020)       0:02:54.527 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Save cloudformation_out into cloudformation_out_final] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.023)       0:02:54.551 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Delete S3 bucket if it exists] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.020)       0:02:54.572 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Report s3 error] ******
Monday 04 August 2025  12:59:44 +0000 (0:00:00.019)       0:02:54.592 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Destroy cloudformation template] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.017)       0:02:54.609 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Report Cloudformation destroy error] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.017)       0:02:54.626 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Debug cloudformation_out] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.015)       0:02:54.642 ********* 
ok: [localhost] => {
    "cloudformation_out": {
        "changed": false,
        "false_condition": "stat_template.stat.size > 51200",
        "skip_reason": "Conditional result was False",
        "skipped": true
    }
}

TASK [agnosticd.cloud_provider_aws.aws_template_create : Debug fallback_regions] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.018)       0:02:54.660 ********* 
ok: [localhost] => {
    "fallback_regions | default([])": []
}

TASK [agnosticd.cloud_provider_aws.aws_template_create : Report Cloudformation error] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.032)       0:02:54.693 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Save aws_region_loop into aws_region_final] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.015)       0:02:54.709 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Debug cloudformation_out_final] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.020)       0:02:54.729 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Output region] ********
Monday 04 August 2025  12:59:44 +0000 (0:00:00.023)       0:02:54.753 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Set stack_deployed to true] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.022)       0:02:54.775 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Save stack_deployed for future runs (idempotent)] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.023)       0:02:54.798 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_template_create : Set stack_deployed to false] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.019)       0:02:54.818 ********* 
skipping: [localhost]

TASK [Run aws_template_create role into fallback region] ***********************
Monday 04 August 2025  12:59:44 +0000 (0:00:00.021)       0:02:54.839 ********* 
skipping: [localhost]

TASK [Report cloudformation error] *********************************************
Monday 04 August 2025  12:59:44 +0000 (0:00:00.037)       0:02:54.877 ********* 
skipping: [localhost]

PLAY [Step 001.2 Create inventory and SSH config setup] ************************

TASK [Include detect region tasks] *********************************************
Monday 04 August 2025  12:59:44 +0000 (0:00:00.036)       0:02:54.913 ********* 
skipping: [localhost]

TASK [Run aws_create_inventory role] *******************************************
Monday 04 August 2025  12:59:44 +0000 (0:00:00.031)       0:02:54.945 ********* 
included: agnosticd.cloud_provider_aws.aws_create_inventory for localhost

TASK [agnosticd.cloud_provider_aws.aws_create_inventory : Report aws region] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.043)       0:02:54.989 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_create_inventory : Gather EC2 instance info] ***
Monday 04 August 2025  12:59:44 +0000 (0:00:00.037)       0:02:55.027 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_create_inventory : Debug r_ec2_info] ****
Monday 04 August 2025  12:59:45 +0000 (0:00:00.827)       0:02:55.854 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_create_inventory : Windows ostype workaround] ***
Monday 04 August 2025  12:59:45 +0000 (0:00:00.031)       0:02:55.885 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_create_inventory : Save stack tag] ******
Monday 04 August 2025  12:59:45 +0000 (0:00:00.031)       0:02:55.917 ********* 
ok: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_create_inventory : Find the bastion in this batch of host] ***
Monday 04 August 2025  12:59:45 +0000 (0:00:00.033)       0:02:55.950 ********* 
ok: [localhost] => (item=bastion.76x7m.internal)

TASK [agnosticd.cloud_provider_aws.aws_create_inventory : Add hosts to the current inventory] ***
Monday 04 August 2025  12:59:45 +0000 (0:00:00.054)       0:02:56.004 ********* 
changed: [localhost] => (item=bastion.76x7m.internal)

TASK [agnosticd.cloud_provider_aws.aws_create_inventory : Add hosts to groups indicated by AnsibleGroup tag] ***
Monday 04 August 2025  12:59:45 +0000 (0:00:00.073)       0:02:56.077 ********* 
changed: [localhost] => (item=bastion.76x7m.internal)

TASK [agnosticd.cloud_provider_aws.aws_create_inventory : Debug hostvars] ******
Monday 04 August 2025  12:59:45 +0000 (0:00:00.042)       0:02:56.120 ********* 
skipping: [localhost]

TASK [agnosticd.cloud_provider_aws.aws_create_inventory : Debug groups] ********
Monday 04 August 2025  12:59:45 +0000 (0:00:00.031)       0:02:56.152 ********* 
skipping: [localhost]

TASK [Run common SSH config generator role] ************************************
Monday 04 August 2025  12:59:45 +0000 (0:00:00.031)       0:02:56.183 ********* 
included: infra_common_ssh_config_generate for localhost

TASK [infra_common_ssh_config_generate : Store bastion hostname as a fact] *****
Monday 04 August 2025  12:59:45 +0000 (0:00:00.045)       0:02:56.229 ********* 
[WARNING]: Found variable using reserved name: remote_user
ok: [localhost]

TASK [infra_common_ssh_config_generate : Delete dedicated known_host if it exists (new deployment)] ***
Monday 04 August 2025  12:59:46 +0000 (0:00:00.041)       0:02:56.270 ********* 
ok: [localhost]

TASK [infra_common_ssh_config_generate : Delete local ssh config, start fresh] ***
Monday 04 August 2025  12:59:46 +0000 (0:00:00.186)       0:02:56.457 ********* 
ok: [localhost]

TASK [infra_common_ssh_config_generate : Create empty local ssh config] ********
Monday 04 August 2025  12:59:46 +0000 (0:00:00.199)       0:02:56.656 ********* 
changed: [localhost]

TASK [infra_common_ssh_config_generate : Add bastion proxy config to workdir ssh config file] ***
Monday 04 August 2025  12:59:46 +0000 (0:00:00.192)       0:02:56.849 ********* 
changed: [localhost]

TASK [infra_common_ssh_config_generate : Add all hosts to workdir ssh config file] ***
Monday 04 August 2025  12:59:46 +0000 (0:00:00.255)       0:02:57.104 ********* 
skipping: [localhost] => (item=bastion.76x7m.internal) 
skipping: [localhost]

PLAY [Step 0000 Include Vars] **************************************************

TASK [Set output_dir for all hosts] ********************************************
Monday 04 August 2025  12:59:46 +0000 (0:00:00.037)       0:02:57.141 ********* 
ok: [localhost]
ok: [bastion.76x7m.internal]

TASK [Include variables files] *************************************************
Monday 04 August 2025  12:59:46 +0000 (0:00:00.023)       0:02:57.165 ********* 
skipping: [localhost] => (item=/runner/project/ansible/cloud_providers/aws/default_vars.yaml) 
skipping: [localhost] => (item=/runner/project/ansible/cloud_providers/aws/default_vars.yml) 
skipping: [bastion.76x7m.internal] => (item=/runner/project/ansible/cloud_providers/aws/default_vars.yaml) 
skipping: [localhost] => (item=/runner/project/ansible/configs/openshift-cluster/default_vars.yaml) 
skipping: [bastion.76x7m.internal] => (item=/runner/project/ansible/cloud_providers/aws/default_vars.yml) 
skipping: [bastion.76x7m.internal] => (item=/runner/project/ansible/configs/openshift-cluster/default_vars.yaml) 
ok: [localhost] => (item=/runner/project/ansible/configs/openshift-cluster/default_vars.yml)
skipping: [localhost] => (item=/runner/project/ansible/configs/openshift-cluster/aws/default_vars.yaml) 
ok: [bastion.76x7m.internal] => (item=/runner/project/ansible/configs/openshift-cluster/default_vars.yml)
skipping: [bastion.76x7m.internal] => (item=/runner/project/ansible/configs/openshift-cluster/aws/default_vars.yaml) 
ok: [localhost] => (item=/runner/project/ansible/configs/openshift-cluster/aws/default_vars.yml)
ok: [bastion.76x7m.internal] => (item=/runner/project/ansible/configs/openshift-cluster/aws/default_vars.yml)

TASK [Set passthrough user data] ***********************************************
Monday 04 August 2025  12:59:46 +0000 (0:00:00.062)       0:02:57.227 ********* 
skipping: [localhost]
skipping: [bastion.76x7m.internal]
[WARNING]: Could not match supplied host pattern, ignoring: windows
[WARNING]: Could not match supplied host pattern, ignoring: network

PLAY [Step 001.3 Configure Linux hosts and wait for connection] ****************

TASK [Set facts for remote access] *********************************************
Monday 04 August 2025  12:59:47 +0000 (0:00:00.033)       0:02:57.261 ********* 
ok: [bastion.76x7m.internal]

TASK [Run aws_wait_for_linux_hosts role] ***************************************
Monday 04 August 2025  12:59:47 +0000 (0:00:00.039)       0:02:57.300 ********* 
included: agnosticd.cloud_provider_aws.aws_wait_for_linux_hosts for bastion.76x7m.internal

TASK [agnosticd.cloud_provider_aws.aws_wait_for_linux_hosts : Wait for linux host to be available] ***
Monday 04 August 2025  12:59:47 +0000 (0:00:00.026)       0:02:57.327 ********* 
ok: [bastion.76x7m.internal]

TASK [agnosticd.cloud_provider_aws.aws_wait_for_linux_hosts : Restart instance if wait_for_connection failed] ***
Monday 04 August 2025  12:59:48 +0000 (0:00:01.278)       0:02:58.605 ********* 
skipping: [bastion.76x7m.internal]

TASK [agnosticd.cloud_provider_aws.aws_wait_for_linux_hosts : Wait for linux host to be available (retry)] ***
Monday 04 August 2025  12:59:48 +0000 (0:00:00.015)       0:02:58.621 ********* 
skipping: [bastion.76x7m.internal]

TASK [agnosticd.cloud_provider_aws.aws_wait_for_linux_hosts : Ping host] *******
Monday 04 August 2025  12:59:48 +0000 (0:00:00.013)       0:02:58.634 ********* 
[WARNING]: Platform linux on host bastion.76x7m.internal is using the
discovered Python interpreter at /usr/bin/python3.9, but future installation of
another Python interpreter could change the meaning of that path. See
https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.
ok: [bastion.76x7m.internal]

TASK [Set Linux hostname] ******************************************************
Monday 04 August 2025  12:59:49 +0000 (0:00:00.649)       0:02:59.283 ********* 
included: agnosticd.cloud_provider_aws.aws_linux_set_hostname for bastion.76x7m.internal

TASK [agnosticd.cloud_provider_aws.aws_linux_set_hostname : Set hostname based on tag_internaldns] ***
Monday 04 August 2025  12:59:49 +0000 (0:00:00.017)       0:02:59.301 ********* 
changed: [bastion.76x7m.internal]

TASK [agnosticd.cloud_provider_aws.aws_linux_set_hostname : Check for cloud.cfg file] ***
Monday 04 August 2025  12:59:50 +0000 (0:00:01.150)       0:03:00.452 ********* 
ok: [bastion.76x7m.internal]

TASK [agnosticd.cloud_provider_aws.aws_linux_set_hostname : Disable updating hostname in /etc/cloud/cloud.cfg] ***
Monday 04 August 2025  12:59:50 +0000 (0:00:00.601)       0:03:01.053 ********* 
changed: [bastion.76x7m.internal]

TASK [agnosticd.cloud_provider_aws.aws_linux_set_hostname : Add preserve_hostname to /etc/cloud/cloud.cfg] ***
Monday 04 August 2025  12:59:51 +0000 (0:00:00.542)       0:03:01.596 ********* 
changed: [bastion.76x7m.internal]

TASK [Add authorized_keys] *****************************************************
Monday 04 August 2025  12:59:51 +0000 (0:00:00.548)       0:03:02.145 ********* 
skipping: [bastion.76x7m.internal]

PLAY [Step 001.4 Configure Windows hosts and wait for connection] **************
skipping: no hosts matched

PLAY [Step 002 - Post Infrastructure] ******************************************

TASK [Save user data] **********************************************************
Monday 04 August 2025  12:59:51 +0000 (0:00:00.034)       0:03:02.179 ********* 
ok: [localhost] => {
    "changed": false,
    "data": {
        "cloud_provider": "aws",
        "guid": "76x7m"
    }
}

TASK [Debug cloudformation_out_final] ******************************************
Monday 04 August 2025  12:59:51 +0000 (0:00:00.035)       0:03:02.214 ********* 
skipping: [localhost]

TASK [Debug cloudformation_out_existing] ***************************************
Monday 04 August 2025  12:59:51 +0000 (0:00:00.018)       0:03:02.233 ********* 
skipping: [localhost]

TASK [Save Route53User credentials from stack outputs (CloudFormation just created)] ***
Monday 04 August 2025  12:59:51 +0000 (0:00:00.018)       0:03:02.251 ********* 
ok: [localhost]

TASK [Save Route53User credentials from stack outputs (CloudFormation existed previously)] ***
Monday 04 August 2025  12:59:52 +0000 (0:00:00.041)       0:03:02.293 ********* 
skipping: [localhost]

TASK [Debug Route53 variables] *************************************************
Monday 04 August 2025  12:59:52 +0000 (0:00:00.034)       0:03:02.327 ********* 
ok: [localhost] => (item=route53user: openshift-cluster-76x7m-Route53User-c5KhJ1gLdBbT) => {
    "msg": "route53user: openshift-cluster-76x7m-Route53User-c5KhJ1gLdBbT"
}
ok: [localhost] => (item=route53user_access_key: [REDACTED_AWS Access Key_SECRET]) => {
    "msg": "route53user_access_key: [REDACTED_AWS Access Key_SECRET]"
}
ok: [localhost] => (item=route53user_secret_access_key: [REDACTED_REPLACED]) => {
    "msg": "route53user_secret_access_key: [REDACTED_REPLACED]"
}

TASK [Create secret for SSH Key] ***********************************************
Monday 04 August 2025  12:59:52 +0000 (0:00:00.039)       0:03:02.367 ********* 
skipping: [localhost]

TASK [Set FQDN for the bastion VM] *********************************************
Monday 04 August 2025  12:59:52 +0000 (0:00:00.015)       0:03:02.382 ********* 
skipping: [localhost]

TASK [Set FQDN for each Windows VM] ********************************************
Monday 04 August 2025  12:59:52 +0000 (0:00:00.015)       0:03:02.397 ********* 
skipping: [localhost]

TASK [Set FQDN for each Windows VM] ********************************************
Monday 04 August 2025  12:59:52 +0000 (0:00:00.014)       0:03:02.411 ********* 
skipping: [localhost]

TASK [Print Host Information] **************************************************
Monday 04 August 2025  12:59:52 +0000 (0:00:00.014)       0:03:02.426 ********* 
skipping: [localhost]

PLAY [Export inventory] ********************************************************

TASK [Export in-memory inventory to inventory file] ****************************
Monday 04 August 2025  12:59:52 +0000 (0:00:00.017)       0:03:02.443 ********* 
skipping: [localhost]

PLAY [Step 003 - Pre Software] *************************************************

TASK [Print debug message] *****************************************************
Monday 04 August 2025  12:59:52 +0000 (0:00:00.029)       0:03:02.472 ********* 
ok: [localhost] => {
    "msg": "Step 003 - Pre Software"
}

PLAY [Step 003.1 Configure all hosts with repositories and common packages] ****

TASK [host_satellite_repositories : Run setup if gather_facts hasn't been run] ***
Monday 04 August 2025  12:59:52 +0000 (0:00:00.018)       0:03:02.490 ********* 
ok: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Configure Satellite repositories] **********
Monday 04 August 2025  12:59:53 +0000 (0:00:00.950)       0:03:03.441 ********* 
included: /runner/project/ansible/roles/host_satellite_repositories/tasks/satellite_register.yml for bastion.76x7m.internal

TASK [host_satellite_repositories : Check subscription-manager package existence] ***
Monday 04 August 2025  12:59:53 +0000 (0:00:00.055)       0:03:03.496 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Install subscription-manager package] ******
Monday 04 August 2025  12:59:53 +0000 (0:00:00.033)       0:03:03.530 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Remove rh-amazon-rhui-client package] ******
Monday 04 August 2025  12:59:53 +0000 (0:00:00.034)       0:03:03.564 ********* 
changed: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Unregister the system just in case] ********
Monday 04 August 2025  12:59:58 +0000 (0:00:05.429)       0:03:08.993 ********* 
included: /runner/project/ansible/roles/host_satellite_repositories/tasks/unregister.yml for bastion.76x7m.internal

TASK [host_satellite_repositories : Unregister from Subscription Manager] ******
Monday 04 August 2025  12:59:58 +0000 (0:00:00.038)       0:03:09.032 ********* 
changed: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Install CA certificate from satellite server] ***
Monday 04 August 2025  12:59:59 +0000 (0:00:01.091)       0:03:10.123 ********* 
changed: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Update CA trust bundle] ********************
Monday 04 August 2025  13:00:00 +0000 (0:00:00.863)       0:03:10.987 ********* 
changed: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Remove satellite cert] *********************
Monday 04 August 2025  13:00:03 +0000 (0:00:02.437)       0:03:13.425 ********* 
ok: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Find current repository files] *************
Monday 04 August 2025  13:00:04 +0000 (0:00:01.260)       0:03:14.685 ********* 
ok: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Remove current repository files] ***********
Monday 04 August 2025  13:00:05 +0000 (0:00:00.750)       0:03:15.436 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Install Satellite CA certificate package] ***
Monday 04 August 2025  13:00:05 +0000 (0:00:00.019)       0:03:15.455 ********* 
changed: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Disable reporting of package profile to Satellite] ***
Monday 04 August 2025  13:00:10 +0000 (0:00:04.861)       0:03:20.316 ********* 
changed: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Set host_satellite_repositories_subscription_hostname to provided value] ***
Monday 04 August 2025  13:00:10 +0000 (0:00:00.744)       0:03:21.061 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Set host_satellite_repositories_subscription_hostname with randomization] ***
Monday 04 August 2025  13:00:10 +0000 (0:00:00.030)       0:03:21.091 ********* 
ok: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Set network.fqdn in /etc/rhsm/facts/katello.facts] ***
Monday 04 August 2025  13:00:10 +0000 (0:00:00.034)       0:03:21.126 ********* 
changed: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Register with activation-key] **************
Monday 04 August 2025  13:00:11 +0000 (0:00:01.014)       0:03:22.140 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Register with activation-key with HA] ******
Monday 04 August 2025  13:00:11 +0000 (0:00:00.032)       0:03:22.172 ********* 
changed: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Enable RHSM to manage repositories] ********
Monday 04 August 2025  13:00:18 +0000 (0:00:06.699)       0:03:28.872 ********* 
changed: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Lock RHEL 9 release to specific version] ***
Monday 04 August 2025  13:00:19 +0000 (0:00:01.152)       0:03:30.024 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Enable repos] ******************************
Monday 04 August 2025  13:00:19 +0000 (0:00:00.038)       0:03:30.063 ********* 
changed: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Clean repositories] ************************
Monday 04 August 2025  13:00:23 +0000 (0:00:03.866)       0:03:33.930 ********* 
changed: [bastion.76x7m.internal]

TASK [host_satellite_repositories : Unregister from subscription manager] ******
Monday 04 August 2025  13:00:25 +0000 (0:00:01.436)       0:03:35.366 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_common_packages : Deactivate DNS lookup in sshd] ********************
Monday 04 August 2025  13:00:25 +0000 (0:00:00.028)       0:03:35.395 ********* 
changed: [bastion.76x7m.internal]

TASK [host_common_packages : Update all packages] ******************************
Monday 04 August 2025  13:00:25 +0000 (0:00:00.600)       0:03:35.996 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_common_packages : Determine if reboot is needed] ********************
Monday 04 August 2025  13:00:25 +0000 (0:00:00.027)       0:03:36.023 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_common_packages : Reboot all VMs] ***********************************
Monday 04 August 2025  13:00:25 +0000 (0:00:00.027)       0:03:36.050 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_common_packages : Update network facts after reboot] ****************
Monday 04 August 2025  13:00:25 +0000 (0:00:00.028)       0:03:36.079 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_common_packages : Run setup if gather_facts hasn't been run] ********
Monday 04 August 2025  13:00:25 +0000 (0:00:00.037)       0:03:36.116 ********* 
skipping: [bastion.76x7m.internal]

TASK [host_common_packages : Install common packages for RHEL 9] ***************
Monday 04 August 2025  13:00:25 +0000 (0:00:00.040)       0:03:36.157 ********* 
included: /runner/project/ansible/roles/host_common_packages/tasks/packages_el9.yml for bastion.76x7m.internal

TASK [host_common_packages : Install common packages for RHEL 9] ***************
Monday 04 August 2025  13:00:25 +0000 (0:00:00.038)       0:03:36.195 ********* 
changed: [bastion.76x7m.internal]

TASK [host_common_packages : Install extra packages] ***************************
Monday 04 August 2025  13:01:40 +0000 (0:01:14.951)       0:04:51.147 ********* 
skipping: [bastion.76x7m.internal]

TASK [Add GUID to /etc/skel/.bashrc] *******************************************
Monday 04 August 2025  13:01:40 +0000 (0:00:00.030)       0:04:51.177 ********* 
changed: [bastion.76x7m.internal]

RUNNING HANDLER [host_common_packages : Restart sshd] **************************
Monday 04 August 2025  13:01:41 +0000 (0:00:00.842)       0:04:52.019 ********* 
changed: [bastion.76x7m.internal]

PLAY [Step 003.2 - Configuring bastion hosts] **********************************

TASK [Gathering Facts] *********************************************************
Monday 04 August 2025  13:01:43 +0000 (0:00:01.268)       0:04:53.288 ********* 
ok: [bastion.76x7m.internal]

TASK [bastion : Generate an SSH key on the Bastion and configure access on all the hosts] ***
Monday 04 August 2025  13:01:44 +0000 (0:00:01.401)       0:04:54.690 ********* 
included: /runner/project/ansible/roles/bastion/tasks/create_bastion_ssh_key_and_access.yml for bastion.76x7m.internal

TASK [bastion : Generate SSH keys] *********************************************
Monday 04 August 2025  13:01:44 +0000 (0:00:00.036)       0:04:54.726 ********* 
changed: [bastion.76x7m.internal]

TASK [bastion : Read SSH public key] *******************************************
Monday 04 August 2025  13:01:45 +0000 (0:00:01.205)       0:04:55.932 ********* 
ok: [bastion.76x7m.internal]

TASK [bastion : Save all facts for SSH] ****************************************
Monday 04 August 2025  13:01:46 +0000 (0:00:00.699)       0:04:56.632 ********* 
ok: [bastion.76x7m.internal]

TASK [bastion : Debug ssh pub key] *********************************************
Monday 04 August 2025  13:01:46 +0000 (0:00:00.034)       0:04:56.666 ********* 
ok: [bastion.76x7m.internal] => {
    "msg": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDOMw9bEMRhBxouenbHy2zrwSZSGUzQ2tW3DhbG6MTHf1N7U1izdKCsu25SxbM9v0SrT+H9CsLTeCjviEmjzsKoOSUHbgkc9I6WT5Vc8aKADzu/J/PawDZZXgfaejWu1baKWx386O1BfL8U5RtsldMN8S/5qhWS19NDddoyZ2+4uowJlJh2d0+bLYOwOrVJ1Q6u53MEwggrrtqoMNFo8vZDfHOHLNqtIUVZyaGUgh71DIZKnBz06KOGtk4ldo9XQDric+HmP+HHlS3pPVwpKQZm+QOxzq1RPxBfkhbTLaZJAc/0zg6+ECPtNH5T9KDJ99L6+Amna/lUZrbgMjzl0iPH Bastion\\n"
}

TASK [bastion : Add bastion access to all hosts] *******************************
Monday 04 August 2025  13:01:46 +0000 (0:00:00.032)       0:04:56.699 ********* 
changed: [bastion.76x7m.internal] => (item=bastion.76x7m.internal)

TASK [bastion : Add bastion access to all hosts] *******************************
Monday 04 August 2025  13:01:47 +0000 (0:00:00.981)       0:04:57.681 ********* 
changed: [bastion.76x7m.internal] => (item=bastion.76x7m.internal)

TASK [bastion : Generate .ssh/config] ******************************************
Monday 04 August 2025  13:01:48 +0000 (0:00:00.799)       0:04:58.480 ********* 
changed: [bastion.76x7m.internal]

TASK [bastion : Add GUID to /etc/skel/.bashrc] *********************************
Monday 04 August 2025  13:01:49 +0000 (0:00:01.443)       0:04:59.924 ********* 
ok: [bastion.76x7m.internal]

TASK [bastion : Add GUID to ~ec2-user/.bashrc] *********************************
Monday 04 August 2025  13:01:50 +0000 (0:00:00.733)       0:05:00.657 ********* 
changed: [bastion.76x7m.internal]

TASK [bastion : Add CLOUDUSER to /etc/skel/.bashrc] ****************************
Monday 04 August 2025  13:01:51 +0000 (0:00:00.684)       0:05:01.342 ********* 
changed: [bastion.76x7m.internal]

TASK [bastion : Add CLOUDUSER to ~ec2-user/.bashrc] ****************************
Monday 04 August 2025  13:01:51 +0000 (0:00:00.744)       0:05:02.086 ********* 
changed: [bastion.76x7m.internal]

TASK [Install FTL] *************************************************************
Monday 04 August 2025  13:01:52 +0000 (0:00:00.704)       0:05:02.791 ********* 
skipping: [bastion.76x7m.internal]

TASK [bastion : Set up student user] *******************************************
Monday 04 August 2025  13:01:52 +0000 (0:00:00.030)       0:05:02.821 ********* 
included: /runner/project/ansible/roles/bastion/tasks/setup_student_user.yml for bastion.76x7m.internal

TASK [bastion : Set _bastion_student_user_password if password has been provided] ***
Monday 04 August 2025  13:01:52 +0000 (0:00:00.042)       0:05:02.863 ********* 
skipping: [bastion.76x7m.internal]

TASK [bastion : Generate _bastion_student_user_password if not defined] ********
Monday 04 August 2025  13:01:52 +0000 (0:00:00.032)       0:05:02.895 ********* 
ok: [bastion.76x7m.internal]

TASK [bastion : Create student user] *******************************************
Monday 04 August 2025  13:01:52 +0000 (0:00:00.036)       0:05:02.932 ********* 
changed: [bastion.76x7m.internal]

TASK [bastion : Add student public key if provided] ****************************
Monday 04 August 2025  13:01:53 +0000 (0:00:01.202)       0:05:04.135 ********* 
skipping: [bastion.76x7m.internal]

TASK [bastion : Enable password authentication] ********************************
Monday 04 August 2025  13:01:53 +0000 (0:00:00.031)       0:05:04.166 ********* 
changed: [bastion.76x7m.internal]

TASK [bastion : Remove PasswordAuthentication line from 50-cloud-init.conf] ****
Monday 04 August 2025  13:01:54 +0000 (0:00:00.629)       0:05:04.795 ********* 
changed: [bastion.76x7m.internal]

TASK [bastion : Disable root password authentication] **************************
Monday 04 August 2025  13:01:55 +0000 (0:00:00.607)       0:05:05.403 ********* 
changed: [bastion.76x7m.internal]

TASK [bastion : Allow passwordless sudo] ***************************************
Monday 04 August 2025  13:01:55 +0000 (0:00:00.609)       0:05:06.012 ********* 
changed: [bastion.76x7m.internal]

TASK [bastion : Restart sshd] **************************************************
Monday 04 August 2025  13:01:56 +0000 (0:00:00.602)       0:05:06.614 ********* 
changed: [bastion.76x7m.internal]

TASK [bastion : Set _bastion_public_hostname from inventory (not an OpenShift Cluster config)] ***
Monday 04 August 2025  13:01:57 +0000 (0:00:00.894)       0:05:07.509 ********* 
skipping: [bastion.76x7m.internal]

TASK [bastion : Set Bastion Hostname (AWS)] ************************************
Monday 04 August 2025  13:01:57 +0000 (0:00:00.034)       0:05:07.544 ********* 
ok: [bastion.76x7m.internal]

TASK [bastion : Set Bastion Hostname (GCP)] ************************************
Monday 04 August 2025  13:01:57 +0000 (0:00:00.048)       0:05:07.593 ********* 
skipping: [bastion.76x7m.internal]

TASK [bastion : Set Bastion Hostname (Other)] **********************************
Monday 04 August 2025  13:01:57 +0000 (0:00:00.036)       0:05:07.629 ********* 
skipping: [bastion.76x7m.internal]

TASK [bastion : Print access info (non CNV)] ***********************************
Monday 04 August 2025  13:01:57 +0000 (0:00:00.038)       0:05:07.668 ********* 
ok: [bastion.76x7m.internal] => {
    "changed": false,
    "msg": "user.info: You can access your bastion via SSH:\\nssh lab-user@bastion.76x7m.sandbox1795.opentlc.com\\n\\nUse password 'koIBY5J7KpSv' when prompted.\\n"
}

TASK [bastion : Print access info (CNV)] ***************************************
Monday 04 August 2025  13:01:57 +0000 (0:00:00.042)       0:05:07.710 ********* 
skipping: [bastion.76x7m.internal]

TASK [bastion : Set access data] ***********************************************
Monday 04 August 2025  13:01:57 +0000 (0:00:00.037)       0:05:07.748 ********* 
ok: [bastion.76x7m.internal] => {
    "changed": false,
    "data": {
        "bastion_public_hostname": "bastion.76x7m.sandbox1795.opentlc.com",
        "bastion_ssh_password": "[REDACTED_Secret Keyword_SECRET]",
        "bastion_ssh_user_name": "lab-user"
    }
}

TASK [bastion : Set bastion port for CNV] **************************************
Monday 04 August 2025  13:01:57 +0000 (0:00:00.043)       0:05:07.792 ********* 
skipping: [bastion.76x7m.internal]

PLAY [Step 004 - Software] *****************************************************

TASK [Install OpenShift] *******************************************************
Monday 04 August 2025  13:01:57 +0000 (0:00:00.047)       0:05:07.839 ********* 
included: host_ocp4_deploy for localhost

TASK [host_ocp4_deploy : Include tasks file for installation method 'openshift_install'] ***
Monday 04 August 2025  13:01:57 +0000 (0:00:00.018)       0:05:07.858 ********* 
included: /runner/project/ansible/roles/host_ocp4_deploy/tasks/openshift_install.yml for localhost

TASK [host_ocp4_deploy : Wait for openshift-install to complete] ***************
Monday 04 August 2025  13:01:57 +0000 (0:00:00.021)       0:05:07.879 ********* 
ok: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_deploy : Check if there is a cluster installed] ****************
Monday 04 August 2025  13:01:58 +0000 (0:00:00.576)       0:05:08.456 ********* 
ok: [localhost -> bastion.76x7m.internal]

TASK [Call Role to provision OCP4 install host] ********************************
Monday 04 August 2025  13:01:58 +0000 (0:00:00.565)       0:05:09.021 ********* 
included: host_ocp4_provisioner for localhost

TASK [host_ocp4_provisioner : Set up cloud provider specific prerequisites] ****
Monday 04 August 2025  13:01:58 +0000 (0:00:00.024)       0:05:09.045 ********* 
included: /runner/project/ansible/roles/host_ocp4_provisioner/tasks/aws_prereqs.yml for localhost

TASK [host_ocp4_provisioner : Create .aws directory] ***************************
Monday 04 August 2025  13:01:58 +0000 (0:00:00.030)       0:05:09.075 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_provisioner : Add aws credentials for sandboxes] ***************
Monday 04 August 2025  13:01:59 +0000 (0:00:00.586)       0:05:09.661 ********* 
skipping: [localhost]

TASK [host_ocp4_provisioner : Add aws credentials for shared account] **********
Monday 04 August 2025  13:01:59 +0000 (0:00:00.033)       0:05:09.695 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_provisioner : Install slirp4netns] *****************************
Monday 04 August 2025  13:02:00 +0000 (0:00:00.566)       0:05:10.261 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_provisioner : Update max_user_namespaces in sysctl] ************
Monday 04 August 2025  13:02:05 +0000 (0:00:05.496)       0:05:15.758 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [Call Role to install OpenShift] ******************************************
Monday 04 August 2025  13:02:06 +0000 (0:00:00.719)       0:05:16.477 ********* 
included: host_ocp4_installer for localhost

TASK [host_ocp4_installer : Assert OpenShift Versions] *************************
Monday 04 August 2025  13:02:06 +0000 (0:00:00.061)       0:05:16.539 ********* 
ok: [localhost -> bastion.76x7m.internal] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [host_ocp4_installer : Install client and OpenShift Installer binaries] ***
Monday 04 August 2025  13:02:06 +0000 (0:00:00.027)       0:05:16.567 ********* 
included: /runner/project/ansible/roles/host_ocp4_installer/tasks/install_installer.yml for localhost

TASK [host_ocp4_installer : Gather distribution version] ***********************
Monday 04 August 2025  13:02:06 +0000 (0:00:00.036)       0:05:16.603 ********* 
ok: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Set URLs for OpenShift GA releases (specific version)] ***
Monday 04 August 2025  13:02:07 +0000 (0:00:00.822)       0:05:17.426 ********* 
ok: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Set URLs for OpenShift GA releases (latest stable)] ***
Monday 04 August 2025  13:02:07 +0000 (0:00:00.056)       0:05:17.482 ********* 
skipping: [localhost]

TASK [host_ocp4_installer : Set URLs for OpenShift dev preview releases] *******
Monday 04 August 2025  13:02:07 +0000 (0:00:00.039)       0:05:17.522 ********* 
skipping: [localhost]

TASK [host_ocp4_installer : Ensure _host_ocp4_installer_url and _host_ocp4_installer_client_url are set] ***
Monday 04 August 2025  13:02:07 +0000 (0:00:00.032)       0:05:17.555 ********* 
ok: [localhost -> bastion.76x7m.internal] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [host_ocp4_installer : Debug URLs] ****************************************
Monday 04 August 2025  13:02:07 +0000 (0:00:00.040)       0:05:17.595 ********* 
ok: [localhost -> bastion.76x7m.internal] => (item=OpenShift Installer URL: https://mirror.openshift.com/pub/openshift-v4/clients/ocp/4.18.6/openshift-install-linux-4.18.6.tar.gz) => {
    "msg": "OpenShift Installer URL: https://mirror.openshift.com/pub/openshift-v4/clients/ocp/4.18.6/openshift-install-linux-4.18.6.tar.gz"
}
ok: [localhost -> bastion.76x7m.internal] => (item=OpenShift Client URL: https://mirror.openshift.com/pub/openshift-v4/clients/ocp/4.18.6/openshift-client-linux-4.18.6.tar.gz) => {
    "msg": "OpenShift Client URL: https://mirror.openshift.com/pub/openshift-v4/clients/ocp/4.18.6/openshift-client-linux-4.18.6.tar.gz"
}

TASK [host_ocp4_installer : Get the OpenShift Installer] ***********************
Monday 04 August 2025  13:02:07 +0000 (0:00:00.030)       0:05:17.626 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Check if the installer is a FIPS installer] ********
Monday 04 August 2025  13:02:35 +0000 (0:00:27.677)       0:05:45.303 ********* 
ok: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Hard link the FIPS installer if it exists] *********
Monday 04 August 2025  13:02:35 +0000 (0:00:00.759)       0:05:46.063 ********* 
skipping: [localhost]

TASK [host_ocp4_installer : Get the OpenShift CLI] *****************************
Monday 04 August 2025  13:02:35 +0000 (0:00:00.020)       0:05:46.083 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Enable FIPS mode on host] **************************
Monday 04 August 2025  13:02:44 +0000 (0:00:08.413)       0:05:54.496 ********* 
skipping: [localhost]

TASK [host_ocp4_installer : Generate install_config.yaml] **********************
Monday 04 August 2025  13:02:44 +0000 (0:00:00.036)       0:05:54.533 ********* 
included: /runner/project/ansible/roles/host_ocp4_installer/tasks/generate_install_config.yml for localhost

TASK [host_ocp4_installer : Generate SSH keys for installer] *******************
Monday 04 August 2025  13:02:44 +0000 (0:00:00.043)       0:05:54.577 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Slurp public key] **********************************
Monday 04 August 2025  13:02:45 +0000 (0:00:00.807)       0:05:55.384 ********* 
ok: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Create cluster directory] **************************
Monday 04 August 2025  13:02:45 +0000 (0:00:00.569)       0:05:55.954 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Generate config install-config.yaml] ***************
Monday 04 August 2025  13:02:46 +0000 (0:00:00.580)       0:05:56.534 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Make a copy of the cluster install config] *********
Monday 04 August 2025  13:02:47 +0000 (0:00:01.391)       0:05:57.926 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Create openshift-install manifests] ****************
Monday 04 August 2025  13:02:48 +0000 (0:00:00.631)       0:05:58.557 ********* 
included: /runner/project/ansible/roles/host_ocp4_installer/tasks/create_manifests.yml for localhost

TASK [host_ocp4_installer : Run openshift-install create manifests] ************
Monday 04 August 2025  13:02:48 +0000 (0:00:00.045)       0:05:58.603 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Run the installer] *********************************
Monday 04 August 2025  13:02:56 +0000 (0:00:07.713)       0:06:06.316 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Check installer status] ****************************
Monday 04 August 2025  13:02:56 +0000 (0:00:00.759)       0:06:07.076 ********* 
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (300 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (299 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (298 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (297 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (296 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (295 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (294 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (293 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (292 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (291 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (290 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (289 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (288 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (287 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (286 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (285 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (284 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (283 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (282 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (281 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (280 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (279 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (278 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (277 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (276 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (275 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (274 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (273 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (272 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (271 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (270 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (269 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (268 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (267 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (266 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (265 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (264 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (263 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (262 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (261 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (260 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (259 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (258 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (257 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (256 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (255 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (254 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (253 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (252 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (251 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (250 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (249 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (248 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (247 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (246 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (245 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (244 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (243 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (242 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (241 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (240 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (239 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (238 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (237 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (236 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (235 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (234 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (233 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (232 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (231 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (230 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (229 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (228 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (227 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (226 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (225 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (224 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (223 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (222 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (221 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (220 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (219 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (218 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (217 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (216 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (215 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (214 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (213 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (212 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (211 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (210 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (209 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (208 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (207 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (206 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (205 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (204 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (203 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (202 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (201 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (200 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (199 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (198 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (197 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (196 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (195 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (194 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (193 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (192 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (191 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (190 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (189 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (188 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (187 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (186 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (185 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (184 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (183 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (182 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (181 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (180 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (179 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (178 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (177 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (176 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (175 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (174 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (173 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (172 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (171 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (170 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (169 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (168 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (167 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (166 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (165 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (164 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (163 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (162 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (161 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (160 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (159 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (158 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (157 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (156 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (155 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (154 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (153 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (152 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (151 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (150 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (149 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (148 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (147 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (146 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (145 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (144 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (143 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (142 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (141 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (140 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (139 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (138 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (137 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (136 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (135 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (134 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (133 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (132 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (131 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (130 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (129 retries left).
FAILED - RETRYING: [localhost -> bastion.76x7m.internal]: Check installer status (128 retries left).
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Gzip Install log] **********************************
Monday 04 August 2025  13:47:48 +0000 (0:44:51.810)       0:50:58.887 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Get Install log] ***********************************
Monday 04 August 2025  13:47:49 +0000 (0:00:00.707)       0:50:59.594 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [Save output_dir archive] *************************************************
Monday 04 August 2025  13:47:50 +0000 (0:00:00.681)       0:51:00.276 ********* 
included: agnosticd_save_output_dir for localhost

TASK [agnosticd_save_output_dir : Create output_dir archive] *******************
Monday 04 August 2025  13:47:50 +0000 (0:00:00.104)       0:51:00.380 ********* 
included: /runner/project/ansible/roles/agnosticd_save_output_dir/tasks/create_output_dir_archive.yml for localhost

TASK [agnosticd_save_output_dir : Create tempfile for archive] *****************
Monday 04 August 2025  13:47:50 +0000 (0:00:00.111)       0:51:00.492 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Set agnosticd_save_output_dir_archive_tempfile] ***
Monday 04 August 2025  13:47:50 +0000 (0:00:00.266)       0:51:00.759 ********* 
ok: [localhost]

TASK [agnosticd_save_output_dir : Create output_dir archive] *******************
Monday 04 August 2025  13:47:50 +0000 (0:00:00.084)       0:51:00.843 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Encrypt tarball using password] **************
Monday 04 August 2025  13:47:50 +0000 (0:00:00.252)       0:51:01.096 ********* 
skipping: [localhost]

TASK [agnosticd_save_output_dir : Upload output_dir archive to S3] *************
Monday 04 August 2025  13:47:50 +0000 (0:00:00.085)       0:51:01.181 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Remove output_dir archive tempfile] **********
Monday 04 August 2025  13:47:51 +0000 (0:00:01.001)       0:51:02.183 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Remove output_dir encrypted archive tempfile] ***
Monday 04 August 2025  13:47:52 +0000 (0:00:00.180)       0:51:02.364 ********* 
skipping: [localhost]

TASK [host_ocp4_installer : Fetch kube config] *********************************
Monday 04 August 2025  13:47:52 +0000 (0:00:00.035)       0:51:02.399 ********* 
changed: [localhost -> bastion.76x7m.internal] => (item=kubeconfig)
changed: [localhost -> bastion.76x7m.internal] => (item=kubeadmin-password)

TASK [host_ocp4_installer : Make sure .kube directory exists for ec2-user] *****
Monday 04 August 2025  13:47:53 +0000 (0:00:01.211)       0:51:03.611 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Make sure .kube directory exists for root] *********
Monday 04 August 2025  13:47:53 +0000 (0:00:00.541)       0:51:04.153 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Copy cluster kubeconfig to /home/ec2-user] *********
Monday 04 August 2025  13:47:54 +0000 (0:00:00.596)       0:51:04.750 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Copy cluster kubeconfig to /root/.kube/config] *****
Monday 04 August 2025  13:47:55 +0000 (0:00:00.556)       0:51:05.307 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Make sure .kube directory exists in /home/lab-user] ***
Monday 04 August 2025  13:47:55 +0000 (0:00:00.562)       0:51:05.869 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Copy kubeconfig to /home/lab-user] *****************
Monday 04 August 2025  13:47:56 +0000 (0:00:00.588)       0:51:06.457 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer : Create OpenShift Bash completion file] *************
Monday 04 August 2025  13:47:56 +0000 (0:00:00.602)       0:51:07.059 ********* 
changed: [localhost -> bastion.76x7m.internal]

TASK [Get installed cluster information] ***************************************
Monday 04 August 2025  13:48:02 +0000 (0:00:05.566)       0:51:12.625 ********* 
included: host_ocp4_installer_info for localhost

TASK [host_ocp4_installer_info : Get kubeadmin password] ***********************
Monday 04 August 2025  13:48:02 +0000 (0:00:00.034)       0:51:12.660 ********* 
ok: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer_info : Determine Web console URL] ********************
Monday 04 August 2025  13:48:02 +0000 (0:00:00.521)       0:51:13.181 ********* 
ok: [localhost]

TASK [host_ocp4_installer_info : Determine API server URL] *********************
Monday 04 August 2025  13:48:03 +0000 (0:00:00.982)       0:51:14.164 ********* 
ok: [localhost]

TASK [host_ocp4_installer_info : Determine OpenShift Ingress Domain] ***********
Monday 04 August 2025  13:48:04 +0000 (0:00:00.606)       0:51:14.771 ********* 
ok: [localhost]

TASK [host_ocp4_installer_info : Set facts for OpenShift access] ***************
Monday 04 August 2025  13:48:05 +0000 (0:00:00.670)       0:51:15.442 ********* 
ok: [localhost -> bastion.76x7m.internal]

TASK [host_ocp4_installer_info : Set user data for kubeadmin password] *********
Monday 04 August 2025  13:48:05 +0000 (0:00:00.046)       0:51:15.488 ********* 
skipping: [localhost]

TASK [host_ocp4_installer_info : Set user data for OpenShift access] ***********
Monday 04 August 2025  13:48:05 +0000 (0:00:00.035)       0:51:15.523 ********* 
ok: [localhost -> bastion.76x7m.internal] => {
    "changed": false,
    "data": {
        "openshift_api_url": "api.ocp.76x7m.sandbox1795.opentlc.com",
        "openshift_cluster_ingress_domain": "apps.ocp.76x7m.sandbox1795.opentlc.com",
        "openshift_console_url": "https://console-openshift-console.apps.ocp.76x7m.sandbox1795.opentlc.com"
    }
}

TASK [host_ocp4_installer_info : Show user messages for OpenShift access] ******
Monday 04 August 2025  13:48:05 +0000 (0:00:00.052)       0:51:15.575 ********* 
ok: [localhost -> bastion.76x7m.internal] => {
    "changed": false,
    "msg": "user.info: OpenShift Console: https://console-openshift-console.apps.ocp.76x7m.sandbox1795.opentlc.com\\nOpenShift API for command line 'oc' client: api.ocp.76x7m.sandbox1795.opentlc.com\\n"
}

PLAY [Step 005 - Post software] ************************************************

TASK [Print post software] *****************************************************
Monday 04 August 2025  13:48:05 +0000 (0:00:00.052)       0:51:15.628 ********* 
ok: [bastion.76x7m.internal] => {
    "msg": "Post-Software Steps starting"
}

TASK [Remove AWS Credentials from bastion] *************************************
Monday 04 August 2025  13:48:05 +0000 (0:00:00.016)       0:51:15.644 ********* 
changed: [bastion.76x7m.internal]

TASK [Remove Azure Credentials directory from bastion] *************************
Monday 04 August 2025  13:48:05 +0000 (0:00:00.572)       0:51:16.217 ********* 
skipping: [bastion.76x7m.internal]

TASK [Remove the openshift-installer GCP Credentials directory from bastion] ***
Monday 04 August 2025  13:48:05 +0000 (0:00:00.013)       0:51:16.231 ********* 
skipping: [bastion.76x7m.internal]

TASK [Remove gcloud CLI Credentials directory from bastion] ********************
Monday 04 August 2025  13:48:05 +0000 (0:00:00.012)       0:51:16.244 ********* 
skipping: [bastion.76x7m.internal]

TASK [Print GCP access user info] **********************************************
Monday 04 August 2025  13:48:06 +0000 (0:00:00.013)       0:51:16.257 ********* 
skipping: [bastion.76x7m.internal]

PLAY [Step 005.2 - Post install cluster configuration] *************************

TASK [Setup cluster-admin service account] *************************************
Monday 04 August 2025  13:48:06 +0000 (0:00:00.013)       0:51:16.271 ********* 
skipping: [localhost]

PLAY [Install workloads] *******************************************************

TASK [Install workloads] *******************************************************
Monday 04 August 2025  13:48:06 +0000 (0:00:00.029)       0:51:16.301 ********* 
included: agnosticd.core_workloads.ocp4_workload_openshift_data_foundation for localhost => (item=agnosticd.core_workloads.ocp4_workload_openshift_data_foundation)
included: agnosticd.core_workloads.ocp4_workload_machinesets for localhost => (item=agnosticd.core_workloads.ocp4_workload_machinesets)
included: agnosticd.core_workloads.ocp4_workload_cert_manager for localhost => (item=agnosticd.core_workloads.ocp4_workload_cert_manager)
included: agnosticd.core_workloads.ocp4_workload_authentication_rhsso for localhost => (item=agnosticd.core_workloads.ocp4_workload_authentication_rhsso)
included: agnosticd.core_workloads.ocp4_workload_serverless for localhost => (item=agnosticd.core_workloads.ocp4_workload_serverless)
included: agnosticd.core_workloads.ocp4_workload_pipelines for localhost => (item=agnosticd.core_workloads.ocp4_workload_pipelines)
included: agnosticd.core_workloads.ocp4_workload_openshift_gitops for localhost => (item=agnosticd.core_workloads.ocp4_workload_openshift_gitops)
included: agnosticd.core_workloads.ocp4_workload_minio for localhost => (item=agnosticd.core_workloads.ocp4_workload_minio)
included: agnosticd.core_workloads.ocp4_workload_nfd for localhost => (item=agnosticd.core_workloads.ocp4_workload_nfd)
included: agnosticd.core_workloads.ocp4_workload_authorino for localhost => (item=agnosticd.core_workloads.ocp4_workload_authorino)
included: agnosticd.core_workloads.ocp4_workload_servicemesh2 for localhost => (item=agnosticd.core_workloads.ocp4_workload_servicemesh2)
included: agnosticd.ai_workloads.ocp4_workload_nvidia_gpu_operator for localhost => (item=agnosticd.ai_workloads.ocp4_workload_nvidia_gpu_operator)
included: agnosticd.ai_workloads.ocp4_workload_s3_model_copy_to_minio for localhost => (item=agnosticd.ai_workloads.ocp4_workload_s3_model_copy_to_minio)
included: agnosticd.ai_workloads.ocp4_workload_openshift_ai for localhost => (item=agnosticd.ai_workloads.ocp4_workload_openshift_ai)
included: agnosticd.core_workloads.ocp4_workload_gitops_bootstrap for localhost => (item=agnosticd.core_workloads.ocp4_workload_gitops_bootstrap)
included: agnosticd.core_workloads.ocp4_workload_showroom for localhost => (item=agnosticd.core_workloads.ocp4_workload_showroom)

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Running workload provision tasks] ***
Monday 04 August 2025  13:48:06 +0000 (0:00:00.198)       0:51:16.499 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_openshift_data_foundation/tasks/workload.yml for localhost

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Setting up workload] ***
Monday 04 August 2025  13:48:06 +0000 (0:00:00.038)       0:51:16.537 ********* 
ok: [localhost] => {
    "msg": "Setting up OpenShift Data Foundation"
}

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Define label_selector list] ***
Monday 04 August 2025  13:48:06 +0000 (0:00:00.020)       0:51:16.558 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Add to label_selector list] ***
Monday 04 August 2025  13:48:06 +0000 (0:00:00.020)       0:51:16.578 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Discovering worker nodes] ***
Monday 04 August 2025  13:48:06 +0000 (0:00:00.017)       0:51:16.596 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Fail for less than 3 worker nodes] ***
Monday 04 August 2025  13:48:06 +0000 (0:00:00.638)       0:51:17.234 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "More than 3 worker nodes. Continuing."
}

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Set variables] ***
Monday 04 August 2025  13:48:07 +0000 (0:00:00.035)       0:51:17.269 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Adding Ceph labels to worker nodes] ***
Monday 04 August 2025  13:48:07 +0000 (0:00:00.047)       0:51:17.317 ********* 
changed: [localhost] => (item=ip-10-0-18-79.us-east-2.compute.internal)
changed: [localhost] => (item=ip-10-0-32-78.us-east-2.compute.internal)
changed: [localhost] => (item=ip-10-0-89-150.us-east-2.compute.internal)
[WARNING]: unknown field "name"

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Create namespace openshift-storage] ***
Monday 04 August 2025  13:48:08 +0000 (0:00:01.930)       0:51:19.247 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Create CatalogSource] ***
Monday 04 August 2025  13:48:09 +0000 (0:00:00.605)       0:51:19.853 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Create OperatorGroup] ***
Monday 04 August 2025  13:48:10 +0000 (0:00:00.635)       0:51:20.489 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Create operator subscription] ***
Monday 04 August 2025  13:48:10 +0000 (0:00:00.622)       0:51:21.111 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Wait for the CRD storagesystems to become available] ***
Monday 04 August 2025  13:48:11 +0000 (0:00:00.649)       0:51:21.760 ********* 
FAILED - RETRYING: [localhost]: Wait for the CRD storagesystems to become available (200 retries left).
FAILED - RETRYING: [localhost]: Wait for the CRD storagesystems to become available (199 retries left).
FAILED - RETRYING: [localhost]: Wait for the CRD storagesystems to become available (198 retries left).
FAILED - RETRYING: [localhost]: Wait for the CRD storagesystems to become available (197 retries left).
FAILED - RETRYING: [localhost]: Wait for the CRD storagesystems to become available (196 retries left).
FAILED - RETRYING: [localhost]: Wait for the CRD storagesystems to become available (195 retries left).
FAILED - RETRYING: [localhost]: Wait for the CRD storagesystems to become available (194 retries left).
FAILED - RETRYING: [localhost]: Wait for the CRD storagesystems to become available (193 retries left).
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Wait for the CRD storagecluster to become available] ***
Monday 04 August 2025  13:49:36 +0000 (0:01:25.165)       0:52:46.926 ********* 
FAILED - RETRYING: [localhost]: Wait for the CRD storagecluster to become available (200 retries left).
FAILED - RETRYING: [localhost]: Wait for the CRD storagecluster to become available (199 retries left).
FAILED - RETRYING: [localhost]: Wait for the CRD storagecluster to become available (198 retries left).
FAILED - RETRYING: [localhost]: Wait for the CRD storagecluster to become available (197 retries left).
FAILED - RETRYING: [localhost]: Wait for the CRD storagecluster to become available (196 retries left).
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Wait for the console plugin to become available] ***
Monday 04 August 2025  13:50:30 +0000 (0:00:53.454)       0:53:40.381 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Enable ODF console plugin] ***
Monday 04 August 2025  13:50:30 +0000 (0:00:00.627)       0:53:41.009 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Create the ODF StorageCluster] ***
Monday 04 August 2025  13:50:31 +0000 (0:00:00.663)       0:53:41.672 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Create the ODF StorageSystem] ***
Monday 04 August 2025  13:50:32 +0000 (0:00:00.698)       0:53:42.371 ********* 
[WARNING]: metadata.finalizers: "storagesystem.odf.openshift.io": prefer a
domain-qualified finalizer name to avoid accidental conflicts with other
finalizer writers
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Wait for ODF Storage System to finish deploying] ***
Monday 04 August 2025  13:50:32 +0000 (0:00:00.671)       0:53:43.042 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Wait for ODF Storage Cluster to finish deploying] ***
Monday 04 August 2025  13:52:03 +0000 (0:01:30.668)       0:55:13.711 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Update Config Map rook-ceph-operator-config] ***
Monday 04 August 2025  13:53:44 +0000 (0:01:40.688)       0:56:54.399 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Delete DaemonSets to pick up modified ConfigMap] ***
Monday 04 August 2025  13:53:44 +0000 (0:00:00.029)       0:56:54.429 ********* 
skipping: [localhost] => (item=csi-cephfsplugin) 
skipping: [localhost] => (item=csi-rbdplugin) 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Restart Rook Ceph operator to redeploy DaemonSets] ***
Monday 04 August 2025  13:53:44 +0000 (0:00:00.034)       0:56:54.463 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Wait for the StorageClasses to become available] ***
Monday 04 August 2025  13:53:44 +0000 (0:00:00.028)       0:56:54.491 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Get all storage classes] ***
Monday 04 August 2025  13:53:44 +0000 (0:00:00.629)       0:56:55.121 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Remove default from previous default storage class] ***
Monday 04 August 2025  13:53:45 +0000 (0:00:00.571)       0:56:55.692 ********* 
skipping: [localhost] => (item=gp2-csi) 
changed: [localhost] => (item=gp3-csi)
skipping: [localhost] => (item=ocs-storagecluster-ceph-rbd) 
skipping: [localhost] => (item=ocs-storagecluster-cephfs) 

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Set new default storage class] ***
Monday 04 August 2025  13:53:46 +0000 (0:00:00.899)       0:56:56.592 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Deploy Ceph toolbox] ***
Monday 04 August 2025  13:53:47 +0000 (0:00:00.788)       0:56:57.380 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Running workload removal tasks] ***
Monday 04 August 2025  13:53:47 +0000 (0:00:00.026)       0:56:57.407 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Running workload provision tasks] ***
Monday 04 August 2025  13:53:47 +0000 (0:00:00.013)       0:56:57.421 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_machinesets/tasks/workload.yml for localhost

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Setup MachineConfigPools] ***
Monday 04 August 2025  13:53:47 +0000 (0:00:00.020)       0:56:57.442 ********* 
skipping: [localhost] => (item=worker-gpu) 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Configure OpenShift MachineSets] ***
Monday 04 August 2025  13:53:47 +0000 (0:00:00.032)       0:56:57.475 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_machinesets/tasks/machineset-setup.yml for localhost

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Set MachineSet facts] ***
Monday 04 August 2025  13:53:47 +0000 (0:00:00.017)       0:56:57.493 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_machinesets/tasks/machineset-set-facts.yml for localhost

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Get MachineSets] ****
Monday 04 August 2025  13:53:47 +0000 (0:00:00.020)       0:56:57.513 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Set _ocp4_workload_machinesets_base_worker_machinesets] ***
Monday 04 August 2025  13:53:47 +0000 (0:00:00.597)       0:56:58.111 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Print current MachineSets] ***
Monday 04 August 2025  13:53:47 +0000 (0:00:00.084)       0:56:58.196 ********* 
ok: [localhost] => {
    "_ocp4_workload_machinesets_current_machineset_names": [
        "ocp-2dsq5-worker-us-east-2a",
        "ocp-2dsq5-worker-us-east-2b",
        "ocp-2dsq5-worker-us-east-2c"
    ]
}

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Set cluster facts] ***
Monday 04 August 2025  13:53:47 +0000 (0:00:00.019)       0:56:58.215 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Debug cluster facts] ***
Monday 04 August 2025  13:53:48 +0000 (0:00:00.047)       0:56:58.262 ********* 
ok: [localhost] => (item={'label': 'Cluster Label', 'value': 'ocp-2dsq5'}) => {
    "msg": "Cluster Label: ocp-2dsq5"
}
ok: [localhost] => (item={'label': 'Cloud Provider API Version', 'value': 'machine.openshift.io/v1beta1'}) => {
    "msg": "Cloud Provider API Version: machine.openshift.io/v1beta1"
}
ok: [localhost] => (item={'label': 'Cloud Provider Platform', 'value': 'aws'}) => {
    "msg": "Cloud Provider Platform: aws"
}

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Disable base worker MachineSets] ***
Monday 04 August 2025  13:53:48 +0000 (0:00:00.030)       0:56:58.293 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Configure MachineSets for cloud provider] ***
Monday 04 August 2025  13:53:48 +0000 (0:00:00.025)       0:56:58.319 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_machinesets/tasks/machineset-aws.yml for localhost

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Define custom machinesets] ***
Monday 04 August 2025  13:53:48 +0000 (0:00:00.019)       0:56:58.338 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_machinesets/tasks/machineset-group-aws.yml for localhost => (item=worker-gpu)

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Get cluster version information] ***
Monday 04 August 2025  13:53:48 +0000 (0:00:00.024)       0:56:58.363 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Get cluster infrastructure information] ***
Monday 04 August 2025  13:53:48 +0000 (0:00:00.020)       0:56:58.384 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Get all MachineSets] ***
Monday 04 August 2025  13:53:48 +0000 (0:00:00.022)       0:56:58.406 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Extract all relevant information] ***
Monday 04 August 2025  13:53:48 +0000 (0:00:00.019)       0:56:58.426 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Debug cluster information] ***
Monday 04 August 2025  13:53:48 +0000 (0:00:00.021)       0:56:58.448 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Overwrite aws_coreos_ami_id] ***
Monday 04 August 2025  13:53:48 +0000 (0:00:00.021)       0:56:58.469 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Define worker-gpu machinesets] ***
Monday 04 August 2025  13:53:48 +0000 (0:00:00.019)       0:56:58.489 ********* 
changed: [localhost] => (item=ocp-2dsq5-worker-gpu-us-east-2c)
changed: [localhost] => (item=ocp-2dsq5-worker-gpu-us-east-2b)
changed: [localhost] => (item=ocp-2dsq5-worker-gpu-us-east-2a)
[WARNING]: unknown field "spec.template.spec.versions"

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Define worker-gpu machineautoscalers] ***
Monday 04 August 2025  13:53:50 +0000 (0:00:02.151)       0:57:00.641 ********* 
skipping: [localhost] => (item=ocp-2dsq5-worker-gpu-us-east-2c) 
skipping: [localhost] => (item=ocp-2dsq5-worker-gpu-us-east-2b) 
skipping: [localhost] => (item=ocp-2dsq5-worker-gpu-us-east-2a) 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Enable cluster autoscaler] ***
Monday 04 August 2025  13:53:50 +0000 (0:00:00.056)       0:57:00.698 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Wait for Nodes to be available] ***
Monday 04 August 2025  13:53:50 +0000 (0:00:00.039)       0:57:00.737 ********* 
skipping: [localhost] => (item={'autoscale': False, 'instance_type': 'g6e.2xlarge', 'name': 'worker-gpu', 'role': 'worker-gpu', 'taints': [{'effect': 'NoSchedule', 'key': 'nvidia.com/gpu', 'value': True}], 'total_replicas': 1, 'total_replicas_max': 2, 'total_replicas_min': 1}) 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Configure Ingress Controllers and Image Registry] ***
Monday 04 August 2025  13:53:50 +0000 (0:00:00.031)       0:57:00.769 ********* 
skipping: [localhost] => (item=ingress-controller.yaml.j2) 
skipping: [localhost] => (item=image-registry.yaml.j2) 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Create ConfigMap for Cluster Monitoring] ***
Monday 04 August 2025  13:53:50 +0000 (0:00:00.040)       0:57:00.810 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_machinesets : Running workload removal tasks] ***
Monday 04 August 2025  13:53:50 +0000 (0:00:00.038)       0:57:00.848 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Running workload provision tasks] ***
Monday 04 August 2025  13:53:50 +0000 (0:00:00.015)       0:57:00.863 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_cert_manager/tasks/workload.yml for localhost

TASK [Install Red Hat Cert Manager operator] ***********************************
Monday 04 August 2025  13:53:50 +0000 (0:00:00.031)       0:57:00.895 ********* 
included: install_operator for localhost

TASK [install_operator : Install the operator - openshift-cert-manager-operator] ***
Monday 04 August 2025  13:53:50 +0000 (0:00:00.037)       0:57:00.932 ********* 
included: /runner/project/ansible/roles/install_operator/tasks/install.yml for localhost

TASK [install_operator : Check that operator name has been provided] ***********
Monday 04 August 2025  13:53:50 +0000 (0:00:00.034)       0:57:00.967 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [install_operator : Check that starting CSV also has autoapprove set to false] ***
Monday 04 August 2025  13:53:50 +0000 (0:00:00.036)       0:57:01.003 ********* 
skipping: [localhost]

TASK [install_operator : Ensure Namespace exists (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:53:50 +0000 (0:00:00.031)       0:57:01.035 ********* 
changed: [localhost]

TASK [install_operator : Ensure OperatorGroup exists (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:53:51 +0000 (0:00:00.594)       0:57:01.630 ********* 
changed: [localhost]

TASK [install_operator : Create CatalogSource for use with catalog snapshot (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:53:52 +0000 (0:00:00.681)       0:57:02.311 ********* 
changed: [localhost]

TASK [install_operator : Set subscription channel to provided channel (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:53:52 +0000 (0:00:00.768)       0:57:03.079 ********* 
ok: [localhost]

TASK [install_operator : Get cluster version] **********************************
Monday 04 August 2025  13:53:52 +0000 (0:00:00.034)       0:57:03.114 ********* 
skipping: [localhost]

TASK [install_operator : Get PackageManifest for the operator (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:53:52 +0000 (0:00:00.034)       0:57:03.148 ********* 
skipping: [localhost]

TASK [install_operator : Set operator channel (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:53:52 +0000 (0:00:00.035)       0:57:03.184 ********* 
skipping: [localhost]

TASK [install_operator : Print operator channel to be installed (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:53:52 +0000 (0:00:00.032)       0:57:03.216 ********* 
ok: [localhost] => {
    "msg": "Operator channel to be installed: stable-v1"
}

TASK [install_operator : Create operator subscription (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:53:52 +0000 (0:00:00.020)       0:57:03.236 ********* 
changed: [localhost]

TASK [install_operator : Wait until InstallPlan is created (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:53:53 +0000 (0:00:00.734)       0:57:03.971 ********* 
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-cert-manager-operator) (100 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-cert-manager-operator) (99 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-cert-manager-operator) (98 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-cert-manager-operator) (97 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-cert-manager-operator) (96 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-cert-manager-operator) (95 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-cert-manager-operator) (94 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-cert-manager-operator) (93 retries left).
ok: [localhost]

TASK [install_operator : Set InstallPlan name (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:55:18 +0000 (0:01:25.147)       0:58:29.119 ********* 
ok: [localhost]

TASK [install_operator : Print InstallPlan (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:55:18 +0000 (0:00:00.089)       0:58:29.209 ********* 
ok: [localhost] => {
    "msg": "InstallPlan: install-rzb2r"
}

TASK [install_operator : Get InstallPlan (openshift-cert-manager-operator)] ****
Monday 04 August 2025  13:55:18 +0000 (0:00:00.017)       0:58:29.226 ********* 
ok: [localhost]

TASK [install_operator : Approve InstallPlan if necessary (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:55:19 +0000 (0:00:00.628)       0:58:29.854 ********* 
skipping: [localhost]

TASK [install_operator : Get Installed CSV (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:55:19 +0000 (0:00:00.019)       0:58:29.873 ********* 
ok: [localhost]

TASK [install_operator : Print CSV version to be installed (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:55:20 +0000 (0:00:00.691)       0:58:30.565 ********* 
ok: [localhost] => {
    "msg": "Starting CSV: "
}

TASK [install_operator : Wait until CSV is installed (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:55:20 +0000 (0:00:00.071)       0:58:30.637 ********* 
ok: [localhost]

TASK [install_operator : Remove the operator - openshift-cert-manager-operator] ***
Monday 04 August 2025  13:55:21 +0000 (0:00:00.779)       0:58:31.416 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Update CertManager for AWS/GCP/Azure to use external DNS] ***
Monday 04 August 2025  13:55:21 +0000 (0:00:00.016)       0:58:31.433 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Set DNS facts] *****
Monday 04 August 2025  13:55:21 +0000 (0:00:00.761)       0:58:32.195 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Print API and wildcard domain] ***
Monday 04 August 2025  13:55:21 +0000 (0:00:00.019)       0:58:32.214 ********* 
ok: [localhost] => {
    "msg": "API: api.ocp.76x7m.sandbox1795.opentlc.com, Wildcard Domain: *.apps.ocp.76x7m.sandbox1795.opentlc.com"
}

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Wait until CertManager is ready] ***
Monday 04 August 2025  13:55:21 +0000 (0:00:00.017)       0:58:32.231 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Create ZeroSSL credentials secret for cert manager] ***
Monday 04 August 2025  13:55:42 +0000 (0:00:20.708)       0:58:52.939 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Set up cloud provider specific prerequisites for cert manager] ***
Monday 04 August 2025  13:55:43 +0000 (0:00:00.659)       0:58:53.599 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_cert_manager/tasks/cert_manager_aws.yml for localhost

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Use provided HostedZoneID] ***
Monday 04 August 2025  13:55:43 +0000 (0:00:00.026)       0:58:53.625 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Get HostedZoneID] ***
Monday 04 August 2025  13:55:43 +0000 (0:00:00.036)       0:58:53.662 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Set HostedZoneID fact] ***
Monday 04 August 2025  13:55:44 +0000 (0:00:00.595)       0:58:54.258 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Print HostedZoneID] ***
Monday 04 August 2025  13:55:44 +0000 (0:00:00.037)       0:58:54.295 ********* 
ok: [localhost] => {
    "msg": "HostedZoneID: Z05021841TLC4IN6Y6PV4"
}

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Create AWS credentials secret for cert manager] ***
Monday 04 August 2025  13:55:44 +0000 (0:00:00.017)       0:58:54.312 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Set up ClusterIssuer and request certificates] ***
Monday 04 August 2025  13:55:44 +0000 (0:00:00.660)       0:58:54.973 ********* 
FAILED - RETRYING: [localhost]: Set up ClusterIssuer and request certificates (10 retries left).
changed: [localhost] => (item=clusterissuer.yaml.j2)
changed: [localhost] => (item=certificate-ingress.yaml.j2)
changed: [localhost] => (item=certificate-api.yaml.j2)

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Run ingress controller certificate check task] ***
Monday 04 August 2025  13:56:17 +0000 (0:00:32.618)       0:59:27.591 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_cert_manager/tasks/cert_manager_ingress_cert_check.yml for localhost => (item=0)
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_cert_manager/tasks/cert_manager_ingress_cert_check.yml for localhost => (item=1)
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_cert_manager/tasks/cert_manager_ingress_cert_check.yml for localhost => (item=2)
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_cert_manager/tasks/cert_manager_ingress_cert_check.yml for localhost => (item=3)

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Wait until Ingress Certificate is ready] ***
Monday 04 August 2025  13:56:17 +0000 (0:00:00.056)       0:59:27.648 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Mark certificate ready] ***
Monday 04 August 2025  14:00:58 +0000 (0:04:40.927)       1:04:08.575 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Wait until Ingress Certificate is ready] ***
Monday 04 August 2025  14:00:58 +0000 (0:00:00.034)       1:04:08.609 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Mark certificate ready] ***
Monday 04 August 2025  14:00:58 +0000 (0:00:00.030)       1:04:08.639 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Wait until Ingress Certificate is ready] ***
Monday 04 August 2025  14:00:58 +0000 (0:00:00.034)       1:04:08.674 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Mark certificate ready] ***
Monday 04 August 2025  14:00:58 +0000 (0:00:00.032)       1:04:08.706 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Wait until Ingress Certificate is ready] ***
Monday 04 August 2025  14:00:58 +0000 (0:00:00.036)       1:04:08.742 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Mark certificate ready] ***
Monday 04 August 2025  14:00:58 +0000 (0:00:00.033)       1:04:08.776 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Update Ingress controller to use certificate] ***
Monday 04 August 2025  14:00:58 +0000 (0:00:00.046)       1:04:08.822 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Run API certificate check task] ***
Monday 04 August 2025  14:00:59 +0000 (0:00:00.745)       1:04:09.567 ********* 
skipping: [localhost] => (item=0) 
skipping: [localhost] => (item=1) 
skipping: [localhost] => (item=2) 
skipping: [localhost] => (item=3) 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Update API server to use certificate] ***
Monday 04 August 2025  14:00:59 +0000 (0:00:00.035)       1:04:09.603 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Wait for Cluster Operator kube-apiserver to finish rolling out] ***
Monday 04 August 2025  14:00:59 +0000 (0:00:00.026)       1:04:09.629 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Find all Kube configs] ***
Monday 04 August 2025  14:00:59 +0000 (0:00:00.026)       1:04:09.656 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Fix Kube configs] ***
Monday 04 August 2025  14:00:59 +0000 (0:00:00.027)       1:04:09.684 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Make sure API calls succeed] ***
Monday 04 August 2025  14:00:59 +0000 (0:00:00.027)       1:04:09.711 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_cert_manager : Running workload removal tasks] ***
Monday 04 August 2025  14:00:59 +0000 (0:00:00.026)       1:04:09.738 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Running workload provision tasks] ***
Monday 04 August 2025  14:00:59 +0000 (0:00:00.016)       1:04:09.755 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_authentication_rhsso/tasks/workload.yml for localhost

TASK [Install rhsso operator] **************************************************
Monday 04 August 2025  14:00:59 +0000 (0:00:00.033)       1:04:09.788 ********* 
included: install_operator for localhost

TASK [install_operator : Install the operator - rhsso-operator] ****************
Monday 04 August 2025  14:00:59 +0000 (0:00:00.028)       1:04:09.817 ********* 
included: /runner/project/ansible/roles/install_operator/tasks/install.yml for localhost

TASK [install_operator : Check that operator name has been provided] ***********
Monday 04 August 2025  14:00:59 +0000 (0:00:00.028)       1:04:09.846 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [install_operator : Check that starting CSV also has autoapprove set to false] ***
Monday 04 August 2025  14:00:59 +0000 (0:00:00.034)       1:04:09.881 ********* 
skipping: [localhost]

TASK [install_operator : Ensure Namespace exists (rhsso-operator)] *************
Monday 04 August 2025  14:00:59 +0000 (0:00:00.031)       1:04:09.912 ********* 
changed: [localhost]

TASK [install_operator : Ensure OperatorGroup exists (rhsso-operator)] *********
Monday 04 August 2025  14:01:00 +0000 (0:00:00.598)       1:04:10.510 ********* 
changed: [localhost]

TASK [install_operator : Create CatalogSource for use with catalog snapshot (rhsso-operator)] ***
Monday 04 August 2025  14:01:00 +0000 (0:00:00.688)       1:04:11.198 ********* 
changed: [localhost]

TASK [install_operator : Set subscription channel to provided channel (rhsso-operator)] ***
Monday 04 August 2025  14:01:01 +0000 (0:00:00.655)       1:04:11.854 ********* 
ok: [localhost]

TASK [install_operator : Get cluster version] **********************************
Monday 04 August 2025  14:01:01 +0000 (0:00:00.034)       1:04:11.889 ********* 
skipping: [localhost]

TASK [install_operator : Get PackageManifest for the operator (rhsso-operator)] ***
Monday 04 August 2025  14:01:01 +0000 (0:00:00.031)       1:04:11.920 ********* 
skipping: [localhost]

TASK [install_operator : Set operator channel (rhsso-operator)] ****************
Monday 04 August 2025  14:01:01 +0000 (0:00:00.032)       1:04:11.952 ********* 
skipping: [localhost]

TASK [install_operator : Print operator channel to be installed (rhsso-operator)] ***
Monday 04 August 2025  14:01:01 +0000 (0:00:00.031)       1:04:11.984 ********* 
ok: [localhost] => {
    "msg": "Operator channel to be installed: stable"
}

TASK [install_operator : Create operator subscription (rhsso-operator)] ********
Monday 04 August 2025  14:01:01 +0000 (0:00:00.019)       1:04:12.003 ********* 
changed: [localhost]

TASK [install_operator : Wait until InstallPlan is created (rhsso-operator)] ***
Monday 04 August 2025  14:01:02 +0000 (0:00:00.662)       1:04:12.665 ********* 
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (rhsso-operator) (100 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (rhsso-operator) (99 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (rhsso-operator) (98 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (rhsso-operator) (97 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (rhsso-operator) (96 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (rhsso-operator) (95 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (rhsso-operator) (94 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (rhsso-operator) (93 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (rhsso-operator) (92 retries left).
ok: [localhost]

TASK [install_operator : Set InstallPlan name (rhsso-operator)] ****************
Monday 04 August 2025  14:02:38 +0000 (0:01:35.643)       1:05:48.308 ********* 
ok: [localhost]

TASK [install_operator : Print InstallPlan (rhsso-operator)] *******************
Monday 04 August 2025  14:02:38 +0000 (0:00:00.048)       1:05:48.357 ********* 
ok: [localhost] => {
    "msg": "InstallPlan: install-ljd5l"
}

TASK [install_operator : Get InstallPlan (rhsso-operator)] *********************
Monday 04 August 2025  14:02:38 +0000 (0:00:00.019)       1:05:48.376 ********* 
ok: [localhost]

TASK [install_operator : Approve InstallPlan if necessary (rhsso-operator)] ****
Monday 04 August 2025  14:02:38 +0000 (0:00:00.576)       1:05:48.952 ********* 
skipping: [localhost]

TASK [install_operator : Get Installed CSV (rhsso-operator)] *******************
Monday 04 August 2025  14:02:38 +0000 (0:00:00.017)       1:05:48.970 ********* 
ok: [localhost]

TASK [install_operator : Print CSV version to be installed (rhsso-operator)] ***
Monday 04 August 2025  14:02:39 +0000 (0:00:00.615)       1:05:49.585 ********* 
ok: [localhost] => {
    "msg": "Starting CSV: "
}

TASK [install_operator : Wait until CSV is installed (rhsso-operator)] *********
Monday 04 August 2025  14:02:39 +0000 (0:00:00.025)       1:05:49.611 ********* 
ok: [localhost]

TASK [install_operator : Remove the operator - rhsso-operator] *****************
Monday 04 August 2025  14:02:40 +0000 (0:00:00.646)       1:05:50.257 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Generate cluster admin password] ***
Monday 04 August 2025  14:02:40 +0000 (0:00:00.014)       1:05:50.272 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Use provided admin password] ***
Monday 04 August 2025  14:02:40 +0000 (0:00:00.034)       1:05:50.307 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Generate user password] ***
Monday 04 August 2025  14:02:40 +0000 (0:00:00.040)       1:05:50.347 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Use provided user password] ***
Monday 04 August 2025  14:02:40 +0000 (0:00:00.033)       1:05:50.381 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Set facts] ***
Monday 04 August 2025  14:02:40 +0000 (0:00:00.039)       1:05:50.421 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Create RHSSO resources] ***
Monday 04 August 2025  14:02:40 +0000 (0:00:00.019)       1:05:50.441 ********* 
changed: [localhost] => (item=rhsso-instance.yml.j2)
changed: [localhost] => (item=rhsso-realm-openshift.yml.j2)
changed: [localhost] => (item=rhsso-client-openshift.yml.j2)

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Retrieve OpenShift realm client credentials] ***
Monday 04 August 2025  14:02:42 +0000 (0:00:02.120)       1:05:52.561 ********* 
FAILED - RETRYING: [localhost]: Retrieve OpenShift realm client credentials (120 retries left).
FAILED - RETRYING: [localhost]: Retrieve OpenShift realm client credentials (119 retries left).
FAILED - RETRYING: [localhost]: Retrieve OpenShift realm client credentials (118 retries left).
FAILED - RETRYING: [localhost]: Retrieve OpenShift realm client credentials (117 retries left).
FAILED - RETRYING: [localhost]: Retrieve OpenShift realm client credentials (116 retries left).
FAILED - RETRYING: [localhost]: Retrieve OpenShift realm client credentials (115 retries left).
FAILED - RETRYING: [localhost]: Retrieve OpenShift realm client credentials (114 retries left).
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Decode OpenShift realm client secret] ***
Monday 04 August 2025  14:03:56 +0000 (0:01:14.462)       1:07:07.024 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Create OpenShift auth resources] ***
Monday 04 August 2025  14:03:56 +0000 (0:00:00.032)       1:07:07.056 ********* 
changed: [localhost] => (item=openshift-openid-client-secret.yml.j2)
changed: [localhost] => (item=openshift-oauth.yml.j2)

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Create OpenShift identity provider (rosa)] ***
Monday 04 August 2025  14:03:58 +0000 (0:00:01.382)       1:07:08.439 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Creating admin user] ***
Monday 04 August 2025  14:03:58 +0000 (0:00:00.031)       1:07:08.471 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Create cluster admin role binding] ***
Monday 04 August 2025  14:03:58 +0000 (0:00:00.719)       1:07:09.190 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Create users] ***
Monday 04 August 2025  14:03:59 +0000 (0:00:00.682)       1:07:09.873 ********* 
changed: [localhost] => (item=0)

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Retrieve RHSSO admin credentials] ***
Monday 04 August 2025  14:04:00 +0000 (0:00:00.681)       1:07:10.555 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Remove kubeadmin user] ***
Monday 04 August 2025  14:04:00 +0000 (0:00:00.604)       1:07:11.159 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Save user information messages] ***
Monday 04 August 2025  14:04:01 +0000 (0:00:00.650)       1:07:11.810 ********* 
ok: [localhost] => {
    "changed": false,
    "data": {
        "openshift_api_server_url": "api.ocp.76x7m.sandbox1795.opentlc.com",
        "openshift_cluster_console_url": "console-openshift-console.apps.ocp.76x7m.sandbox1795.opentlc.com",
        "openshift_cluster_num_users": "1",
        "openshift_cluster_user_base": "user",
        "openshift_cluster_user_count": "1",
        "rhsso_admin_console": "keycloak-rhsso.apps.ocp.76x7m.sandbox1795.opentlc.com",
        "rhsso_admin_password": "[REDACTED_Secret Keyword_SECRET]",
        "rhsso_admin_user": "admin"
    },
    "msg": "user.info: Authentication via RHSSO is enabled on this cluster. RHSSO admin console: https://keycloak-rhsso.apps.ocp.76x7m.sandbox1795.opentlc.com RHSSO admin user: admin RHSSO admin password: REDACTED_SECRET
}

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Save admin information] ***
Monday 04 August 2025  14:04:01 +0000 (0:00:00.050)       1:07:11.861 ********* 
ok: [localhost] => {
    "changed": false,
    "data": {
        "openshift_cluster_admin_password": "[REDACTED_Secret Keyword_SECRET]",
        "openshift_cluster_admin_username": "admin"
    },
    "msg": "user.info: User 'admin' with password 'MzIyNTU2' is cluster admin."
}

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Print user information] ***
Monday 04 August 2025  14:04:01 +0000 (0:00:00.058)       1:07:11.919 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "user.info: Users `user1` .. `user1` created with password `MjI1NTgz`"
}

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Save user information for user access] ***
Monday 04 August 2025  14:04:01 +0000 (0:00:00.046)       1:07:11.965 ********* 
ok: [localhost] => (item=0) => {
    "ansible_loop_var": "n",
    "changed": false,
    "data": {
        "console_url": "console-openshift-console.apps.ocp.76x7m.sandbox1795.opentlc.com",
        "login_command": "oc login --insecure-skip-tls-verify=false --username user1 --password MjI1NTgz api.ocp.76x7m.sandbox1795.opentlc.com",
        "openshift_cluster_ingress_domain": "apps.ocp.76x7m.sandbox1795.opentlc.com",
        "openshift_console_url": "https://console-openshift-console.apps.ocp.76x7m.sandbox1795.opentlc.com",
        "password": "[REDACTED_Secret Keyword_SECRET]",
        "user": "user1"
    },
    "n": 0,
    "user": "user1"
}

TASK [agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Running workload removal tasks] ***
Monday 04 August 2025  14:04:01 +0000 (0:00:00.051)       1:07:12.016 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Running workload provision tasks] ***
Monday 04 August 2025  14:04:01 +0000 (0:00:00.016)       1:07:12.033 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_serverless/tasks/workload.yml for localhost

TASK [Install Operator] ********************************************************
Monday 04 August 2025  14:04:01 +0000 (0:00:00.026)       1:07:12.060 ********* 
included: install_operator for localhost

TASK [install_operator : Install the operator - serverless-operator] ***********
Monday 04 August 2025  14:04:01 +0000 (0:00:00.019)       1:07:12.079 ********* 
included: /runner/project/ansible/roles/install_operator/tasks/install.yml for localhost

TASK [install_operator : Check that operator name has been provided] ***********
Monday 04 August 2025  14:04:01 +0000 (0:00:00.026)       1:07:12.105 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [install_operator : Check that starting CSV also has autoapprove set to false] ***
Monday 04 August 2025  14:04:01 +0000 (0:00:00.043)       1:07:12.149 ********* 
skipping: [localhost]

TASK [install_operator : Ensure Namespace exists (serverless-operator)] ********
Monday 04 August 2025  14:04:01 +0000 (0:00:00.041)       1:07:12.191 ********* 
changed: [localhost]

TASK [install_operator : Ensure OperatorGroup exists (serverless-operator)] ****
Monday 04 August 2025  14:04:02 +0000 (0:00:00.616)       1:07:12.807 ********* 
changed: [localhost]

TASK [install_operator : Create CatalogSource for use with catalog snapshot (serverless-operator)] ***
Monday 04 August 2025  14:04:03 +0000 (0:00:00.675)       1:07:13.482 ********* 
changed: [localhost]

TASK [install_operator : Set subscription channel to provided channel (serverless-operator)] ***
Monday 04 August 2025  14:04:03 +0000 (0:00:00.693)       1:07:14.175 ********* 
ok: [localhost]

TASK [install_operator : Get cluster version] **********************************
Monday 04 August 2025  14:04:03 +0000 (0:00:00.036)       1:07:14.212 ********* 
skipping: [localhost]

TASK [install_operator : Get PackageManifest for the operator (serverless-operator)] ***
Monday 04 August 2025  14:04:03 +0000 (0:00:00.032)       1:07:14.244 ********* 
skipping: [localhost]

TASK [install_operator : Set operator channel (serverless-operator)] ***********
Monday 04 August 2025  14:04:04 +0000 (0:00:00.030)       1:07:14.275 ********* 
skipping: [localhost]

TASK [install_operator : Print operator channel to be installed (serverless-operator)] ***
Monday 04 August 2025  14:04:04 +0000 (0:00:00.031)       1:07:14.306 ********* 
ok: [localhost] => {
    "msg": "Operator channel to be installed: stable"
}

TASK [install_operator : Create operator subscription (serverless-operator)] ***
Monday 04 August 2025  14:04:04 +0000 (0:00:00.021)       1:07:14.328 ********* 
changed: [localhost]

TASK [install_operator : Wait until InstallPlan is created (serverless-operator)] ***
Monday 04 August 2025  14:04:04 +0000 (0:00:00.670)       1:07:14.999 ********* 
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (serverless-operator) (100 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (serverless-operator) (99 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (serverless-operator) (98 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (serverless-operator) (97 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (serverless-operator) (96 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (serverless-operator) (95 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (serverless-operator) (94 retries left).
ok: [localhost]

TASK [install_operator : Set InstallPlan name (serverless-operator)] ***********
Monday 04 August 2025  14:05:19 +0000 (0:01:14.677)       1:08:29.676 ********* 
ok: [localhost]

TASK [install_operator : Print InstallPlan (serverless-operator)] **************
Monday 04 August 2025  14:05:19 +0000 (0:00:00.047)       1:08:29.724 ********* 
ok: [localhost] => {
    "msg": "InstallPlan: install-r7msc"
}

TASK [install_operator : Get InstallPlan (serverless-operator)] ****************
Monday 04 August 2025  14:05:19 +0000 (0:00:00.019)       1:08:29.743 ********* 
ok: [localhost]

TASK [install_operator : Approve InstallPlan if necessary (serverless-operator)] ***
Monday 04 August 2025  14:05:20 +0000 (0:00:00.591)       1:08:30.334 ********* 
skipping: [localhost]

TASK [install_operator : Get Installed CSV (serverless-operator)] **************
Monday 04 August 2025  14:05:20 +0000 (0:00:00.018)       1:08:30.353 ********* 
ok: [localhost]

TASK [install_operator : Print CSV version to be installed (serverless-operator)] ***
Monday 04 August 2025  14:05:20 +0000 (0:00:00.596)       1:08:30.950 ********* 
ok: [localhost] => {
    "msg": "Starting CSV: "
}

TASK [install_operator : Wait until CSV is installed (serverless-operator)] ****
Monday 04 August 2025  14:05:20 +0000 (0:00:00.026)       1:08:30.977 ********* 
FAILED - RETRYING: [localhost]: Wait until CSV is installed (serverless-operator) (30 retries left).
ok: [localhost]

TASK [install_operator : Remove the operator - serverless-operator] ************
Monday 04 August 2025  14:05:31 +0000 (0:00:11.241)       1:08:42.218 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Create knative-serving namespace] ***
Monday 04 August 2025  14:05:31 +0000 (0:00:00.015)       1:08:42.233 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Create KNative Serving object] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.029)       1:08:42.262 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Wait until KNative Serving installation is complete] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.028)       1:08:42.290 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Create knative-eventing namespace] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.034)       1:08:42.325 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Create knative-eventing namespace and KNative Eventing object] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.037)       1:08:42.362 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Wait until KNative Eventing installation is complete] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.031)       1:08:42.394 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Get kn ConsoleCLIDownload] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.030)       1:08:42.424 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Get kn download URL from ConsoleCLIDownload] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.030)       1:08:42.454 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Get kn download route] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.030)       1:08:42.485 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Get kn download URL from Route] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.030)       1:08:42.515 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Download kn cli tool] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.030)       1:08:42.545 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Install kn CLI on bastion] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.043)       1:08:42.589 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Remove downloaded file] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.038)       1:08:42.628 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Create kn bash completion file] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.036)       1:08:42.664 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_serverless : Running workload removal tasks] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.033)       1:08:42.698 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_pipelines : Running workload provision tasks] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.014)       1:08:42.713 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_pipelines/tasks/workload.yml for localhost

TASK [Install OpenShift Pipelines operator] ************************************
Monday 04 August 2025  14:05:32 +0000 (0:00:00.022)       1:08:42.735 ********* 
included: install_operator for localhost

TASK [install_operator : Install the operator - openshift-pipelines-operator] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.020)       1:08:42.755 ********* 
included: /runner/project/ansible/roles/install_operator/tasks/install.yml for localhost

TASK [install_operator : Check that operator name has been provided] ***********
Monday 04 August 2025  14:05:32 +0000 (0:00:00.027)       1:08:42.782 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [install_operator : Check that starting CSV also has autoapprove set to false] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.040)       1:08:42.822 ********* 
skipping: [localhost]

TASK [install_operator : Ensure Namespace exists (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.046)       1:08:42.869 ********* 
skipping: [localhost]

TASK [install_operator : Ensure OperatorGroup exists (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.017)       1:08:42.887 ********* 
skipping: [localhost]

TASK [install_operator : Create CatalogSource for use with catalog snapshot (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:05:32 +0000 (0:00:00.015)       1:08:42.903 ********* 
changed: [localhost]

TASK [install_operator : Set subscription channel to provided channel (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:05:33 +0000 (0:00:00.694)       1:08:43.597 ********* 
ok: [localhost]

TASK [install_operator : Get cluster version] **********************************
Monday 04 August 2025  14:05:33 +0000 (0:00:00.037)       1:08:43.635 ********* 
skipping: [localhost]

TASK [install_operator : Get PackageManifest for the operator (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:05:33 +0000 (0:00:00.031)       1:08:43.666 ********* 
skipping: [localhost]

TASK [install_operator : Set operator channel (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:05:33 +0000 (0:00:00.031)       1:08:43.698 ********* 
skipping: [localhost]

TASK [install_operator : Print operator channel to be installed (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:05:33 +0000 (0:00:00.032)       1:08:43.730 ********* 
ok: [localhost] => {
    "msg": "Operator channel to be installed: pipelines-1.15"
}

TASK [install_operator : Create operator subscription (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:05:33 +0000 (0:00:00.018)       1:08:43.748 ********* 
changed: [localhost]

TASK [install_operator : Wait until InstallPlan is created (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:05:34 +0000 (0:00:00.702)       1:08:44.451 ********* 
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-pipelines-operator) (100 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-pipelines-operator) (99 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-pipelines-operator) (98 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-pipelines-operator) (97 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-pipelines-operator) (96 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-pipelines-operator) (95 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-pipelines-operator) (94 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-pipelines-operator) (93 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-pipelines-operator) (92 retries left).
ok: [localhost]

TASK [install_operator : Set InstallPlan name (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:07:10 +0000 (0:01:35.815)       1:10:20.266 ********* 
ok: [localhost]

TASK [install_operator : Print InstallPlan (openshift-pipelines-operator)] *****
Monday 04 August 2025  14:07:10 +0000 (0:00:00.050)       1:10:20.317 ********* 
ok: [localhost] => {
    "msg": "InstallPlan: install-w28z2"
}

TASK [install_operator : Get InstallPlan (openshift-pipelines-operator)] *******
Monday 04 August 2025  14:07:10 +0000 (0:00:00.018)       1:10:20.335 ********* 
ok: [localhost]

TASK [install_operator : Approve InstallPlan if necessary (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:07:10 +0000 (0:00:00.583)       1:10:20.919 ********* 
skipping: [localhost]

TASK [install_operator : Get Installed CSV (openshift-pipelines-operator)] *****
Monday 04 August 2025  14:07:10 +0000 (0:00:00.019)       1:10:20.939 ********* 
ok: [localhost]

TASK [install_operator : Print CSV version to be installed (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:07:11 +0000 (0:00:00.609)       1:10:21.549 ********* 
ok: [localhost] => {
    "msg": "Starting CSV: "
}

TASK [install_operator : Wait until CSV is installed (openshift-pipelines-operator)] ***
Monday 04 August 2025  14:07:11 +0000 (0:00:00.024)       1:10:21.574 ********* 
FAILED - RETRYING: [localhost]: Wait until CSV is installed (openshift-pipelines-operator) (30 retries left).
FAILED - RETRYING: [localhost]: Wait until CSV is installed (openshift-pipelines-operator) (29 retries left).
ok: [localhost]

TASK [install_operator : Remove the operator - openshift-pipelines-operator] ***
Monday 04 August 2025  14:07:33 +0000 (0:00:21.916)       1:10:43.491 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_pipelines : Wait until pipeline controller pods are ready] ***
Monday 04 August 2025  14:07:33 +0000 (0:00:00.016)       1:10:43.507 ********* 
FAILED - RETRYING: [localhost]: Wait until pipeline controller pods are ready (40 retries left).
FAILED - RETRYING: [localhost]: Wait until pipeline controller pods are ready (39 retries left).
FAILED - RETRYING: [localhost]: Wait until pipeline controller pods are ready (38 retries left).
FAILED - RETRYING: [localhost]: Wait until pipeline controller pods are ready (37 retries left).
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_pipelines : Wait until tkn cli download deployment is ready] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:42.926)       1:11:26.434 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_pipelines : Get tkn ConsoleCLIDownload] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.032)       1:11:26.466 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_pipelines : Get tkn download URL from ConsoleCLIDownload] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.030)       1:11:26.497 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_pipelines : Download tkn cli tool] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.031)       1:11:26.529 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_pipelines : Install tkn CLI on bastion] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.037)       1:11:26.566 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_pipelines : Remove downloaded file] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.037)       1:11:26.603 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_pipelines : Setup tkn bash completion] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.034)       1:11:26.637 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_pipelines : Setup tkn-pac bash completion] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.043)       1:11:26.681 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_pipelines : Running workload removal tasks] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.038)       1:11:26.719 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_gitops : Running workload provision tasks] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.015)       1:11:26.734 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_openshift_gitops/tasks/workload.yml for localhost

TASK [agnosticd.core_workloads.ocp4_workload_openshift_gitops : Set _ocp4_workload_openshift_gitops_domain] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.023)       1:11:26.757 ********* 
ok: [localhost]

TASK [Install OpenShift GitOps operator] ***************************************
Monday 04 August 2025  14:08:16 +0000 (0:00:00.018)       1:11:26.776 ********* 
included: install_operator for localhost

TASK [install_operator : Install the operator - openshift-gitops-operator] *****
Monday 04 August 2025  14:08:16 +0000 (0:00:00.024)       1:11:26.801 ********* 
included: /runner/project/ansible/roles/install_operator/tasks/install.yml for localhost

TASK [install_operator : Check that operator name has been provided] ***********
Monday 04 August 2025  14:08:16 +0000 (0:00:00.033)       1:11:26.834 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [install_operator : Check that starting CSV also has autoapprove set to false] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.041)       1:11:26.875 ********* 
skipping: [localhost]

TASK [install_operator : Ensure Namespace exists (openshift-gitops-operator)] ***
Monday 04 August 2025  14:08:16 +0000 (0:00:00.043)       1:11:26.919 ********* 
changed: [localhost]

TASK [install_operator : Ensure OperatorGroup exists (openshift-gitops-operator)] ***
Monday 04 August 2025  14:08:17 +0000 (0:00:00.648)       1:11:27.567 ********* 
changed: [localhost]

TASK [install_operator : Create CatalogSource for use with catalog snapshot (openshift-gitops-operator)] ***
Monday 04 August 2025  14:08:18 +0000 (0:00:00.782)       1:11:28.350 ********* 
changed: [localhost]

TASK [install_operator : Set subscription channel to provided channel (openshift-gitops-operator)] ***
Monday 04 August 2025  14:08:18 +0000 (0:00:00.805)       1:11:29.155 ********* 
ok: [localhost]

TASK [install_operator : Get cluster version] **********************************
Monday 04 August 2025  14:08:18 +0000 (0:00:00.039)       1:11:29.195 ********* 
skipping: [localhost]

TASK [install_operator : Get PackageManifest for the operator (openshift-gitops-operator)] ***
Monday 04 August 2025  14:08:18 +0000 (0:00:00.034)       1:11:29.229 ********* 
skipping: [localhost]

TASK [install_operator : Set operator channel (openshift-gitops-operator)] *****
Monday 04 August 2025  14:08:19 +0000 (0:00:00.034)       1:11:29.264 ********* 
skipping: [localhost]

TASK [install_operator : Print operator channel to be installed (openshift-gitops-operator)] ***
Monday 04 August 2025  14:08:19 +0000 (0:00:00.034)       1:11:29.299 ********* 
ok: [localhost] => {
    "msg": "Operator channel to be installed: gitops-1.15"
}

TASK [install_operator : Create operator subscription (openshift-gitops-operator)] ***
Monday 04 August 2025  14:08:19 +0000 (0:00:00.019)       1:11:29.318 ********* 
changed: [localhost]

TASK [install_operator : Wait until InstallPlan is created (openshift-gitops-operator)] ***
Monday 04 August 2025  14:08:19 +0000 (0:00:00.795)       1:11:30.113 ********* 
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-gitops-operator) (100 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-gitops-operator) (99 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-gitops-operator) (98 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-gitops-operator) (97 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-gitops-operator) (96 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-gitops-operator) (95 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-gitops-operator) (94 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (openshift-gitops-operator) (93 retries left).
ok: [localhost]

TASK [install_operator : Set InstallPlan name (openshift-gitops-operator)] *****
Monday 04 August 2025  14:09:44 +0000 (0:01:24.964)       1:12:55.078 ********* 
ok: [localhost]

TASK [install_operator : Print InstallPlan (openshift-gitops-operator)] ********
Monday 04 August 2025  14:09:44 +0000 (0:00:00.047)       1:12:55.125 ********* 
ok: [localhost] => {
    "msg": "InstallPlan: install-rkvpj"
}

TASK [install_operator : Get InstallPlan (openshift-gitops-operator)] **********
Monday 04 August 2025  14:09:44 +0000 (0:00:00.017)       1:12:55.142 ********* 
ok: [localhost]

TASK [install_operator : Approve InstallPlan if necessary (openshift-gitops-operator)] ***
Monday 04 August 2025  14:09:45 +0000 (0:00:00.582)       1:12:55.725 ********* 
skipping: [localhost]

TASK [install_operator : Get Installed CSV (openshift-gitops-operator)] ********
Monday 04 August 2025  14:09:45 +0000 (0:00:00.017)       1:12:55.743 ********* 
ok: [localhost]

TASK [install_operator : Print CSV version to be installed (openshift-gitops-operator)] ***
Monday 04 August 2025  14:09:46 +0000 (0:00:00.617)       1:12:56.360 ********* 
ok: [localhost] => {
    "msg": "Starting CSV: "
}

TASK [install_operator : Wait until CSV is installed (openshift-gitops-operator)] ***
Monday 04 August 2025  14:09:46 +0000 (0:00:00.022)       1:12:56.383 ********* 
FAILED - RETRYING: [localhost]: Wait until CSV is installed (openshift-gitops-operator) (30 retries left).
FAILED - RETRYING: [localhost]: Wait until CSV is installed (openshift-gitops-operator) (29 retries left).
ok: [localhost]

TASK [install_operator : Remove the operator - openshift-gitops-operator] ******
Monday 04 August 2025  14:10:07 +0000 (0:00:21.865)       1:13:18.249 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_gitops : Grant cluster-admin permissions to Gitops Service account] ***
Monday 04 August 2025  14:10:08 +0000 (0:00:00.015)       1:13:18.265 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_gitops : Wait until openshift-gitops ArgoCD instance has been created] ***
Monday 04 August 2025  14:10:08 +0000 (0:00:00.600)       1:13:18.865 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_gitops : Create the kustomize-envvar plugin configmap] ***
Monday 04 August 2025  14:10:09 +0000 (0:00:00.607)       1:13:19.472 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_gitops : Update the openshift-gitops ArgoCD instance] ***
Monday 04 August 2025  14:10:09 +0000 (0:00:00.029)       1:13:19.502 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_gitops : Get the OpenShift Gitops ArgoCD server route] ***
Monday 04 August 2025  14:10:09 +0000 (0:00:00.712)       1:13:20.214 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_gitops : Try to install the ArgoCD CLI] ***
Monday 04 August 2025  14:10:09 +0000 (0:00:00.030)       1:13:20.244 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_openshift_gitops : Print project information] ***
Monday 04 August 2025  14:10:10 +0000 (0:00:00.032)       1:13:20.276 ********* 
ok: [localhost] => {
    "changed": false,
    "data": {
        "openshift_gitops_server": "https://openshift-gitops-server-openshift-gitops.apps.ocp.76x7m.sandbox1795.opentlc.com"
    },
    "msg": "user.info: OpenShift GitOps ArgoCD: https://openshift-gitops-server-openshift-gitops.apps.ocp.76x7m.sandbox1795.opentlc.com"
}

TASK [agnosticd.core_workloads.ocp4_workload_openshift_gitops : Running workload removal tasks] ***
Monday 04 August 2025  14:10:10 +0000 (0:00:00.041)       1:13:20.318 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_minio : Running workload provision tasks] ***
Monday 04 August 2025  14:10:10 +0000 (0:00:00.015)       1:13:20.333 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_minio/tasks/workload.yml for localhost

TASK [agnosticd.core_workloads.ocp4_workload_minio : Assert that root user and password are set] ***
Monday 04 August 2025  14:10:10 +0000 (0:00:00.019)       1:13:20.352 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [agnosticd.core_workloads.ocp4_workload_minio : Create OpenShift objects for MinIO object storage] ***
Monday 04 August 2025  14:10:10 +0000 (0:00:00.041)       1:13:20.394 ********* 
changed: [localhost] => (item=namespace.yaml.j2)
changed: [localhost] => (item=secret.yaml.j2)
changed: [localhost] => (item=persistentvolumeclaim.yaml.j2)
changed: [localhost] => (item=deployment.yaml.j2)
changed: [localhost] => (item=service.yaml.j2)

TASK [agnosticd.core_workloads.ocp4_workload_minio : Create OpenShift routes for MinIO object storage] ***
Monday 04 August 2025  14:10:13 +0000 (0:00:03.341)       1:13:23.735 ********* 
changed: [localhost] => (item=route_minio.yaml.j2)
changed: [localhost] => (item=route_console.yaml.j2)

TASK [agnosticd.core_workloads.ocp4_workload_minio : Wait until MinIO Deployment is running] ***
Monday 04 August 2025  14:10:14 +0000 (0:00:01.303)       1:13:25.039 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_minio : Get MinIO Pod] ************
Monday 04 August 2025  14:10:35 +0000 (0:00:20.575)       1:13:45.614 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_minio : Set up MinIO bucket (Single and Multi-User)] ***
Monday 04 August 2025  14:10:35 +0000 (0:00:00.030)       1:13:45.645 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_minio : Running workload removal tasks] ***
Monday 04 August 2025  14:10:35 +0000 (0:00:00.030)       1:13:45.676 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_nfd : Running workload provision tasks] ***
Monday 04 August 2025  14:10:35 +0000 (0:00:00.019)       1:13:45.695 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_nfd/tasks/workload.yml for localhost

TASK [Install OpenShift NFD Operator] ******************************************
Monday 04 August 2025  14:10:35 +0000 (0:00:00.023)       1:13:45.718 ********* 
included: install_operator for localhost

TASK [install_operator : Install the operator - nfd] ***************************
Monday 04 August 2025  14:10:35 +0000 (0:00:00.022)       1:13:45.740 ********* 
included: /runner/project/ansible/roles/install_operator/tasks/install.yml for localhost

TASK [install_operator : Check that operator name has been provided] ***********
Monday 04 August 2025  14:10:35 +0000 (0:00:00.028)       1:13:45.768 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [install_operator : Check that starting CSV also has autoapprove set to false] ***
Monday 04 August 2025  14:10:35 +0000 (0:00:00.035)       1:13:45.804 ********* 
skipping: [localhost]

TASK [install_operator : Ensure Namespace exists (nfd)] ************************
Monday 04 August 2025  14:10:35 +0000 (0:00:00.031)       1:13:45.836 ********* 
changed: [localhost]

TASK [install_operator : Ensure OperatorGroup exists (nfd)] ********************
Monday 04 August 2025  14:10:36 +0000 (0:00:00.584)       1:13:46.420 ********* 
changed: [localhost]

TASK [install_operator : Create CatalogSource for use with catalog snapshot (nfd)] ***
Monday 04 August 2025  14:10:36 +0000 (0:00:00.668)       1:13:47.089 ********* 
changed: [localhost]

TASK [install_operator : Set subscription channel to provided channel (nfd)] ***
Monday 04 August 2025  14:10:37 +0000 (0:00:00.653)       1:13:47.743 ********* 
ok: [localhost]

TASK [install_operator : Get cluster version] **********************************
Monday 04 August 2025  14:10:37 +0000 (0:00:00.035)       1:13:47.778 ********* 
skipping: [localhost]

TASK [install_operator : Get PackageManifest for the operator (nfd)] ***********
Monday 04 August 2025  14:10:37 +0000 (0:00:00.032)       1:13:47.811 ********* 
skipping: [localhost]

TASK [install_operator : Set operator channel (nfd)] ***************************
Monday 04 August 2025  14:10:37 +0000 (0:00:00.032)       1:13:47.843 ********* 
skipping: [localhost]

TASK [install_operator : Print operator channel to be installed (nfd)] *********
Monday 04 August 2025  14:10:37 +0000 (0:00:00.033)       1:13:47.876 ********* 
ok: [localhost] => {
    "msg": "Operator channel to be installed: stable"
}

TASK [install_operator : Create operator subscription (nfd)] *******************
Monday 04 August 2025  14:10:37 +0000 (0:00:00.019)       1:13:47.895 ********* 
changed: [localhost]

TASK [install_operator : Wait until InstallPlan is created (nfd)] **************
Monday 04 August 2025  14:10:38 +0000 (0:00:00.675)       1:13:48.571 ********* 
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (nfd) (100 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (nfd) (99 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (nfd) (98 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (nfd) (97 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (nfd) (96 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (nfd) (95 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (nfd) (94 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (nfd) (93 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (nfd) (92 retries left).
ok: [localhost]

TASK [install_operator : Set InstallPlan name (nfd)] ***************************
Monday 04 August 2025  14:12:13 +0000 (0:01:35.572)       1:15:24.144 ********* 
ok: [localhost]

TASK [install_operator : Print InstallPlan (nfd)] ******************************
Monday 04 August 2025  14:12:13 +0000 (0:00:00.047)       1:15:24.192 ********* 
ok: [localhost] => {
    "msg": "InstallPlan: install-2cxtk"
}

TASK [install_operator : Get InstallPlan (nfd)] ********************************
Monday 04 August 2025  14:12:13 +0000 (0:00:00.018)       1:15:24.210 ********* 
ok: [localhost]

TASK [install_operator : Approve InstallPlan if necessary (nfd)] ***************
Monday 04 August 2025  14:12:14 +0000 (0:00:00.575)       1:15:24.785 ********* 
skipping: [localhost]

TASK [install_operator : Get Installed CSV (nfd)] ******************************
Monday 04 August 2025  14:12:14 +0000 (0:00:00.018)       1:15:24.804 ********* 
ok: [localhost]

TASK [install_operator : Print CSV version to be installed (nfd)] **************
Monday 04 August 2025  14:12:15 +0000 (0:00:00.593)       1:15:25.397 ********* 
ok: [localhost] => {
    "msg": "Starting CSV: "
}

TASK [install_operator : Wait until CSV is installed (nfd)] ********************
Monday 04 August 2025  14:12:15 +0000 (0:00:00.023)       1:15:25.421 ********* 
FAILED - RETRYING: [localhost]: Wait until CSV is installed (nfd) (30 retries left).
ok: [localhost]

TASK [install_operator : Remove the operator - nfd] ****************************
Monday 04 August 2025  14:12:26 +0000 (0:00:11.216)       1:15:36.638 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_nfd : Create NodeFeatureDiscovery Custom Resource] ***
Monday 04 August 2025  14:12:26 +0000 (0:00:00.020)       1:15:36.658 ********* 
changed: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_nfd : Wait for NodeFeatureDiscovery to be Available] ***
Monday 04 August 2025  14:12:27 +0000 (0:00:00.789)       1:15:37.447 ********* 
ok: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_nfd : Running workload removal tasks] ***
Monday 04 August 2025  14:12:37 +0000 (0:00:10.613)       1:15:48.061 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authorino : Running workload provision tasks] ***
Monday 04 August 2025  14:12:37 +0000 (0:00:00.016)       1:15:48.077 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_authorino/tasks/workload.yml for localhost

TASK [Install Authorino operator] **********************************************
Monday 04 August 2025  14:12:37 +0000 (0:00:00.021)       1:15:48.098 ********* 
included: install_operator for localhost

TASK [install_operator : Install the operator - authorino-operator] ************
Monday 04 August 2025  14:12:37 +0000 (0:00:00.024)       1:15:48.123 ********* 
included: /runner/project/ansible/roles/install_operator/tasks/install.yml for localhost

TASK [install_operator : Check that operator name has been provided] ***********
Monday 04 August 2025  14:12:37 +0000 (0:00:00.028)       1:15:48.152 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [install_operator : Check that starting CSV also has autoapprove set to false] ***
Monday 04 August 2025  14:12:37 +0000 (0:00:00.042)       1:15:48.194 ********* 
skipping: [localhost]

TASK [install_operator : Ensure Namespace exists (authorino-operator)] *********
Monday 04 August 2025  14:12:37 +0000 (0:00:00.041)       1:15:48.236 ********* 
skipping: [localhost]

TASK [install_operator : Ensure OperatorGroup exists (authorino-operator)] *****
Monday 04 August 2025  14:12:38 +0000 (0:00:00.021)       1:15:48.257 ********* 
skipping: [localhost]

TASK [install_operator : Create CatalogSource for use with catalog snapshot (authorino-operator)] ***
Monday 04 August 2025  14:12:38 +0000 (0:00:00.018)       1:15:48.276 ********* 
changed: [localhost]

TASK [install_operator : Set subscription channel to provided channel (authorino-operator)] ***
Monday 04 August 2025  14:12:38 +0000 (0:00:00.748)       1:15:49.024 ********* 
ok: [localhost]

TASK [install_operator : Get cluster version] **********************************
Monday 04 August 2025  14:12:38 +0000 (0:00:00.039)       1:15:49.064 ********* 
skipping: [localhost]

TASK [install_operator : Get PackageManifest for the operator (authorino-operator)] ***
Monday 04 August 2025  14:12:38 +0000 (0:00:00.038)       1:15:49.102 ********* 
skipping: [localhost]

TASK [install_operator : Set operator channel (authorino-operator)] ************
Monday 04 August 2025  14:12:38 +0000 (0:00:00.045)       1:15:49.148 ********* 
skipping: [localhost]

TASK [install_operator : Print operator channel to be installed (authorino-operator)] ***
Monday 04 August 2025  14:12:38 +0000 (0:00:00.041)       1:15:49.189 ********* 
ok: [localhost] => {
    "msg": "Operator channel to be installed: stable"
}

TASK [install_operator : Create operator subscription (authorino-operator)] ****
Monday 04 August 2025  14:12:38 +0000 (0:00:00.021)       1:15:49.210 ********* 
changed: [localhost]

TASK [install_operator : Wait until InstallPlan is created (authorino-operator)] ***
Monday 04 August 2025  14:12:39 +0000 (0:00:00.794)       1:15:50.005 ********* 
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (authorino-operator) (100 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (authorino-operator) (99 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (authorino-operator) (98 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (authorino-operator) (97 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (authorino-operator) (96 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (authorino-operator) (95 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (authorino-operator) (94 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (authorino-operator) (93 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (authorino-operator) (92 retries left).
ok: [localhost]

TASK [install_operator : Set InstallPlan name (authorino-operator)] ************
Monday 04 August 2025  14:14:15 +0000 (0:01:36.063)       1:17:26.068 ********* 
ok: [localhost]

TASK [install_operator : Print InstallPlan (authorino-operator)] ***************
Monday 04 August 2025  14:14:15 +0000 (0:00:00.053)       1:17:26.122 ********* 
ok: [localhost] => {
    "msg": "InstallPlan: install-4rb5r"
}

TASK [install_operator : Get InstallPlan (authorino-operator)] *****************
Monday 04 August 2025  14:14:15 +0000 (0:00:00.025)       1:17:26.147 ********* 
ok: [localhost]

TASK [install_operator : Approve InstallPlan if necessary (authorino-operator)] ***
Monday 04 August 2025  14:14:16 +0000 (0:00:00.648)       1:17:26.796 ********* 
skipping: [localhost]

TASK [install_operator : Get Installed CSV (authorino-operator)] ***************
Monday 04 August 2025  14:14:16 +0000 (0:00:00.021)       1:17:26.818 ********* 
ok: [localhost]

TASK [install_operator : Print CSV version to be installed (authorino-operator)] ***
Monday 04 August 2025  14:14:17 +0000 (0:00:00.616)       1:17:27.435 ********* 
ok: [localhost] => {
    "msg": "Starting CSV: "
}

TASK [install_operator : Wait until CSV is installed (authorino-operator)] *****
Monday 04 August 2025  14:14:17 +0000 (0:00:00.040)       1:17:27.475 ********* 
FAILED - RETRYING: [localhost]: Wait until CSV is installed (authorino-operator) (30 retries left).
ok: [localhost]

TASK [install_operator : Remove the operator - authorino-operator] *************
Monday 04 August 2025  14:14:28 +0000 (0:00:11.197)       1:17:38.673 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authorino : Install Authorino] ****
Monday 04 August 2025  14:14:28 +0000 (0:00:00.014)       1:17:38.687 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authorino : Wait for Authorino to be ready] ***
Monday 04 August 2025  14:14:28 +0000 (0:00:00.012)       1:17:38.699 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_authorino : Running workload removal tasks] ***
Monday 04 August 2025  14:14:28 +0000 (0:00:00.014)       1:17:38.714 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_servicemesh2 : Running workload provision tasks] ***
Monday 04 August 2025  14:14:28 +0000 (0:00:00.015)       1:17:38.730 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/core_workloads/roles/ocp4_workload_servicemesh2/tasks/workload.yml for localhost

TASK [Install Elasticsearch operator] ******************************************
Monday 04 August 2025  14:14:28 +0000 (0:00:00.022)       1:17:38.752 ********* 
skipping: [localhost]

TASK [Install Jaeger operator] *************************************************
Monday 04 August 2025  14:14:28 +0000 (0:00:00.030)       1:17:38.783 ********* 
skipping: [localhost]

TASK [Install Kiali operator] **************************************************
Monday 04 August 2025  14:14:28 +0000 (0:00:00.030)       1:17:38.814 ********* 
skipping: [localhost]

TASK [Install Service Mesh 2 operator] *****************************************
Monday 04 August 2025  14:14:28 +0000 (0:00:00.028)       1:17:38.843 ********* 
included: install_operator for localhost

TASK [install_operator : Install the operator - servicemeshoperator] ***********
Monday 04 August 2025  14:14:28 +0000 (0:00:00.023)       1:17:38.866 ********* 
included: /runner/project/ansible/roles/install_operator/tasks/install.yml for localhost

TASK [install_operator : Check that operator name has been provided] ***********
Monday 04 August 2025  14:14:28 +0000 (0:00:00.028)       1:17:38.895 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [install_operator : Check that starting CSV also has autoapprove set to false] ***
Monday 04 August 2025  14:14:28 +0000 (0:00:00.041)       1:17:38.936 ********* 
skipping: [localhost]

TASK [install_operator : Ensure Namespace exists (servicemeshoperator)] ********
Monday 04 August 2025  14:14:28 +0000 (0:00:00.038)       1:17:38.975 ********* 
skipping: [localhost]

TASK [install_operator : Ensure OperatorGroup exists (servicemeshoperator)] ****
Monday 04 August 2025  14:14:28 +0000 (0:00:00.016)       1:17:38.991 ********* 
skipping: [localhost]

TASK [install_operator : Create CatalogSource for use with catalog snapshot (servicemeshoperator)] ***
Monday 04 August 2025  14:14:28 +0000 (0:00:00.014)       1:17:39.006 ********* 
changed: [localhost]

TASK [install_operator : Set subscription channel to provided channel (servicemeshoperator)] ***
Monday 04 August 2025  14:14:29 +0000 (0:00:00.660)       1:17:39.667 ********* 
ok: [localhost]

TASK [install_operator : Get cluster version] **********************************
Monday 04 August 2025  14:14:29 +0000 (0:00:00.038)       1:17:39.705 ********* 
skipping: [localhost]

TASK [install_operator : Get PackageManifest for the operator (servicemeshoperator)] ***
Monday 04 August 2025  14:14:29 +0000 (0:00:00.033)       1:17:39.738 ********* 
skipping: [localhost]

TASK [install_operator : Set operator channel (servicemeshoperator)] ***********
Monday 04 August 2025  14:14:29 +0000 (0:00:00.032)       1:17:39.771 ********* 
skipping: [localhost]

TASK [install_operator : Print operator channel to be installed (servicemeshoperator)] ***
Monday 04 August 2025  14:14:29 +0000 (0:00:00.035)       1:17:39.807 ********* 
ok: [localhost] => {
    "msg": "Operator channel to be installed: stable"
}

TASK [install_operator : Create operator subscription (servicemeshoperator)] ***
Monday 04 August 2025  14:14:29 +0000 (0:00:00.019)       1:17:39.826 ********* 
changed: [localhost]

TASK [install_operator : Wait until InstallPlan is created (servicemeshoperator)] ***
Monday 04 August 2025  14:14:30 +0000 (0:00:00.703)       1:17:40.529 ********* 
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (servicemeshoperator) (100 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (servicemeshoperator) (99 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (servicemeshoperator) (98 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (servicemeshoperator) (97 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (servicemeshoperator) (96 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (servicemeshoperator) (95 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (servicemeshoperator) (94 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (servicemeshoperator) (93 retries left).
ok: [localhost]

TASK [install_operator : Set InstallPlan name (servicemeshoperator)] ***********
Monday 04 August 2025  14:15:55 +0000 (0:01:25.334)       1:19:05.864 ********* 
ok: [localhost]

TASK [install_operator : Print InstallPlan (servicemeshoperator)] **************
Monday 04 August 2025  14:15:55 +0000 (0:00:00.052)       1:19:05.916 ********* 
ok: [localhost] => {
    "msg": "InstallPlan: install-qkgd6"
}

TASK [install_operator : Get InstallPlan (servicemeshoperator)] ****************
Monday 04 August 2025  14:15:55 +0000 (0:00:00.020)       1:19:05.936 ********* 
ok: [localhost]

TASK [install_operator : Approve InstallPlan if necessary (servicemeshoperator)] ***
Monday 04 August 2025  14:15:56 +0000 (0:00:00.619)       1:19:06.556 ********* 
skipping: [localhost]

TASK [install_operator : Get Installed CSV (servicemeshoperator)] **************
Monday 04 August 2025  14:15:56 +0000 (0:00:00.022)       1:19:06.578 ********* 
ok: [localhost]

TASK [install_operator : Print CSV version to be installed (servicemeshoperator)] ***
Monday 04 August 2025  14:15:56 +0000 (0:00:00.625)       1:19:07.204 ********* 
ok: [localhost] => {
    "msg": "Starting CSV: "
}

TASK [install_operator : Wait until CSV is installed (servicemeshoperator)] ****
Monday 04 August 2025  14:15:56 +0000 (0:00:00.024)       1:19:07.229 ********* 
FAILED - RETRYING: [localhost]: Wait until CSV is installed (servicemeshoperator) (30 retries left).
ok: [localhost]

TASK [install_operator : Remove the operator - servicemeshoperator] ************
Monday 04 August 2025  14:16:08 +0000 (0:00:11.214)       1:19:18.443 ********* 
skipping: [localhost]

TASK [agnosticd.core_workloads.ocp4_workload_servicemesh2 : Running workload removal tasks] ***
Monday 04 August 2025  14:16:08 +0000 (0:00:00.016)       1:19:18.460 ********* 
skipping: [localhost]

TASK [agnosticd.ai_workloads.ocp4_workload_nvidia_gpu_operator : Running workload provision tasks] ***
Monday 04 August 2025  14:16:08 +0000 (0:00:00.015)       1:19:18.475 ********* 
included: /runner/requirements_collections/ansible_collections/agnosticd/ai_workloads/roles/ocp4_workload_nvidia_gpu_operator/tasks/workload.yml for localhost

TASK [agnosticd.ai_workloads.ocp4_workload_nvidia_gpu_operator : Check for NodeFeatureDiscovery objects] ***
Monday 04 August 2025  14:16:08 +0000 (0:00:00.021)       1:19:18.497 ********* 
ok: [localhost]

TASK [agnosticd.ai_workloads.ocp4_workload_nvidia_gpu_operator : Fail if no NodeFeatureDiscovery objects found] ***
Monday 04 August 2025  14:16:08 +0000 (0:00:00.602)       1:19:19.100 ********* 
skipping: [localhost]

TASK [Install NVIDIA GPU operator] *********************************************
Monday 04 August 2025  14:16:08 +0000 (0:00:00.036)       1:19:19.136 ********* 
included: install_operator for localhost

TASK [install_operator : Install the operator - gpu-operator-certified] ********
Monday 04 August 2025  14:16:08 +0000 (0:00:00.024)       1:19:19.160 ********* 
included: /runner/project/ansible/roles/install_operator/tasks/install.yml for localhost

TASK [install_operator : Check that operator name has been provided] ***********
Monday 04 August 2025  14:16:08 +0000 (0:00:00.029)       1:19:19.190 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [install_operator : Check that starting CSV also has autoapprove set to false] ***
Monday 04 August 2025  14:16:08 +0000 (0:00:00.035)       1:19:19.226 ********* 
skipping: [localhost]

TASK [install_operator : Ensure Namespace exists (gpu-operator-certified)] *****
Monday 04 August 2025  14:16:09 +0000 (0:00:00.033)       1:19:19.259 ********* 
changed: [localhost]

TASK [install_operator : Ensure OperatorGroup exists (gpu-operator-certified)] ***
Monday 04 August 2025  14:16:09 +0000 (0:00:00.664)       1:19:19.924 ********* 
changed: [localhost]

TASK [install_operator : Create CatalogSource for use with catalog snapshot (gpu-operator-certified)] ***
Monday 04 August 2025  14:16:10 +0000 (0:00:00.770)       1:19:20.694 ********* 
changed: [localhost]

TASK [install_operator : Set subscription channel to provided channel (gpu-operator-certified)] ***
Monday 04 August 2025  14:16:11 +0000 (0:00:00.799)       1:19:21.493 ********* 
ok: [localhost]

TASK [install_operator : Get cluster version] **********************************
Monday 04 August 2025  14:16:11 +0000 (0:00:00.039)       1:19:21.533 ********* 
skipping: [localhost]

TASK [install_operator : Get PackageManifest for the operator (gpu-operator-certified)] ***
Monday 04 August 2025  14:16:11 +0000 (0:00:00.033)       1:19:21.567 ********* 
skipping: [localhost]

TASK [install_operator : Set operator channel (gpu-operator-certified)] ********
Monday 04 August 2025  14:16:11 +0000 (0:00:00.031)       1:19:21.598 ********* 
skipping: [localhost]

TASK [install_operator : Print operator channel to be installed (gpu-operator-certified)] ***
Monday 04 August 2025  14:16:11 +0000 (0:00:00.038)       1:19:21.637 ********* 
ok: [localhost] => {
    "msg": "Operator channel to be installed: v25.3"
}

TASK [install_operator : Create operator subscription (gpu-operator-certified)] ***
Monday 04 August 2025  14:16:11 +0000 (0:00:00.028)       1:19:21.665 ********* 
changed: [localhost]

TASK [install_operator : Wait until InstallPlan is created (gpu-operator-certified)] ***
Monday 04 August 2025  14:16:12 +0000 (0:00:00.790)       1:19:22.456 ********* 
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (gpu-operator-certified) (100 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (gpu-operator-certified) (99 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (gpu-operator-certified) (98 retries left).
FAILED - RETRYING: [localhost]: Wait until InstallPlan is created (gpu-operator-certified) (97 retries left).
ok: [localhost]

TASK [install_operator : Set InstallPlan name (gpu-operator-certified)] ********
Monday 04 August 2025  14:16:55 +0000 (0:00:43.109)       1:20:05.565 ********* 
ok: [localhost]

TASK [install_operator : Print InstallPlan (gpu-operator-certified)] ***********
Monday 04 August 2025  14:16:55 +0000 (0:00:00.061)       1:20:05.627 ********* 
ok: [localhost] => {
    "msg": "InstallPlan: install-t5v5z"
}

TASK [install_operator : Get InstallPlan (gpu-operator-certified)] *************
Monday 04 August 2025  14:16:55 +0000 (0:00:00.025)       1:20:05.652 ********* 
ok: [localhost]

TASK [install_operator : Approve InstallPlan if necessary (gpu-operator-certified)] ***
Monday 04 August 2025  14:16:55 +0000 (0:00:00.596)       1:20:06.248 ********* 
skipping: [localhost]

TASK [install_operator : Get Installed CSV (gpu-operator-certified)] ***********
Monday 04 August 2025  14:16:56 +0000 (0:00:00.020)       1:20:06.269 ********* 
ok: [localhost]

TASK [install_operator : Print CSV version to be installed (gpu-operator-certified)] ***
Monday 04 August 2025  14:16:56 +0000 (0:00:00.618)       1:20:06.887 ********* 
ok: [localhost] => {
    "msg": "Starting CSV: "
}

TASK [install_operator : Wait until CSV is installed (gpu-operator-certified)] ***
Monday 04 August 2025  14:16:56 +0000 (0:00:00.028)       1:20:06.916 ********* 
FAILED - RETRYING: [localhost]: Wait until CSV is installed (gpu-operator-certified) (30 retries left).
FAILED - RETRYING: [localhost]: Wait until CSV is installed (gpu-operator-certified) (29 retries left).
ok: [localhost]

TASK [install_operator : Remove the operator - gpu-operator-certified] *********
Monday 04 August 2025  14:17:18 +0000 (0:00:21.877)       1:20:28.793 ********* 
skipping: [localhost]

TASK [agnosticd.ai_workloads.ocp4_workload_nvidia_gpu_operator : Setup NVIDIA GPU Cluster Policy] ***
Monday 04 August 2025  14:17:18 +0000 (0:00:00.016)       1:20:28.809 ********* 
changed: [localhost]

TASK [agnosticd.ai_workloads.ocp4_workload_nvidia_gpu_operator : Wait for ClusterPolicy to be ready] ***
Monday 04 August 2025  14:17:19 +0000 (0:00:00.668)       1:20:29.478 ********* 
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException: Failed to gather information about ClusterPolicy(s) even after waiting for 600 seconds
fatal: [localhost]: FAILED! => {"changed": false, "msg": "Failed to gather information about ClusterPolicy(s) even after waiting for 600 seconds"}

TASKS RECAP ********************************************************************
Monday 04 August 2025  14:27:20 +0000 (0:10:01.257)       1:30:30.736 ********* 
=============================================================================== 
host_ocp4_installer : Check installer status ------------------------- 2691.81s
agnosticd.ai_workloads.ocp4_workload_nvidia_gpu_operator : Wait for ClusterPolicy to be ready - 601.26s
agnosticd.core_workloads.ocp4_workload_cert_manager : Wait until Ingress Certificate is ready - 280.93s
agnosticd.cloud_provider_aws.aws_template_create : Launch CloudFormation from local template - 157.65s
agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Wait for ODF Storage Cluster to finish deploying - 100.69s
install_operator : Wait until InstallPlan is created (authorino-operator) -- 96.06s
install_operator : Wait until InstallPlan is created (openshift-pipelines-operator) -- 95.82s
install_operator : Wait until InstallPlan is created (rhsso-operator) -- 95.64s
install_operator : Wait until InstallPlan is created (nfd) ------------- 95.57s
agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Wait for ODF Storage System to finish deploying -- 90.67s
install_operator : Wait until InstallPlan is created (servicemeshoperator) -- 85.33s
agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Wait for the CRD storagesystems to become available -- 85.17s
install_operator : Wait until InstallPlan is created (openshift-cert-manager-operator) -- 85.15s
install_operator : Wait until InstallPlan is created (openshift-gitops-operator) -- 84.96s
host_common_packages : Install common packages for RHEL 9 -------------- 74.95s
install_operator : Wait until InstallPlan is created (serverless-operator) -- 74.68s
agnosticd.core_workloads.ocp4_workload_authentication_rhsso : Retrieve OpenShift realm client credentials -- 74.46s
agnosticd.core_workloads.ocp4_workload_openshift_data_foundation : Wait for the CRD storagecluster to become available -- 53.45s
install_operator : Wait until InstallPlan is created (gpu-operator-certified) -- 43.11s
agnosticd.core_workloads.ocp4_workload_pipelines : Wait until pipeline controller pods are ready -- 42.93s
