[DEPRECATION WARNING]: ANSIBLE_COLLECTIONS_PATHS option. Reason: does not fit 
var naming standard, use the singular form ANSIBLE_COLLECTIONS_PATH instead 
Alternatives: none. This feature will be removed in version 2.19. Deprecation 
warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
Vault password (gpte_vault_0): 

PLAY [Step 0000 Set Action] ****************************************************

TASK [Set ACTION to provision] *************************************************
Monday 04 August 2025  12:34:24 +0000 (0:00:00.007)       0:00:00.007 ********* 
skipping: [localhost]

PLAY [Step 0000 Setup runtime] *************************************************

TASK [debug] *******************************************************************
Monday 04 August 2025  12:34:24 +0000 (0:00:00.018)       0:00:00.026 ********* 
skipping: [localhost]

TASK [Ensure cloud provider is supported] **************************************
Monday 04 August 2025  12:34:24 +0000 (0:00:00.013)       0:00:00.039 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}

PLAY [Step 0000 Setup Output Directory] ****************************************

TASK [Set output_dir if not defined] *******************************************
Monday 04 August 2025  12:34:24 +0000 (0:00:00.015)       0:00:00.055 ********* 
skipping: [localhost]

TASK [Create output_dir if it does not exists] *********************************
Monday 04 August 2025  12:34:24 +0000 (0:00:00.013)       0:00:00.068 ********* 
changed: [localhost]

TASK [Attempt to restore output_dir contents] **********************************
Monday 04 August 2025  12:34:24 +0000 (0:00:00.288)       0:00:00.357 ********* 
included: agnosticd_restore_output_dir for localhost

TASK [agnosticd_restore_output_dir : Restore output_dir from s3 bucket] ********
Monday 04 August 2025  12:34:24 +0000 (0:00:00.024)       0:00:00.381 ********* 
included: /runner/project/ansible/roles/agnosticd_restore_output_dir/tasks/restore-from-s3.yml for localhost

TASK [agnosticd_restore_output_dir : Get output_dir archive from s3] ***********
Monday 04 August 2025  12:34:24 +0000 (0:00:00.037)       0:00:00.418 ********* 
included: /runner/project/ansible/roles/agnosticd_restore_output_dir/tasks/fetch-from-s3-s3_object.yml for localhost

TASK [agnosticd_restore_output_dir : Get output_dir archive from s3] ***********
Monday 04 August 2025  12:34:24 +0000 (0:00:00.028)       0:00:00.447 ********* 
ok: [localhost]

TASK [agnosticd_restore_output_dir : Decrypt archive] **************************
Monday 04 August 2025  12:34:25 +0000 (0:00:00.951)       0:00:01.398 ********* 
skipping: [localhost]

TASK [agnosticd_restore_output_dir : Restore output_dir from archive] **********
Monday 04 August 2025  12:34:25 +0000 (0:00:00.017)       0:00:01.415 ********* 
skipping: [localhost]

TASK [agnosticd_restore_output_dir : Remove archive file from output_dir] ******
Monday 04 August 2025  12:34:25 +0000 (0:00:00.013)       0:00:01.429 ********* 
ok: [localhost]

TASK [agnosticd_restore_output_dir : Remove encrypted archive file from output_dir] ***
Monday 04 August 2025  12:34:25 +0000 (0:00:00.183)       0:00:01.613 ********* 
ok: [localhost]

TASK [Touch file provision-user-data.yaml and provision-user-info.yaml] ********
Monday 04 August 2025  12:34:25 +0000 (0:00:00.160)       0:00:01.774 ********* 
changed: [localhost] => (item=user-info.yaml)
changed: [localhost] => (item=user-data.yaml)

TASK [Create empty user-info.yaml and user-data.yaml in output dir] ************
Monday 04 August 2025  12:34:26 +0000 (0:00:00.337)       0:00:02.111 ********* 
changed: [localhost] => (item=user-info.yaml)
changed: [localhost] => (item=user-data.yaml)

TASK [Create symlink user-data.yaml -> provision-user-data.yaml] ***************
Monday 04 August 2025  12:34:27 +0000 (0:00:00.731)       0:00:02.843 ********* 
changed: [localhost] => (item=user-info.yaml)
changed: [localhost] => (item=user-data.yaml)

PLAY [Step 0000 Include Vars] **************************************************

TASK [Set output_dir for all hosts] ********************************************
Monday 04 August 2025  12:34:27 +0000 (0:00:00.323)       0:00:03.166 ********* 
ok: [localhost]

TASK [Include variables files] *************************************************
Monday 04 August 2025  12:34:27 +0000 (0:00:00.019)       0:00:03.186 ********* 
skipping: [localhost] => (item=/runner/project/ansible/cloud_providers/openshift_cnv_default_vars.yaml) 
skipping: [localhost] => (item=/runner/project/ansible/cloud_providers/openshift_cnv_default_vars.yml) 
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/env_vars.yaml) 
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/env_vars.yml) 
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars.yaml) 
ok: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars.yml)
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars_openshift_cnv.yaml) 
ok: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars_openshift_cnv.yml)
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/env_secret_vars.yaml) 
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/env_secret_vars.yml) 
[WARNING]: Found variable using reserved name: remote_user

TASK [Include secret_file if passed as extra-var] ******************************
Monday 04 August 2025  12:34:27 +0000 (0:00:00.052)       0:00:03.239 ********* 
skipping: [localhost]

TASK [Set passthrough user data] ***********************************************
Monday 04 August 2025  12:34:27 +0000 (0:00:00.015)       0:00:03.255 ********* 
skipping: [localhost]

PLAY [Step 0000 Install Galaxy roles and collections] **************************

TASK [Use requirements_content] ************************************************
Monday 04 August 2025  12:34:27 +0000 (0:00:00.020)       0:00:03.275 ********* 
skipping: [localhost]

TASK [Copy requirements content to output_dir] *********************************
Monday 04 August 2025  12:34:27 +0000 (0:00:00.015)       0:00:03.291 ********* 
skipping: [localhost]

TASK [Use requirements_path from the config] ***********************************
Monday 04 August 2025  12:34:27 +0000 (0:00:00.015)       0:00:03.306 ********* 
ok: [localhost]

TASK [Check if requirements.yml exists] ****************************************
Monday 04 August 2025  12:34:27 +0000 (0:00:00.023)       0:00:03.330 ********* 
ok: [localhost]

TASK [set_fact] ****************************************************************
Monday 04 August 2025  12:34:27 +0000 (0:00:00.162)       0:00:03.492 ********* 
ok: [localhost]

TASK [Install roles from requirements.yml] *************************************
Monday 04 August 2025  12:34:27 +0000 (0:00:00.017)       0:00:03.509 ********* 
changed: [localhost]

TASK [Install collections from requirements.yml (Not EE)] **********************
Monday 04 August 2025  12:34:28 +0000 (0:00:00.828)       0:00:04.338 ********* 
skipping: [localhost]

TASK [Get installed collections (EE)] ******************************************
Monday 04 August 2025  12:34:28 +0000 (0:00:00.025)       0:00:04.363 ********* 
included: /runner/project/ansible/install_collections_ee.yml for localhost

TASK [Get the list of installed collections (EE)] ******************************
Monday 04 August 2025  12:34:28 +0000 (0:00:00.024)       0:00:04.388 ********* 
changed: [localhost]

TASK [Create temporary file for requirements.yml (EE)] *************************
Monday 04 August 2025  12:34:29 +0000 (0:00:00.480)       0:00:04.868 ********* 
changed: [localhost]

TASK [Rewrite requirements, filter out installed collections (EE)] *************
Monday 04 August 2025  12:34:29 +0000 (0:00:00.257)       0:00:05.126 ********* 
[WARNING]: skipping installation of community.general==9.2.0 ;
community.general==10.5.0 already installed in EE
[WARNING]: skipping installation of community.crypto==2.21.1 ;
community.crypto==2.26.0 already installed in EE
[WARNING]: skipping installation of ansible.posix==1.5.4 ; ansible.posix==2.0.0
already installed in EE
[WARNING]: skipping installation of kubernetes.core==5.0.0 ;
kubernetes.core==5.2.0 already installed in EE
[WARNING]: skipping installation of amazon.aws==8.1.0 ; amazon.aws==9.4.0
already installed in EE
[WARNING]: skipping installation of community.vmware==4.5.0 ;
community.vmware==5.5.0 already installed in EE
[WARNING]: skipping installation of vmware.vmware_rest==3.0.1 ;
vmware.vmware_rest==4.7.0 already installed in EE
[WARNING]: skipping installation of vmware.vmware==1.11.0 ;
vmware.vmware==1.11.0 already installed in EE
[WARNING]: skipping installation of google.cloud==1.3.0 ; google.cloud==1.5.1
already installed in EE
[WARNING]: skipping installation of openstack.cloud==2.2.0 ;
openstack.cloud==2.4.1 already installed in EE
[WARNING]: skipping installation of community.okd==4.0.0 ; community.okd==4.0.1
already installed in EE
[WARNING]: skipping installation of kubevirt.core==2.0.0 ; kubevirt.core==2.1.0
already installed in EE
changed: [localhost]

TASK [Install collections from requirements.yml (EE)] **************************
Monday 04 August 2025  12:34:29 +0000 (0:00:00.311)       0:00:05.438 ********* 
changed: [localhost]

TASK [Cleanup tempfile (EE)] ***************************************************
Monday 04 August 2025  12:34:30 +0000 (0:00:00.792)       0:00:06.230 ********* 
changed: [localhost]

TASK [Install dynamic sources] *************************************************
Monday 04 August 2025  12:34:30 +0000 (0:00:00.174)       0:00:06.405 ********* 
included: agnosticd_dynamic for localhost

TASK [agnosticd_dynamic : Create dynamic-cache and dynamic-roles directories] ***
Monday 04 August 2025  12:34:30 +0000 (0:00:00.019)       0:00:06.424 ********* 
changed: [localhost] => (item=/runner/project/ansible/dynamic-cache)
changed: [localhost] => (item=/runner/project/ansible/dynamic-roles)

TASK [agnosticd_dynamic : Install ansible-galaxy sources to dynamic roles dir] ***
Monday 04 August 2025  12:34:30 +0000 (0:00:00.328)       0:00:06.753 ********* 
skipping: [localhost]

TASK [agnosticd_dynamic : Install ansible-galaxy sources to cache] *************
Monday 04 August 2025  12:34:30 +0000 (0:00:00.017)       0:00:06.770 ********* 
skipping: [localhost]

TASK [agnosticd_dynamic : Install git sources] *********************************
Monday 04 August 2025  12:34:30 +0000 (0:00:00.018)       0:00:06.789 ********* 
skipping: [localhost]

PLAY [Step 000 - Pre Infrastructure] *******************************************

TASK [Print debug message] *****************************************************
Monday 04 August 2025  12:34:30 +0000 (0:00:00.021)       0:00:06.810 ********* 
ok: [localhost] => {
    "msg": "Step 000 Pre Infrastructure"
}

TASK [Ensure variables are set] ************************************************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.016)       0:00:06.826 ********* 
ok: [localhost] => {
    "changed": false,
    "msg": "ocp4_pull_secret variable is defined"
}

TASK [Run add user to GCP project role] ****************************************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.018)       0:00:06.845 ********* 
skipping: [localhost]

TASK [Create GCP Credentials File] *********************************************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.012)       0:00:06.857 ********* 
skipping: [localhost]

TASK [Get Google Cloud SDK] ****************************************************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.011)       0:00:06.869 ********* 
skipping: [localhost]

TASK [Generate windows Administrator password if not already defined] **********
Monday 04 August 2025  12:34:31 +0000 (0:00:00.011)       0:00:06.880 ********* 
skipping: [localhost]

TASK [Set fact generated_windows_password (just generated)] ********************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.010)       0:00:06.890 ********* 
skipping: [localhost]

TASK [Run infra-aws-capacity-reservation] **************************************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.011)       0:00:06.902 ********* 
skipping: [localhost]

TASK [Set availability zone for bastion, masters and workers] ******************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.010)       0:00:06.912 ********* 
skipping: [localhost]

PLAY [Step 001.1 Deploy Infrastructure] ****************************************

TASK [Create ssh provision key] ************************************************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.012)       0:00:06.925 ********* 
included: create_ssh_provision_key for localhost

TASK [create_ssh_provision_key : include_tasks] ********************************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.030)       0:00:06.955 ********* 
included: /runner/project/ansible/roles-infra/create_ssh_provision_key/tasks/checks.yaml for localhost

TASK [create_ssh_provision_key : Ensure key_name is not defined] ***************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.012)       0:00:06.967 ********* 
skipping: [localhost]

TASK [create_ssh_provision_key : Generate SSH keys] ****************************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.013)       0:00:06.981 ********* 
changed: [localhost]

TASK [create_ssh_provision_key : Fix permission of ssh key] ********************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.351)       0:00:07.333 ********* 
changed: [localhost]

TASK [create_ssh_provision_key : Generate SSH pub key content] *****************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.158)       0:00:07.491 ********* 
ok: [localhost]

TASK [create_ssh_provision_key : Save all facts for SSH] ***********************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.189)       0:00:07.681 ********* 
ok: [localhost]

TASK [create_ssh_provision_key : Write SSH pub key] ****************************
Monday 04 August 2025  12:34:31 +0000 (0:00:00.019)       0:00:07.700 ********* 
changed: [localhost]

TASK [create_ssh_provision_key : Report user info for SSH provision key as user data] ***
Monday 04 August 2025  12:34:32 +0000 (0:00:00.312)       0:00:08.013 ********* 
skipping: [localhost]

TASK [include_role : agnosticd_save_output_dir] ********************************
Monday 04 August 2025  12:34:32 +0000 (0:00:00.012)       0:00:08.026 ********* 
included: agnosticd_save_output_dir for localhost

TASK [agnosticd_save_output_dir : Save output dir if archive file is defined] ***
Monday 04 August 2025  12:34:32 +0000 (0:00:00.032)       0:00:08.058 ********* 
included: /runner/project/ansible/roles/agnosticd_save_output_dir/tasks/save-output-dir.yml for localhost

TASK [agnosticd_save_output_dir : Create output_dir archive] *******************
Monday 04 August 2025  12:34:32 +0000 (0:00:00.026)       0:00:08.085 ********* 
included: /runner/project/ansible/roles/agnosticd_save_output_dir/tasks/create-output-dir-archive.yml for localhost

TASK [agnosticd_save_output_dir : Create tempfile for archive] *****************
Monday 04 August 2025  12:34:32 +0000 (0:00:00.020)       0:00:08.106 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Set agnosticd_save_output_dir_archive_tempfile] ***
Monday 04 August 2025  12:34:32 +0000 (0:00:00.151)       0:00:08.258 ********* 
ok: [localhost]

TASK [agnosticd_save_output_dir : Create output_dir archive] *******************
Monday 04 August 2025  12:34:32 +0000 (0:00:00.015)       0:00:08.273 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Encrypt tarball using password] **************
Monday 04 August 2025  12:34:32 +0000 (0:00:00.179)       0:00:08.453 ********* 
skipping: [localhost]

TASK [agnosticd_save_output_dir : Upload output_dir archive to S3] *************
Monday 04 August 2025  12:34:32 +0000 (0:00:00.017)       0:00:08.471 ********* 
included: /runner/project/ansible/roles/agnosticd_save_output_dir/tasks/upload-archive-s3.yml for localhost

TASK [Run infra-cloud-tags role] ***********************************************
Monday 04 August 2025  12:34:32 +0000 (0:00:00.024)       0:00:08.495 ********* 
included: infra-cloud-tags for localhost

TASK [infra-cloud-tags : Set cloud_tags_final (string)] ************************
Monday 04 August 2025  12:34:32 +0000 (0:00:00.024)       0:00:08.519 ********* 
skipping: [localhost]

TASK [infra-cloud-tags : Set cloud_tags_final (dictionary)] ********************
Monday 04 August 2025  12:34:32 +0000 (0:00:00.024)       0:00:08.544 ********* 
ok: [localhost]

TASK [agnosticd_save_output_dir : Save output_dir archive to AWS S3] ***********
Monday 04 August 2025  12:34:32 +0000 (0:00:00.037)       0:00:08.581 ********* 
included: /runner/project/ansible/roles/agnosticd_save_output_dir/tasks/upload-archive-s3-s3_object.yml for localhost

TASK [agnosticd_save_output_dir : Save output_dir archive to AWS S3] ***********
Monday 04 August 2025  12:34:32 +0000 (0:00:00.035)       0:00:08.617 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Remove output_dir archive tempfile] **********
Monday 04 August 2025  12:34:33 +0000 (0:00:00.916)       0:00:09.534 ********* 
changed: [localhost]

TASK [agnosticd_save_output_dir : Remove output_dir encrypted archive tempfile] ***
Monday 04 August 2025  12:34:33 +0000 (0:00:00.162)       0:00:09.696 ********* 
skipping: [localhost]

TASK [agnosticd_save_output_dir : Save output dir if archive file is defined] ***
Monday 04 August 2025  12:34:33 +0000 (0:00:00.018)       0:00:09.715 ********* 
skipping: [localhost]

TASK [Run infra-openshift-cnv-resources Role] **********************************
Monday 04 August 2025  12:34:33 +0000 (0:00:00.017)       0:00:09.732 ********* 
included: infra-openshift-cnv-resources for localhost

TASK [infra-openshift-cnv-resources : ansible.builtin.include_tasks] ***********
Monday 04 August 2025  12:34:33 +0000 (0:00:00.021)       0:00:09.753 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-resources : ansible.builtin.include_tasks] ***********
Monday 04 August 2025  12:34:33 +0000 (0:00:00.012)       0:00:09.765 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-resources : ansible.builtin.include_tasks] ***********
Monday 04 August 2025  12:34:33 +0000 (0:00:00.014)       0:00:09.779 ********* 
included: /runner/project/ansible/roles-infra/infra-openshift-cnv-resources/tasks/create_networks.yaml for localhost

TASK [infra-openshift-cnv-resources : Create Networks] *************************
Monday 04 August 2025  12:34:33 +0000 (0:00:00.018)       0:00:09.798 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-resources : ansible.builtin.include_tasks] ***********
Monday 04 August 2025  12:34:33 +0000 (0:00:00.016)       0:00:09.815 ********* 
included: /runner/project/ansible/roles-infra/infra-openshift-cnv-resources/tasks/create_instances.yaml for localhost

TASK [ansible.builtin.include_role : infra-cloud-tags] *************************
Monday 04 August 2025  12:34:34 +0000 (0:00:00.024)       0:00:09.839 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-resources : set_fact] ********************************
Monday 04 August 2025  12:34:34 +0000 (0:00:00.065)       0:00:09.905 ********* 
ok: [localhost]

TASK [infra-openshift-cnv-resources : Create Instances] ************************
Monday 04 August 2025  12:34:34 +0000 (0:00:00.055)       0:00:09.960 ********* 
included: /runner/project/ansible/roles-infra/infra-openshift-cnv-resources/tasks/create_instance.yaml for localhost => (item={'name': 'bastion', 'count': 1, 'unique': True, 'alt_name': 'bastion', 'memory': '4Gi', 'cores': 2, 'image_size': '30Gi', 'image': 'rhel-9.5', 'networkdata': 'network: 2', 'userdata': '', 'metadata': [{'AnsibleGroup': 'bastions'}, {'function': 'bastion'}, {'user': 'lab-user'}, {'project': 'ocp4-cluster-v6wwh'}, {'ostype': 'linux'}, {'Purpose': 'prod'}], 'tags': [{'key': 'AnsibleGroup', 'value': 'bastions'}, {'key': 'ostype', 'value': 'linux'}, {'key': 'instance_filter', 'value': 'ocp4-cluster-v6wwh'}], 'networks': ['default']})

TASK [infra-openshift-cnv-resources : Empty variable _instance_] ***************
Monday 04 August 2025  12:34:34 +0000 (0:00:00.127)       0:00:10.087 ********* 
ok: [localhost]

TASK [infra-openshift-cnv-resources : Set the instances interfaces] ************
Monday 04 August 2025  12:34:34 +0000 (0:00:00.027)       0:00:10.115 ********* 
ok: [localhost] => (item=default)

TASK [infra-openshift-cnv-resources : Set the instances disks] *****************
Monday 04 August 2025  12:34:34 +0000 (0:00:00.060)       0:00:10.175 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-resources : Set cloud_config] ************************
Monday 04 August 2025  12:34:34 +0000 (0:00:00.014)       0:00:10.189 ********* 
ok: [localhost]

TASK [infra-openshift-cnv-resources : Set cloud init disk if needed] ***********
Monday 04 August 2025  12:34:34 +0000 (0:00:00.020)       0:00:10.210 ********* 
ok: [localhost]

TASK [infra-openshift-cnv-resources : Create instance(s) "bastion"] ************
Monday 04 August 2025  12:34:34 +0000 (0:00:00.024)       0:00:10.235 ********* 
changed: [localhost] => (item=1)
[WARNING]: unknown field "spec.template.spec.domain.memory.memory"

TASK [infra-openshift-cnv-resources : Wait till VM is running] *****************
Monday 04 August 2025  12:34:35 +0000 (0:00:01.121)       0:00:11.357 ********* 
FAILED - RETRYING: [localhost]: Wait till VM is running (30 retries left).
FAILED - RETRYING: [localhost]: Wait till VM is running (29 retries left).
ok: [localhost] => (item=1)

TASK [infra-openshift-cnv-resources : ansible.builtin.set_fact] ****************
Monday 04 August 2025  12:34:57 +0000 (0:00:22.126)       0:00:33.483 ********* 
ok: [localhost] => (item={'changed': True, 'result': {'apiVersion': 'kubevirt.io/v1', 'kind': 'VirtualMachine', 'metadata': {'annotations': {'AnsibleGroup': 'bastions', 'Purpose': 'prod', 'Stack': 'ocp4-cluster-v6wwh', 'env_type': 'ocp4-cluster', 'function': 'bastion', 'guid': 'v6wwh', 'instance_filter': 'ocp4-cluster-v6wwh', 'ostype': 'linux', 'owner': 'unknown', 'platform': 'rhpds', 'project': 'ocp4-cluster-v6wwh', 'purpose': 'prod', 'user': 'lab-user', 'uuid': '3d7166e0-dfc3-5d0f-a429-f85ac2d630e8'}, 'creationTimestamp': '2025-08-04T12:34:35Z', 'generation': 1, 'managedFields': [{'apiVersion': 'kubevirt.io/v1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'.': {}, 'f:AnsibleGroup': {}, 'f:Purpose': {}, 'f:Stack': {}, 'f:env_type': {}, 'f:function': {}, 'f:guid': {}, 'f:instance_filter': {}, 'f:ostype': {}, 'f:owner': {}, 'f:platform': {}, 'f:project': {}, 'f:purpose': {}, 'f:user': {}, 'f:uuid': {}}}, 'f:spec': {'.': {}, 'f:dataVolumeTemplates': {}, 'f:running': {}, 'f:template': {'.': {}, 'f:metadata': {'.': {}, 'f:labels': {'.': {}, 'f:vm.cnv.io/name': {}}}, 'f:spec': {'.': {}, 'f:domain': {'.': {}, 'f:cpu': {'.': {}, 'f:cores': {}, 'f:model': {}}, 'f:devices': {'.': {}, 'f:disks': {}, 'f:interfaces': {}}, 'f:firmware': {'.': {}, 'f:bootloader': {'.': {}, 'f:bios': {}}, 'f:uuid': {}}, 'f:machine': {'.': {}, 'f:type': {}}, 'f:memory': {'.': {}, 'f:guest': {}}}, 'f:networks': {}, 'f:volumes': {}}}}}, 'manager': 'OpenAPI-Generator', 'operation': 'Update', 'time': '2025-08-04T12:34:35Z'}], 'name': 'bastion', 'namespace': 'sandbox-v6wwh-ocp4-cluster', 'resourceVersion': '246301299', 'uid': 'c952ca3c-bef2-4263-a54e-3a06e5dc5f05'}, 'spec': {'dataVolumeTemplates': [{'metadata': {'creationTimestamp': None, 'name': 'bastion-v6wwh'}, 'spec': {'pvc': {'accessModes': ['ReadWriteMany'], 'resources': {'requests': {'storage': '30Gi'}}, 'volumeMode': 'Block'}, 'source': {'pvc': {'name': 'rhel-9.5', 'namespace': 'cnv-images'}}}}], 'running': True, 'template': {'metadata': {'creationTimestamp': None, 'labels': {'vm.cnv.io/name': 'bastion'}}, 'spec': {'architecture': 'amd64', 'domain': {'cpu': {'cores': 2, 'model': 'host-passthrough'}, 'devices': {'disks': [{'disk': {'bus': 'virtio'}, 'name': 'bastion-v6wwh'}, {'disk': {'bus': 'virtio'}, 'name': 'cloudinitdisk'}], 'interfaces': [{'masquerade': {}, 'model': 'e1000e', 'name': 'default', 'pciAddress': '0000:00:03.0'}]}, 'firmware': {'bootloader': {'bios': {}}, 'uuid': '9fabcb02-6baf-5c76-809d-011b875d3fbd'}, 'machine': {'type': 'pc-q35-rhel9.2.0'}, 'memory': {'guest': '4Gi'}, 'resources': {}}, 'networks': [{'name': 'default', 'pod': {}}], 'volumes': [{'dataVolume': {'name': 'bastion-v6wwh'}, 'name': 'bastion-v6wwh'}, {'cloudInitNoCloud': {'networkDataBase64': 'bmV0d29yazogMg==', 'userDataBase64': '[REDACTED_Base64 High Entropy String_SECRET]'}, 'name': 'cloudinitdisk'}]}}}}, 'method': 'create', 'invocation': {'module_args': {'host': 'https://api.ocpv08.dal10.infra.demo.redhat.com:6443', 'api_key': '[REDACTED_Secret Keyword_SECRET]', 'validate_certs': False, 'definition': {'apiVersion': 'kubevirt.io/v1', 'kind': 'VirtualMachine', 'metadata': {'name': 'bastion', 'namespace': 'sandbox-v6wwh-ocp4-cluster', 'annotations': {'Stack': 'ocp4-cluster-v6wwh', 'owner': 'unknown', 'env_type': 'ocp4-cluster', 'guid': 'v6wwh', 'uuid': '3d7166e0-dfc3-5d0f-a429-f85ac2d630e8', 'platform': 'rhpds', 'purpose': 'prod', 'AnsibleGroup': 'bastions', 'function': 'bastion', 'user': 'lab-user', 'project': 'ocp4-cluster-v6wwh', 'ostype': 'linux', 'Purpose': 'prod', 'instance_filter': 'ocp4-cluster-v6wwh'}}, 'spec': {'dataVolumeTemplates': [{'metadata': {'name': 'bastion-v6wwh'}, 'spec': {'source': {'pvc': {'namespace': 'cnv-images', 'name': 'rhel-9.5'}}, 'pvc': {'accessModes': ['ReadWriteMany'], 'volumeMode': 'Block', 'resources': {'requests': {'storage': '30Gi'}}}}}], 'running': True, 'template': {'metadata': {'labels': {'vm.cnv.io/name': 'bastion'}}, 'spec': {'domain': {'firmware': {'uuid': '9fabcb02-6baf-5c76-809d-011b875d3fbd', 'bootloader': {'bios': {}}}, 'cpu': {'cores': 2, 'model': 'host-passthrough'}, 'machine': {'type': 'pc-q35-rhel9.2.0'}, 'memory': {'guest': '4Gi', 'memory': {'hugepages': {'pageSize': '1Gi'}}}, 'devices': {'disks': [{'disk': {'bus': 'virtio'}, 'name': 'bastion-v6wwh'}, {'disk': {'bus': 'virtio'}, 'name': 'cloudinitdisk'}], 'interfaces': [{'name': 'default', 'model': 'e1000e', 'pciAddress': '0000:00:03.0', 'masquerade': {}}]}}, 'networks': [{'name': 'default', 'pod': {}}], 'volumes': [{'dataVolume': {'name': 'bastion-v6wwh'}, 'name': 'bastion-v6wwh'}, {'name': 'cloudinitdisk', 'cloudInitNoCloud': {'userDataBase64': '[REDACTED_Base64 High Entropy String_SECRET]', 'networkDataBase64': 'bmV0d29yazogMg=='}}]}}}}, 'resource_definition': {'apiVersion': 'kubevirt.io/v1', 'kind': 'VirtualMachine', 'metadata': {'name': 'bastion', 'namespace': 'sandbox-v6wwh-ocp4-cluster', 'annotations': {'Stack': 'ocp4-cluster-v6wwh', 'owner': 'unknown', 'env_type': 'ocp4-cluster', 'guid': 'v6wwh', 'uuid': '3d7166e0-dfc3-5d0f-a429-f85ac2d630e8', 'platform': 'rhpds', 'purpose': 'prod', 'AnsibleGroup': 'bastions', 'function': 'bastion', 'user': 'lab-user', 'project': 'ocp4-cluster-v6wwh', 'ostype': 'linux', 'Purpose': 'prod', 'instance_filter': 'ocp4-cluster-v6wwh'}}, 'spec': {'dataVolumeTemplates': [{'metadata': {'name': 'bastion-v6wwh'}, 'spec': {'source': {'pvc': {'namespace': 'cnv-images', 'name': 'rhel-9.5'}}, 'pvc': {'accessModes': ['ReadWriteMany'], 'volumeMode': 'Block', 'resources': {'requests': {'storage': '30Gi'}}}}}], 'running': True, 'template': {'metadata': {'labels': {'vm.cnv.io/name': 'bastion'}}, 'spec': {'domain': {'firmware': {'uuid': '9fabcb02-6baf-5c76-809d-011b875d3fbd', 'bootloader': {'bios': {}}}, 'cpu': {'cores': 2, 'model': 'host-passthrough'}, 'machine': {'type': 'pc-q35-rhel9.2.0'}, 'memory': {'guest': '4Gi', 'memory': {'hugepages': {'pageSize': '1Gi'}}}, 'devices': {'disks': [{'disk': {'bus': 'virtio'}, 'name': 'bastion-v6wwh'}, {'disk': {'bus': 'virtio'}, 'name': 'cloudinitdisk'}], 'interfaces': [{'name': 'default', 'model': 'e1000e', 'pciAddress': '0000:00:03.0', 'masquerade': {}}]}}, 'networks': [{'name': 'default', 'pod': {}}], 'volumes': [{'dataVolume': {'name': 'bastion-v6wwh'}, 'name': 'bastion-v6wwh'}, {'name': 'cloudinitdisk', 'cloudInitNoCloud': {'userDataBase64': '[REDACTED_Base64 High Entropy String_SECRET]', 'networkDataBase64': 'bmV0d29yazogMg=='}}]}}}}, 'api_version': 'v1', 'wait': False, 'wait_sleep': 5, 'wait_timeout': 120, 'append_hash': False, 'apply': False, 'continue_on_error': False, 'state': 'present', 'force': False, 'delete_all': False, 'kind': None, 'name': None, 'namespace': None, 'src': None, 'kubeconfig': None, 'context': None, 'username': None, 'password': None, 'ca_cert': None, 'client_cert': None, 'client_key': None, 'proxy': None, 'no_proxy': None, 'proxy_headers': None, 'persist_config': None, 'impersonate_user': None, 'impersonate_groups': None, 'wait_condition': None, 'merge_type': None, 'validate': None, 'template': None, 'delete_options': None, 'label_selectors': None, 'generate_name': None, 'server_side_apply': None, 'hidden_fields': None}}, 'failed': False, 'attempts': 1, 'item': 1, 'ansible_loop_var': 'item', '_index': 0, 'ansible_index_var': '_index'})

TASK [infra-openshift-cnv-resources : Create services for the nodes] ***********
Monday 04 August 2025  12:34:57 +0000 (0:00:00.052)       0:00:33.535 ********* 
included: /runner/project/ansible/roles-infra/infra-openshift-cnv-resources/tasks/create_services.yaml for localhost => (item={'name': 'bastion', 'count': 1, 'unique': True, 'alt_name': 'bastion', 'memory': '4Gi', 'cores': 2, 'image_size': '30Gi', 'image': 'rhel-9.5', 'networkdata': 'network: 2', 'userdata': '', 'metadata': [{'AnsibleGroup': 'bastions'}, {'function': 'bastion'}, {'user': 'lab-user'}, {'project': 'ocp4-cluster-v6wwh'}, {'ostype': 'linux'}, {'Purpose': 'prod'}], 'tags': [{'key': 'AnsibleGroup', 'value': 'bastions'}, {'key': 'ostype', 'value': 'linux'}, {'key': 'instance_filter', 'value': 'ocp4-cluster-v6wwh'}], 'networks': ['default']})

TASK [infra-openshift-cnv-resources : Create a SSH (or defined one) service for internal connections for node bastion] ***
Monday 04 August 2025  12:34:57 +0000 (0:00:00.036)       0:00:33.572 ********* 
changed: [localhost] => (item=1)

TASK [infra-openshift-cnv-resources : Create services for the instances] *******
Monday 04 August 2025  12:34:58 +0000 (0:00:00.739)       0:00:34.311 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-resources : Create routes for the nodes] *************
Monday 04 August 2025  12:34:58 +0000 (0:00:00.013)       0:00:34.325 ********* 
included: /runner/project/ansible/roles-infra/infra-openshift-cnv-resources/tasks/create_routes.yaml for localhost => (item={'name': 'bastion', 'count': 1, 'unique': True, 'alt_name': 'bastion', 'memory': '4Gi', 'cores': 2, 'image_size': '30Gi', 'image': 'rhel-9.5', 'networkdata': 'network: 2', 'userdata': '', 'metadata': [{'AnsibleGroup': 'bastions'}, {'function': 'bastion'}, {'user': 'lab-user'}, {'project': 'ocp4-cluster-v6wwh'}, {'ostype': 'linux'}, {'Purpose': 'prod'}], 'tags': [{'key': 'AnsibleGroup', 'value': 'bastions'}, {'key': 'ostype', 'value': 'linux'}, {'key': 'instance_filter', 'value': 'ocp4-cluster-v6wwh'}], 'networks': ['default']})

TASK [infra-openshift-cnv-resources : Create routes with tls] ******************
Monday 04 August 2025  12:34:58 +0000 (0:00:00.035)       0:00:34.360 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-resources : Create routes without tls] ***************
Monday 04 August 2025  12:34:58 +0000 (0:00:00.018)       0:00:34.379 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-resources : ansible.builtin.include_tasks] ***********
Monday 04 August 2025  12:34:58 +0000 (0:00:00.018)       0:00:34.398 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-resources : ansible.builtin.include_tasks] ***********
Monday 04 August 2025  12:34:58 +0000 (0:00:00.014)       0:00:34.413 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-resources : ansible.builtin.include_tasks] ***********
Monday 04 August 2025  12:34:58 +0000 (0:00:00.013)       0:00:34.426 ********* 
skipping: [localhost]

PLAY [Step 001.2 Create Inventory and SSH config setup] ************************

TASK [Run infra-dns Role] ******************************************************
Monday 04 August 2025  12:34:58 +0000 (0:00:00.017)       0:00:34.444 ********* 
included: infra-dns for localhost

TASK [infra-dns : fail] ********************************************************
Monday 04 August 2025  12:34:58 +0000 (0:00:00.041)       0:00:34.486 ********* 
skipping: [localhost]

TASK [infra-dns : defensive programming, guess base_domain using route53_zone] ***
Monday 04 August 2025  12:34:58 +0000 (0:00:00.015)       0:00:34.502 ********* 
skipping: [localhost]

TASK [infra-dns : defensive programming, guess base_domain using cluster_dns_zone] ***
Monday 04 August 2025  12:34:58 +0000 (0:00:00.027)       0:00:34.529 ********* 
skipping: [localhost]

TASK [infra-dns : fail] ********************************************************
Monday 04 August 2025  12:34:58 +0000 (0:00:00.027)       0:00:34.557 ********* 
skipping: [localhost]

TASK [infra-dns : Iterate over all instances and create DNS entries] ***********
Monday 04 August 2025  12:34:58 +0000 (0:00:00.050)       0:00:34.608 ********* 
skipping: [localhost] => (item={'name': 'bastion', 'count': 1, 'unique': True, 'alt_name': 'bastion', 'memory': '4Gi', 'cores': 2, 'image_size': '30Gi', 'image': 'rhel-9.5', 'networkdata': 'network: 2', 'userdata': '', 'metadata': [{'AnsibleGroup': 'bastions'}, {'function': 'bastion'}, {'user': 'lab-user'}, {'project': 'ocp4-cluster-v6wwh'}, {'ostype': 'linux'}, {'Purpose': 'prod'}], 'tags': [{'key': 'AnsibleGroup', 'value': 'bastions'}, {'key': 'ostype', 'value': 'linux'}, {'key': 'instance_filter', 'value': 'ocp4-cluster-v6wwh'}], 'networks': ['default']}) 
skipping: [localhost]

TASK [infra-openshift-cnv-create-inventory : include_tasks] ********************
Monday 04 August 2025  12:34:58 +0000 (0:00:00.034)       0:00:34.642 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-create-inventory : ansible.builtin.include_tasks] ****
Monday 04 August 2025  12:34:58 +0000 (0:00:00.017)       0:00:34.659 ********* 
included: /runner/project/ansible/roles-infra/infra-openshift-cnv-create-inventory/tasks/create_inventory.yaml for localhost

TASK [infra-openshift-cnv-create-inventory : Search for all running pods] ******
Monday 04 August 2025  12:34:58 +0000 (0:00:00.020)       0:00:34.679 ********* 
ok: [localhost]

TASK [infra-openshift-cnv-create-inventory : Debug OpenShift CNV Instances fact] ***
Monday 04 August 2025  12:34:59 +0000 (0:00:00.678)       0:00:35.358 ********* 
skipping: [localhost]

TASK [infra-openshift-cnv-create-inventory : Find the bastion in this batch of hosts] ***
Monday 04 August 2025  12:34:59 +0000 (0:00:00.019)       0:00:35.378 ********* 
ok: [localhost] => (item={'apiVersion': 'kubevirt.io/v1', 'kind': 'VirtualMachine', 'metadata': {'annotations': {'AnsibleGroup': 'bastions', 'Purpose': 'prod', 'Stack': 'ocp4-cluster-v6wwh', 'env_type': 'ocp4-cluster', 'function': 'bastion', 'guid': 'v6wwh', 'instance_filter': 'ocp4-cluster-v6wwh', 'kubevirt.io/latest-observed-api-version': 'v1', 'kubevirt.io/storage-observed-api-version': 'v1', 'ostype': 'linux', 'owner': 'unknown', 'platform': 'rhpds', 'project': 'ocp4-cluster-v6wwh', 'purpose': 'prod', 'user': 'lab-user', 'uuid': '3d7166e0-dfc3-5d0f-a429-f85ac2d630e8'}, 'creationTimestamp': '2025-08-04T12:34:35Z', 'finalizers': ['kubevirt.io/virtualMachineControllerFinalize'], 'generation': 1, 'managedFields': [{'apiVersion': 'kubevirt.io/v1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'.': {}, 'f:AnsibleGroup': {}, 'f:Purpose': {}, 'f:Stack': {}, 'f:env_type': {}, 'f:function': {}, 'f:guid': {}, 'f:instance_filter': {}, 'f:ostype': {}, 'f:owner': {}, 'f:platform': {}, 'f:project': {}, 'f:purpose': {}, 'f:user': {}, 'f:uuid': {}}}, 'f:spec': {'.': {}, 'f:dataVolumeTemplates': {}, 'f:running': {}, 'f:template': {'.': {}, 'f:metadata': {'.': {}, 'f:labels': {'.': {}, 'f:vm.cnv.io/name': {}}}, 'f:spec': {'.': {}, 'f:domain': {'.': {}, 'f:cpu': {'.': {}, 'f:cores': {}, 'f:model': {}}, 'f:devices': {'.': {}, 'f:disks': {}, 'f:interfaces': {}}, 'f:firmware': {'.': {}, 'f:bootloader': {'.': {}, 'f:bios': {}}, 'f:uuid': {}}, 'f:machine': {'.': {}, 'f:type': {}}, 'f:memory': {'.': {}, 'f:guest': {}}}, 'f:networks': {}, 'f:volumes': {}}}}}, 'manager': 'OpenAPI-Generator', 'operation': 'Update', 'time': '2025-08-04T12:34:35Z'}, {'apiVersion': 'kubevirt.io/v1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'f:kubevirt.io/latest-observed-api-version': {}, 'f:kubevirt.io/storage-observed-api-version': {}}, 'f:finalizers': {'.': {}, 'v:"kubevirt.io/virtualMachineControllerFinalize"': {}}}}, 'manager': 'virt-controller', 'operation': 'Update', 'time': '2025-08-04T12:34:35Z'}, {'apiVersion': 'kubevirt.io/v1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:status': {'.': {}, 'f:conditions': {}, 'f:created': {}, 'f:desiredGeneration': {}, 'f:observedGeneration': {}, 'f:printableStatus': {}, 'f:ready': {}, 'f:runStrategy': {}, 'f:volumeSnapshotStatuses': {}}}, 'manager': 'virt-controller', 'operation': 'Update', 'subresource': 'status', 'time': '2025-08-04T12:34:50Z'}], 'name': 'bastion', 'namespace': 'sandbox-v6wwh-ocp4-cluster', 'resourceVersion': '246301841', 'uid': 'c952ca3c-bef2-4263-a54e-3a06e5dc5f05'}, 'spec': {'dataVolumeTemplates': [{'metadata': {'creationTimestamp': None, 'name': 'bastion-v6wwh'}, 'spec': {'pvc': {'accessModes': ['ReadWriteMany'], 'resources': {'requests': {'storage': '30Gi'}}, 'volumeMode': 'Block'}, 'source': {'pvc': {'name': 'rhel-9.5', 'namespace': 'cnv-images'}}}}], 'running': True, 'template': {'metadata': {'creationTimestamp': None, 'labels': {'vm.cnv.io/name': 'bastion'}}, 'spec': {'architecture': 'amd64', 'domain': {'cpu': {'cores': 2, 'model': 'host-passthrough'}, 'devices': {'disks': [{'disk': {'bus': 'virtio'}, 'name': 'bastion-v6wwh'}, {'disk': {'bus': 'virtio'}, 'name': 'cloudinitdisk'}], 'interfaces': [{'masquerade': {}, 'model': 'e1000e', 'name': 'default', 'pciAddress': '0000:00:03.0'}]}, 'firmware': {'bootloader': {'bios': {}}, 'uuid': '9fabcb02-6baf-5c76-809d-011b875d3fbd'}, 'machine': {'type': 'pc-q35-rhel9.2.0'}, 'memory': {'guest': '4Gi'}, 'resources': {}}, 'networks': [{'name': 'default', 'pod': {}}], 'volumes': [{'dataVolume': {'name': 'bastion-v6wwh'}, 'name': 'bastion-v6wwh'}, {'cloudInitNoCloud': {'networkDataBase64': 'bmV0d29yazogMg==', 'userDataBase64': '[REDACTED_Base64 High Entropy String_SECRET]'}, 'name': 'cloudinitdisk'}]}}}, 'status': {'conditions': [{'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T12:34:47Z', 'status': 'True', 'type': 'Ready'}, {'lastProbeTime': None, 'lastTransitionTime': None, 'message': "All of the VMI's DVs are bound and not running", 'reason': 'AllDVsReady', 'status': 'True', 'type': 'DataVolumesReady'}, {'lastProbeTime': None, 'lastTransitionTime': None, 'status': 'True', 'type': 'LiveMigratable'}], 'created': True, 'desiredGeneration': 1, 'observedGeneration': 1, 'printableStatus': 'Running', 'ready': True, 'runStrategy': 'Always', 'volumeSnapshotStatuses': [{'enabled': True, 'name': 'bastion-v6wwh'}, {'enabled': False, 'name': 'cloudinitdisk', 'reason': 'Snapshot is not supported for this volumeSource type [cloudinitdisk]'}]}})

TASK [infra-openshift-cnv-create-inventory : Expose bastion externally] ********
Monday 04 August 2025  12:34:59 +0000 (0:00:00.033)       0:00:35.411 ********* 
changed: [localhost]

TASK [infra-openshift-cnv-create-inventory : Create inventory (add_host)] ******
Monday 04 August 2025  12:35:00 +0000 (0:00:00.702)       0:00:36.114 ********* 
changed: [localhost] => (item={'apiVersion': 'kubevirt.io/v1', 'kind': 'VirtualMachine', 'metadata': {'annotations': {'AnsibleGroup': 'bastions', 'Purpose': 'prod', 'Stack': 'ocp4-cluster-v6wwh', 'env_type': 'ocp4-cluster', 'function': 'bastion', 'guid': 'v6wwh', 'instance_filter': 'ocp4-cluster-v6wwh', 'kubevirt.io/latest-observed-api-version': 'v1', 'kubevirt.io/storage-observed-api-version': 'v1', 'ostype': 'linux', 'owner': 'unknown', 'platform': 'rhpds', 'project': 'ocp4-cluster-v6wwh', 'purpose': 'prod', 'user': 'lab-user', 'uuid': '3d7166e0-dfc3-5d0f-a429-f85ac2d630e8'}, 'creationTimestamp': '2025-08-04T12:34:35Z', 'finalizers': ['kubevirt.io/virtualMachineControllerFinalize'], 'generation': 1, 'managedFields': [{'apiVersion': 'kubevirt.io/v1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'.': {}, 'f:AnsibleGroup': {}, 'f:Purpose': {}, 'f:Stack': {}, 'f:env_type': {}, 'f:function': {}, 'f:guid': {}, 'f:instance_filter': {}, 'f:ostype': {}, 'f:owner': {}, 'f:platform': {}, 'f:project': {}, 'f:purpose': {}, 'f:user': {}, 'f:uuid': {}}}, 'f:spec': {'.': {}, 'f:dataVolumeTemplates': {}, 'f:running': {}, 'f:template': {'.': {}, 'f:metadata': {'.': {}, 'f:labels': {'.': {}, 'f:vm.cnv.io/name': {}}}, 'f:spec': {'.': {}, 'f:domain': {'.': {}, 'f:cpu': {'.': {}, 'f:cores': {}, 'f:model': {}}, 'f:devices': {'.': {}, 'f:disks': {}, 'f:interfaces': {}}, 'f:firmware': {'.': {}, 'f:bootloader': {'.': {}, 'f:bios': {}}, 'f:uuid': {}}, 'f:machine': {'.': {}, 'f:type': {}}, 'f:memory': {'.': {}, 'f:guest': {}}}, 'f:networks': {}, 'f:volumes': {}}}}}, 'manager': 'OpenAPI-Generator', 'operation': 'Update', 'time': '2025-08-04T12:34:35Z'}, {'apiVersion': 'kubevirt.io/v1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'f:kubevirt.io/latest-observed-api-version': {}, 'f:kubevirt.io/storage-observed-api-version': {}}, 'f:finalizers': {'.': {}, 'v:"kubevirt.io/virtualMachineControllerFinalize"': {}}}}, 'manager': 'virt-controller', 'operation': 'Update', 'time': '2025-08-04T12:34:35Z'}, {'apiVersion': 'kubevirt.io/v1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:status': {'.': {}, 'f:conditions': {}, 'f:created': {}, 'f:desiredGeneration': {}, 'f:observedGeneration': {}, 'f:printableStatus': {}, 'f:ready': {}, 'f:runStrategy': {}, 'f:volumeSnapshotStatuses': {}}}, 'manager': 'virt-controller', 'operation': 'Update', 'subresource': 'status', 'time': '2025-08-04T12:34:50Z'}], 'name': 'bastion', 'namespace': 'sandbox-v6wwh-ocp4-cluster', 'resourceVersion': '246301841', 'uid': 'c952ca3c-bef2-4263-a54e-3a06e5dc5f05'}, 'spec': {'dataVolumeTemplates': [{'metadata': {'creationTimestamp': None, 'name': 'bastion-v6wwh'}, 'spec': {'pvc': {'accessModes': ['ReadWriteMany'], 'resources': {'requests': {'storage': '30Gi'}}, 'volumeMode': 'Block'}, 'source': {'pvc': {'name': 'rhel-9.5', 'namespace': 'cnv-images'}}}}], 'running': True, 'template': {'metadata': {'creationTimestamp': None, 'labels': {'vm.cnv.io/name': 'bastion'}}, 'spec': {'architecture': 'amd64', 'domain': {'cpu': {'cores': 2, 'model': 'host-passthrough'}, 'devices': {'disks': [{'disk': {'bus': 'virtio'}, 'name': 'bastion-v6wwh'}, {'disk': {'bus': 'virtio'}, 'name': 'cloudinitdisk'}], 'interfaces': [{'masquerade': {}, 'model': 'e1000e', 'name': 'default', 'pciAddress': '0000:00:03.0'}]}, 'firmware': {'bootloader': {'bios': {}}, 'uuid': '9fabcb02-6baf-5c76-809d-011b875d3fbd'}, 'machine': {'type': 'pc-q35-rhel9.2.0'}, 'memory': {'guest': '4Gi'}, 'resources': {}}, 'networks': [{'name': 'default', 'pod': {}}], 'volumes': [{'dataVolume': {'name': 'bastion-v6wwh'}, 'name': 'bastion-v6wwh'}, {'cloudInitNoCloud': {'networkDataBase64': 'bmV0d29yazogMg==', 'userDataBase64': '[REDACTED_Base64 High Entropy String_SECRET]'}, 'name': 'cloudinitdisk'}]}}}, 'status': {'conditions': [{'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T12:34:47Z', 'status': 'True', 'type': 'Ready'}, {'lastProbeTime': None, 'lastTransitionTime': None, 'message': "All of the VMI's DVs are bound and not running", 'reason': 'AllDVsReady', 'status': 'True', 'type': 'DataVolumesReady'}, {'lastProbeTime': None, 'lastTransitionTime': None, 'status': 'True', 'type': 'LiveMigratable'}], 'created': True, 'desiredGeneration': 1, 'observedGeneration': 1, 'printableStatus': 'Running', 'ready': True, 'runStrategy': 'Always', 'volumeSnapshotStatuses': [{'enabled': True, 'name': 'bastion-v6wwh'}, {'enabled': False, 'name': 'cloudinitdisk', 'reason': 'Snapshot is not supported for this volumeSource type [cloudinitdisk]'}]}})

TASK [infra-common-ssh-config-generate : Store bastion hostname as a fact] *****
Monday 04 August 2025  12:35:00 +0000 (0:00:00.043)       0:00:36.157 ********* 
ok: [localhost]

TASK [infra-common-ssh-config-generate : Delete dedicated known_host if it exists (new deployment)] ***
Monday 04 August 2025  12:35:00 +0000 (0:00:00.025)       0:00:36.183 ********* 
ok: [localhost]

TASK [infra-common-ssh-config-generate : delete local ssh config, start fresh] ***
Monday 04 August 2025  12:35:00 +0000 (0:00:00.162)       0:00:36.345 ********* 
ok: [localhost]

TASK [infra-common-ssh-config-generate : Create empty local ssh config] ********
Monday 04 August 2025  12:35:00 +0000 (0:00:00.182)       0:00:36.528 ********* 
changed: [localhost]

TASK [infra-common-ssh-config-generate : Add bastion proxy config to workdir ssh config file] ***
Monday 04 August 2025  12:35:00 +0000 (0:00:00.185)       0:00:36.713 ********* 
changed: [localhost]

TASK [infra-common-ssh-config-generate : Add all hosts to workdir ssh config file] ***
Monday 04 August 2025  12:35:01 +0000 (0:00:00.229)       0:00:36.942 ********* 
skipping: [localhost] => (item=bastion) 
skipping: [localhost]

PLAY [Step 0000 Include Vars] **************************************************

TASK [Set output_dir for all hosts] ********************************************
Monday 04 August 2025  12:35:01 +0000 (0:00:00.029)       0:00:36.971 ********* 
ok: [localhost]
ok: [bastion]

TASK [Include variables files] *************************************************
Monday 04 August 2025  12:35:01 +0000 (0:00:00.024)       0:00:36.995 ********* 
skipping: [localhost] => (item=/runner/project/ansible/cloud_providers/openshift_cnv_default_vars.yaml) 
skipping: [localhost] => (item=/runner/project/ansible/cloud_providers/openshift_cnv_default_vars.yml) 
skipping: [bastion] => (item=/runner/project/ansible/cloud_providers/openshift_cnv_default_vars.yaml) 
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/env_vars.yaml) 
skipping: [bastion] => (item=/runner/project/ansible/cloud_providers/openshift_cnv_default_vars.yml) 
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/env_vars.yml) 
skipping: [bastion] => (item=/runner/project/ansible/configs/ocp4-cluster/env_vars.yaml) 
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars.yaml) 
skipping: [bastion] => (item=/runner/project/ansible/configs/ocp4-cluster/env_vars.yml) 
skipping: [bastion] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars.yaml) 
ok: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars.yml)
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars_openshift_cnv.yaml) 
ok: [bastion] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars.yml)
skipping: [bastion] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars_openshift_cnv.yaml) 
ok: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars_openshift_cnv.yml)
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/env_secret_vars.yaml) 
ok: [bastion] => (item=/runner/project/ansible/configs/ocp4-cluster/default_vars_openshift_cnv.yml)
skipping: [localhost] => (item=/runner/project/ansible/configs/ocp4-cluster/env_secret_vars.yml) 
skipping: [bastion] => (item=/runner/project/ansible/configs/ocp4-cluster/env_secret_vars.yaml) 
skipping: [bastion] => (item=/runner/project/ansible/configs/ocp4-cluster/env_secret_vars.yml) 

TASK [Include secret_file if passed as extra-var] ******************************
Monday 04 August 2025  12:35:01 +0000 (0:00:00.060)       0:00:37.056 ********* 
skipping: [localhost]
skipping: [bastion]

TASK [Set passthrough user data] ***********************************************
Monday 04 August 2025  12:35:01 +0000 (0:00:00.019)       0:00:37.075 ********* 
skipping: [localhost]
[WARNING]: Could not match supplied host pattern, ignoring: windows
[WARNING]: Could not match supplied host pattern, ignoring: network

PLAY [Step 001.3 Configure Linux Hosts and Wait for Connection] ****************

TASK [set facts for remote access] *********************************************
Monday 04 August 2025  12:35:01 +0000 (0:00:00.017)       0:00:37.093 ********* 
ok: [bastion]

TASK [Run infra-generic-wait_for_linux_hosts Role] *****************************
Monday 04 August 2025  12:35:01 +0000 (0:00:00.023)       0:00:37.116 ********* 
included: infra-generic-wait_for_linux_hosts for bastion

TASK [infra-generic-wait_for_linux_hosts : wait for linux host to be available] ***
Monday 04 August 2025  12:35:01 +0000 (0:00:00.021)       0:00:37.138 ********* 
ok: [bastion]

TASK [infra-generic-wait_for_linux_hosts : ping] *******************************
Monday 04 August 2025  12:35:33 +0000 (0:00:32.287)       0:01:09.425 ********* 
[WARNING]: Platform linux on host bastion is using the discovered Python
interpreter at /usr/bin/python3.9, but future installation of another Python
interpreter could change the meaning of that path. See
https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.
ok: [bastion]

TASK [Add authorized_keys] *****************************************************
Monday 04 August 2025  12:35:34 +0000 (0:00:01.092)       0:01:10.517 ********* 
included: ssh_authorized_keys for bastion

TASK [ssh_authorized_keys : Add all authorized keys] ***************************
Monday 04 August 2025  12:35:34 +0000 (0:00:00.022)       0:01:10.540 ********* 
changed: [bastion] => (item={'key': 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCvZvn+GL0wTOsAdh1ikIQoqj2Fw/RA6F14O347rgKdpkgOQpGQk1k2gM8wcla2Y1o0bPIzwlNy1oh5o9uNjZDMeDcEXWuXbu0cRBy4pVRhh8a8zAZfssnqoXHHLyPyHWpdTmgIhr0UIGYrzHrnySAnUcDp3gJuE46UEBtrlyv94cVvZf+EZUTaZ+2KjTRLoNryCn7vKoGHQBooYg1DeHLcLSRWEADUo+bP0y64+X/XTMZOAXbf8kTXocqAgfl/usbYdfLOgwU6zWuj8vxzAKuMEXS1AJSp5aeqRKlbbw40IkTmLoQIgJdb2Zt98BH/xHDe9xxhscUCfWeS37XLp75J opentlc_admin_backdoor'})
changed: [bastion] => (item={'key': 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCg5PJgwAB8U2NiXh4aRZAg09f3xjT3y1CP322StmT4ljiqhXoqOOZ++qDIKFmtHGmeEjvkCo11M2oVmJTeaibeS0E+Xsoi9wTcit47h2ka7WPdzhy/togFQOVAftbwi3RtHDOweIFL18FQ8inhu9W/oFibsZjQEWtHoHtLkmA5zOSQtWDmVfx3iWrKd4svkNbJ+SNZMnD0tCDoot3y0Knzyt+wpZtVd94YXpUDTCJ8Ie1nFSdm7H/QB9/bDXeOSSnHBq2xSmywodNoyA1gFZ1hhpPNEauQjzeKCMpNLPATg/jtQb1zojG6QnO/7I5euKOlDeJ1Odg35aTG31p8EbT3UL8NZssdn3YY3OEQ/2rN0PaQ+zxzmzfh1otx4Rsh1IbD5S99GuQD2ma7m0zOzrBb8Mil5TCaTaK8mIADq/lclj0sAMrH1EXyFvDiHEG+cV0iMyXOxEMTJs4YLr8DyqsTZ34TvVSJP9/0YwQuRYhg0MJmFbMvl/4yibTgyvTYLN0= instructor-key-2022'})
changed: [bastion] => (item={'key': 'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIIIDDIOD4M5yYo3uCFDBDb6del+NG2fkboWh90kW/S6H elliptical_instructor_key_2024'})
changed: [bastion] => (item={'key': 'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOBfsRMLCEQt86EZnvQ/rK49wo1odLqpd1NEz3tDjUWY elliptical_admin_key_2023'})
changed: [bastion] => (item={'key': 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQC3nKRSIwWn7pjMf2i1TyXgjsauEIoDS8Xulad2ZAbsmZrWcKU5hPi23xq0g2AjRYiXml8zSX9jAQfmlKnrXGYo5WN39iXGRI3lFJmXwmEHne3Z0qtUgt9MBA4w0Tcunw7pXniKntvo2oiDYZlXHztRMHMeUkUjLgCGjn2cfi0uqd4pxLmneMziHMKDxcyy+9MaGnWr5Bs27r3b6rWNFqG2fAo1Z5ZWEA/r3MhdI9ZzMRJVTUhunpstwMX8MRxx/OGk0zynyHcSkh91sqZ3xhPpvRkmYLRa5I0aw88AMenWBfc586FyORL2e/UVoIoyMkBMnovaRIoiTj74RuPeZ6gGKbbfpt1ggDs4j9Z1Go51GlGPYcchvLQvx+Ucv5+tLZSqZBhPOXLRqFuQgRZz4R6j5O5UkfdjLJxBoHQZxT0Wdzd/XiGcAlyDOq8puNSxdF3w/8eGGSKDdUONv1tc1dcTFd6kR+jYaedjD1fldVrC+4fRUFkFqEovDPVI4159VSqJWz78WuqazNnCRMVDnS4Le+Er1pvTbk5rOdYUkF67vxVwD3cyJ3D1C49wVsIc3+kngZN2246OEMsbVugEPG4A8/UOlHIE5iBps+mM9GX6UFSj4aLFh15XeOGKs7aH2r1thfvFPSvk12t8QvNDhhhhAf5EzzypvNEbXQ6fk3YSUw== rsa_admin_key_2023'})

TASK [ssh_authorized_keys : Add all authorized keys (legacy var all_ssh_authorized_keys)] ***
Monday 04 August 2025  12:35:39 +0000 (0:00:04.657)       0:01:15.197 ********* 
skipping: [bastion]

PLAY [Step 002 - Post Infrastructure] ******************************************

TASK [All-Cloud Post Infrastructure] *******************************************
Monday 04 August 2025  12:35:39 +0000 (0:00:00.016)       0:01:15.214 ********* 
ok: [localhost] => {
    "changed": false,
    "data": {
        "cloud_provider": "openshift_cnv",
        "guid": "v6wwh"
    }
}

TASK [OpenShift Floating IPs on OpenStack] *************************************
Monday 04 August 2025  12:35:39 +0000 (0:00:00.019)       0:01:15.233 ********* 
skipping: [localhost]

TASK [Create secret for SSH Key] ***********************************************
Monday 04 August 2025  12:35:39 +0000 (0:00:00.013)       0:01:15.247 ********* 
skipping: [localhost]

TASK [Save Route53User credentials from stack outputs] *************************
Monday 04 August 2025  12:35:39 +0000 (0:00:00.013)       0:01:15.261 ********* 
skipping: [localhost]

TASK [Set FQDN for the bastion VM] *********************************************
Monday 04 August 2025  12:35:39 +0000 (0:00:00.013)       0:01:15.275 ********* 
skipping: [localhost]

TASK [Set FQDN for each Windows VM] ********************************************
Monday 04 August 2025  12:35:39 +0000 (0:00:00.014)       0:01:15.289 ********* 
skipping: [localhost]

TASK [Set FQDN for each Windows VM] ********************************************
Monday 04 August 2025  12:35:39 +0000 (0:00:00.013)       0:01:15.303 ********* 
skipping: [localhost]

TASK [Print Host Information] **************************************************
Monday 04 August 2025  12:35:39 +0000 (0:00:00.013)       0:01:15.317 ********* 
skipping: [localhost]

PLAY [Step 002 Post Infrastructure regreSSHion hotfix] *************************

TASK [Gathering Facts] *********************************************************
Monday 04 August 2025  12:35:39 +0000 (0:00:00.017)       0:01:15.334 ********* 
ok: [bastion]

TASK [Have facts been gathered?] ***********************************************
Monday 04 August 2025  12:35:41 +0000 (0:00:01.668)       0:01:17.003 ********* 
ok: [bastion]

TASK [Set sshd LoginGraceTime to 0 in /etc/ssh/sshd_config] ********************
Monday 04 August 2025  12:35:42 +0000 (0:00:01.037)       0:01:18.040 ********* 
changed: [bastion]

TASK [Restart SSH service for regreSSHion fix] *********************************
Monday 04 August 2025  12:35:43 +0000 (0:00:00.950)       0:01:18.991 ********* 
changed: [bastion]

PLAY [localhost] ***************************************************************

TASK [Export in-memory inventory to inventory file] ****************************
Monday 04 August 2025  12:35:44 +0000 (0:00:01.265)       0:01:20.257 ********* 
skipping: [localhost]

PLAY [Step 003 - Pre Software] *************************************************

TASK [Print debug message] *****************************************************
Monday 04 August 2025  12:35:44 +0000 (0:00:00.016)       0:01:20.274 ********* 
ok: [localhost] => {
    "msg": "Step 003 - Pre Software"
}
[WARNING]: Could not match supplied host pattern, ignoring: isolated

PLAY [Step 003.1 Configure all hosts with repositories, common files and set environment key] ***

TASK [set-repositories : Run setup if gather_facts hasn't been run] ************
Monday 04 August 2025  12:35:44 +0000 (0:00:00.023)       0:01:20.297 ********* 
skipping: [bastion]

TASK [set-repositories : Configure satellite repositories] *********************
Monday 04 August 2025  12:35:44 +0000 (0:00:00.018)       0:01:20.315 ********* 
included: /runner/project/ansible/roles/set-repositories/tasks/satellite-repos.yml for bastion

TASK [set-repositories : sat | Check subscription-manager package existence] ***
Monday 04 August 2025  12:35:44 +0000 (0:00:00.043)       0:01:20.359 ********* 
skipping: [bastion]

TASK [set-repositories : sat | Install subscription-manager package] ***********
Monday 04 August 2025  12:35:44 +0000 (0:00:00.017)       0:01:20.377 ********* 
skipping: [bastion]

TASK [set-repositories : sat | Remove rh-amazon-rhui-client package] ***********
Monday 04 August 2025  12:35:44 +0000 (0:00:00.017)       0:01:20.394 ********* 
skipping: [bastion]

TASK [set-repositories : sat | Unregister the system just in case] *************
Monday 04 August 2025  12:35:44 +0000 (0:00:00.017)       0:01:20.411 ********* 
included: /runner/project/ansible/roles/set-repositories/tasks/unregister.yml for bastion

TASK [set-repositories : unreg | Unregister From Subscription Manager] *********
Monday 04 August 2025  12:35:44 +0000 (0:00:00.024)       0:01:20.436 ********* 
changed: [bastion]

TASK [set-repositories : sat | Install CA certificate from satellite server] ***
Monday 04 August 2025  12:35:46 +0000 (0:00:01.598)       0:01:22.035 ********* 
changed: [bastion]

TASK [set-repositories : sat | Update CA Trust Bundle] *************************
Monday 04 August 2025  12:35:47 +0000 (0:00:01.238)       0:01:23.273 ********* 
changed: [bastion]

TASK [set-repositories : sat | Remove satellite Cert] **************************
Monday 04 August 2025  12:35:49 +0000 (0:00:01.953)       0:01:25.227 ********* 
ok: [bastion]

TASK [set-repositories : sat | Find current repository files] ******************
Monday 04 August 2025  12:35:51 +0000 (0:00:01.710)       0:01:26.938 ********* 
ok: [bastion]

TASK [set-repositories : sat | Remove current repository files] ****************
Monday 04 August 2025  12:35:52 +0000 (0:00:01.031)       0:01:27.969 ********* 
skipping: [bastion]

TASK [set-repositories : sat | Install Satellite CA certificate package] *******
Monday 04 August 2025  12:35:52 +0000 (0:00:00.013)       0:01:27.983 ********* 
changed: [bastion]

TASK [set-repositories : sat | Disable Reporting Of Package Profile to Satellite] ***
Monday 04 August 2025  12:35:55 +0000 (0:00:03.810)       0:01:31.793 ********* 
changed: [bastion]

TASK [set-repositories : sat | Run setup if gather_facts hasn't been run] ******
Monday 04 August 2025  12:35:57 +0000 (0:00:01.140)       0:01:32.934 ********* 
skipping: [bastion]

TASK [set-repositories : Generate UUID for dmi.system.uuid if cloud provider is Equinix Metal] ***
Monday 04 August 2025  12:35:57 +0000 (0:00:00.019)       0:01:32.954 ********* 
skipping: [bastion]

TASK [set-repositories : sat | Set set_repositories_subscription_hostname with randomization] ***
Monday 04 August 2025  12:35:57 +0000 (0:00:00.020)       0:01:32.975 ********* 
ok: [bastion]

TASK [set-repositories : sat | Set network.fqdn in /etc/rhsm/facts/katello.facts] ***
Monday 04 August 2025  12:35:57 +0000 (0:00:00.030)       0:01:33.005 ********* 
changed: [bastion]

TASK [set-repositories : sat | Register with activation-key] *******************
Monday 04 August 2025  12:35:59 +0000 (0:00:01.868)       0:01:34.874 ********* 
skipping: [bastion]

TASK [set-repositories : sat | Register with activation-key with HA] ***********
Monday 04 August 2025  12:35:59 +0000 (0:00:00.019)       0:01:34.893 ********* 
changed: [bastion]

TASK [set-repositories : sat | Enable RHSM to manage repositories] *************
Monday 04 August 2025  12:36:05 +0000 (0:00:05.931)       0:01:40.824 ********* 
changed: [bastion]

TASK [set-repositories : sat | Lock RHEL 9 release to specific version] ********
Monday 04 August 2025  12:36:06 +0000 (0:00:01.269)       0:01:42.094 ********* 
skipping: [bastion]

TASK [set-repositories : sat | Lock RHEL 8 release to specific version] ********
Monday 04 August 2025  12:36:06 +0000 (0:00:00.019)       0:01:42.113 ********* 
skipping: [bastion]

TASK [set-repositories : sat | Lock RHEL 7 release to specific version] ********
Monday 04 August 2025  12:36:06 +0000 (0:00:00.018)       0:01:42.131 ********* 
skipping: [bastion]

TASK [set-repositories : sat | Enable repos] ***********************************
Monday 04 August 2025  12:36:06 +0000 (0:00:00.017)       0:01:42.149 ********* 
changed: [bastion]

TASK [set-repositories : sat | Purge existing repos] ***************************
Monday 04 August 2025  12:36:12 +0000 (0:00:05.670)       0:01:47.820 ********* 
skipping: [bastion]

TASK [set-repositories : sat | Enable repos for RHEL] **************************
Monday 04 August 2025  12:36:12 +0000 (0:00:00.021)       0:01:47.842 ********* 
skipping: [bastion]

TASK [set-repositories : sat | Create the certificate and key files] ***********
Monday 04 August 2025  12:36:12 +0000 (0:00:00.023)       0:01:47.865 ********* 
skipping: [bastion] => (item=/etc/pki/tls/Red_GPTE.key) 
skipping: [bastion] => (item=/etc/pki/tls/Red_GPTE.pem) 
skipping: [bastion]

TASK [set-repositories : sat | Add certificate and key content] ****************
Monday 04 August 2025  12:36:12 +0000 (0:00:00.029)       0:01:47.895 ********* 
skipping: [bastion]

TASK [set-repositories : sat | create open.repo template on host] **************
Monday 04 August 2025  12:36:12 +0000 (0:00:00.021)       0:01:47.917 ********* 
skipping: [bastion]

TASK [set-repositories : sat | clean repositories] *****************************
Monday 04 August 2025  12:36:12 +0000 (0:00:00.019)       0:01:47.937 ********* 
changed: [bastion]

TASK [set-repositories : Unregister from subscription manager] *****************
Monday 04 August 2025  12:36:13 +0000 (0:00:01.641)       0:01:49.579 ********* 
skipping: [bastion]

TASK [common : Deactivate DNS lookup in sshd] **********************************
Monday 04 August 2025  12:36:13 +0000 (0:00:00.023)       0:01:49.602 ********* 
changed: [bastion]

TASK [common : Update all packages] ********************************************
Monday 04 August 2025  12:36:14 +0000 (0:00:00.964)       0:01:50.566 ********* 
ASYNC POLL on bastion: jid=j514748108429.7343 started=1 finished=0
ASYNC POLL on bastion: jid=j514748108429.7343 started=1 finished=0
ASYNC POLL on bastion: jid=j514748108429.7343 started=1 finished=0
ASYNC POLL on bastion: jid=j514748108429.7343 started=1 finished=0
ASYNC POLL on bastion: jid=j514748108429.7343 started=1 finished=0
ASYNC POLL on bastion: jid=j514748108429.7343 started=1 finished=0
ASYNC POLL on bastion: jid=j514748108429.7343 started=1 finished=0
ASYNC POLL on bastion: jid=j514748108429.7343 started=1 finished=0
ASYNC POLL on bastion: jid=j514748108429.7343 started=1 finished=0
ASYNC OK on bastion: jid=j514748108429.7343
changed: [bastion]

TASK [common : Update all packages Legacy] *************************************
Monday 04 August 2025  12:41:25 +0000 (0:05:10.522)       0:07:01.088 ********* 
skipping: [bastion]

TASK [common : Determine if reboot is needed] **********************************
Monday 04 August 2025  12:41:25 +0000 (0:00:00.021)       0:07:01.110 ********* 
ok: [bastion]

TASK [common : Reboot all VMs] *************************************************
Monday 04 August 2025  12:41:27 +0000 (0:00:01.852)       0:07:02.963 ********* 
changed: [bastion]

TASK [common : Update network facts after reboot] ******************************
Monday 04 August 2025  12:42:00 +0000 (0:00:32.941)       0:07:35.904 ********* 
ok: [bastion]

TASK [common : Run setup if gather_facts hasn't been run] **********************
Monday 04 August 2025  12:42:01 +0000 (0:00:01.315)       0:07:37.220 ********* 
skipping: [bastion]

TASK [common : install common packages for RHEL 7] *****************************
Monday 04 August 2025  12:42:01 +0000 (0:00:00.021)       0:07:37.241 ********* 
skipping: [bastion]

TASK [common : install common packages for RHEL 8] *****************************
Monday 04 August 2025  12:42:01 +0000 (0:00:00.030)       0:07:37.272 ********* 
skipping: [bastion]

TASK [common : Set up python alternatives for convenience] *********************
Monday 04 August 2025  12:42:01 +0000 (0:00:00.029)       0:07:37.301 ********* 
skipping: [bastion]

TASK [common : install common packages for RHEL 9] *****************************
Monday 04 August 2025  12:42:01 +0000 (0:00:00.030)       0:07:37.332 ********* 
changed: [bastion]

TASK [common : install extra packages] *****************************************
Monday 04 August 2025  12:43:17 +0000 (0:01:15.649)       0:08:52.982 ********* 
skipping: [bastion]

TASK [common : Update specified packages] **************************************
Monday 04 August 2025  12:43:17 +0000 (0:00:00.020)       0:08:53.002 ********* 
skipping: [bastion]

TASK [common : Determine if reboot is needed] **********************************
Monday 04 August 2025  12:43:17 +0000 (0:00:00.018)       0:08:53.020 ********* 
skipping: [bastion]

TASK [common : Reboot VMs] *****************************************************
Monday 04 August 2025  12:43:17 +0000 (0:00:00.018)       0:08:53.038 ********* 
skipping: [bastion]

TASK [common : Refresh network facts post-reboot] ******************************
Monday 04 August 2025  12:43:17 +0000 (0:00:00.019)       0:08:53.058 ********* 
skipping: [bastion]

TASK [set_env_authorized_key : create /root/.ssh] ******************************
Monday 04 August 2025  12:43:17 +0000 (0:00:00.020)       0:08:53.079 ********* 
ok: [bastion]

TASK [set_env_authorized_key : copy the environment .pem key] ******************
Monday 04 August 2025  12:43:18 +0000 (0:00:00.993)       0:08:54.072 ********* 
changed: [bastion]

TASK [set_env_authorized_key : copy the environment .pub key] ******************
Monday 04 August 2025  12:43:20 +0000 (0:00:01.936)       0:08:56.009 ********* 
changed: [bastion]

TASK [set_env_authorized_key : Set authorized key from file] *******************
Monday 04 August 2025  12:43:22 +0000 (0:00:01.934)       0:08:57.943 ********* 
ok: [bastion]

TASK [set_env_authorized_key : Generate host .ssh/config Template] *************
Monday 04 August 2025  12:43:23 +0000 (0:00:00.969)       0:08:58.913 ********* 
changed: [bastion -> localhost]

TASK [set_env_authorized_key : copy over host .ssh/config Template] ************
Monday 04 August 2025  12:43:23 +0000 (0:00:00.298)       0:08:59.211 ********* 
changed: [bastion]

TASK [Add GUID to /etc/skel/.bashrc] *******************************************
Monday 04 August 2025  12:43:25 +0000 (0:00:01.979)       0:09:01.191 ********* 
changed: [bastion]

RUNNING HANDLER [common : restart_sshd] ****************************************
Monday 04 August 2025  12:43:26 +0000 (0:00:00.948)       0:09:02.139 ********* 
changed: [bastion]

PLAY [Step 003.2 - Configuring Bastion Hosts] **********************************

TASK [bastion-lite : Generate an SSH key on the Bastion and configure access on all the hosts] ***
Monday 04 August 2025  12:43:27 +0000 (0:00:01.241)       0:09:03.380 ********* 
included: /runner/project/ansible/roles/bastion-lite/tasks/./create_bastion_ssh_key_and_access.yml for bastion

TASK [bastion-lite : Generate SSH keys] ****************************************
Monday 04 August 2025  12:43:27 +0000 (0:00:00.024)       0:09:03.405 ********* 
changed: [bastion]

TASK [bastion-lite : Fix permission of ssh key] ********************************
Monday 04 August 2025  12:43:28 +0000 (0:00:01.368)       0:09:04.774 ********* 
changed: [bastion]

TASK [bastion-lite : Generate SSH pub key content] *****************************
Monday 04 August 2025  12:43:29 +0000 (0:00:00.970)       0:09:05.744 ********* 
ok: [bastion]

TASK [bastion-lite : Save all facts for SSH] ***********************************
Monday 04 August 2025  12:43:30 +0000 (0:00:00.974)       0:09:06.719 ********* 
ok: [bastion]

TASK [bastion-lite : Write SSH pub key] ****************************************
Monday 04 August 2025  12:43:30 +0000 (0:00:00.023)       0:09:06.743 ********* 
changed: [bastion]

TASK [bastion-lite : Add bastion access to all hosts] **************************
Monday 04 August 2025  12:43:32 +0000 (0:00:02.070)       0:09:08.813 ********* 
changed: [bastion] => (item=bastion)

TASK [bastion-lite : Add bastion access to all hosts] **************************
Monday 04 August 2025  12:43:34 +0000 (0:00:01.044)       0:09:09.858 ********* 
changed: [bastion] => (item=bastion)

TASK [bastion-lite : Generate .ssh/config] *************************************
Monday 04 August 2025  12:43:35 +0000 (0:00:01.004)       0:09:10.862 ********* 
changed: [bastion]

TASK [Install FTL] *************************************************************
Monday 04 August 2025  12:43:37 +0000 (0:00:02.038)       0:09:12.901 ********* 
skipping: [bastion]

TASK [bastion-lite : Ensure system Python3 has selinux library installed] ******
Monday 04 August 2025  12:43:37 +0000 (0:00:00.017)       0:09:12.919 ********* 
skipping: [bastion]

TASK [bastion-lite : Install OpenShift Helm 3] *********************************
Monday 04 August 2025  12:43:37 +0000 (0:00:00.016)       0:09:12.935 ********* 
skipping: [bastion]

TASK [bastion-lite : Add GUID to /etc/skel/.bashrc] ****************************
Monday 04 August 2025  12:43:37 +0000 (0:00:00.015)       0:09:12.951 ********* 
ok: [bastion]

TASK [bastion-lite : Add GUID to ~cloud-user/.bashrc] **************************
Monday 04 August 2025  12:43:38 +0000 (0:00:00.942)       0:09:13.893 ********* 
changed: [bastion]

TASK [bastion-lite : Add CLOUDUSER to /etc/skel/.bashrc] ***********************
Monday 04 August 2025  12:43:39 +0000 (0:00:00.930)       0:09:14.824 ********* 
changed: [bastion]

TASK [bastion-lite : Add CLOUDUSER to ~cloud-user/.bashrc] *********************
Monday 04 August 2025  12:43:39 +0000 (0:00:00.944)       0:09:15.768 ********* 
changed: [bastion]

TASK [bastion-student-user : Generate student_password if not defined] *********
Monday 04 August 2025  12:43:40 +0000 (0:00:00.955)       0:09:16.724 ********* 
ok: [bastion]

TASK [bastion-student-user : Create user] **************************************
Monday 04 August 2025  12:43:40 +0000 (0:00:00.027)       0:09:16.751 ********* 
changed: [bastion]

TASK [bastion-student-user : Add student public key] ***************************
Monday 04 August 2025  12:43:42 +0000 (0:00:01.547)       0:09:18.299 ********* 
skipping: [bastion]

TASK [bastion-student-user : Add env authorized public key to student user] ****
Monday 04 August 2025  12:43:42 +0000 (0:00:00.019)       0:09:18.319 ********* 
changed: [bastion]

TASK [bastion-student-user : Enable password authentication] *******************
Monday 04 August 2025  12:43:43 +0000 (0:00:00.983)       0:09:19.302 ********* 
changed: [bastion]

TASK [bastion-student-user : Remove PasswordAuthentication line from 50-cloud-init.conf] ***
Monday 04 August 2025  12:43:44 +0000 (0:00:00.941)       0:09:20.243 ********* 
changed: [bastion]

TASK [bastion-student-user : Disable root password authentication] *************
Monday 04 August 2025  12:43:45 +0000 (0:00:00.935)       0:09:21.179 ********* 
changed: [bastion]

TASK [bastion-student-user : Allow passwordless sudo] **************************
Monday 04 August 2025  12:43:46 +0000 (0:00:00.930)       0:09:22.109 ********* 
changed: [bastion]

TASK [bastion-student-user : Restart sshd] *************************************
Monday 04 August 2025  12:43:47 +0000 (0:00:00.941)       0:09:23.051 ********* 
changed: [bastion]

TASK [bastion-student-user : Print access info (non CNV)] **********************
Monday 04 August 2025  12:43:48 +0000 (0:00:01.212)       0:09:24.264 ********* 
skipping: [bastion]

TASK [bastion-student-user : Store access info (non CNV)] **********************
Monday 04 August 2025  12:43:48 +0000 (0:00:00.023)       0:09:24.287 ********* 
skipping: [bastion]

TASK [bastion-student-user : Print access info (CNV)] **************************
Monday 04 August 2025  12:43:48 +0000 (0:00:00.024)       0:09:24.311 ********* 
skipping: [bastion]

TASK [bastion-student-user : Store access info (CNV)] **************************
Monday 04 August 2025  12:43:48 +0000 (0:00:00.018)       0:09:24.330 ********* 
ok: [bastion] => {
    "changed": false,
    "data": {
        "bastion_public_hostname": "ssh.ocpv08.rhdp.net",
        "bastion_ssh_command": "ssh lab-user@ssh.ocpv08.rhdp.net 
        "bastion_ssh_password": "[REDACTED_Secret Keyword_SECRET]",
        "bastion_ssh_port": "30444",
        "bastion_ssh_user_name": "lab-user"
    }
}

TASK [Prepare student user for using Ansible within the environment] ***********
Monday 04 August 2025  12:43:48 +0000 (0:00:00.038)       0:09:24.368 ********* 
skipping: [bastion]

TASK [Copy SSH private key to student user .ssh directory] *********************
Monday 04 August 2025  12:43:48 +0000 (0:00:00.024)       0:09:24.392 ********* 
changed: [bastion]

TASK [Copy SSH public key to student user .ssh directory] **********************
Monday 04 August 2025  12:43:49 +0000 (0:00:00.957)       0:09:25.350 ********* 
changed: [bastion]

TASK [Copy SSH config to student user .ssh directory] **************************
Monday 04 August 2025  12:43:50 +0000 (0:00:00.953)       0:09:26.303 ********* 
changed: [bastion]

PLAY [Step 003.3 Create a Python3 VirtualEnv for use in the k8s Ansible tasks] ***

TASK [Setup k8s virtualenv (EL9)] **********************************************
Monday 04 August 2025  12:43:51 +0000 (0:00:00.970)       0:09:27.274 ********* 
included: host_virtualenv for bastion

TASK [host_virtualenv : Check host_virtualenv_path is defined] *****************
Monday 04 August 2025  12:43:51 +0000 (0:00:00.026)       0:09:27.301 ********* 
ok: [bastion] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [host_virtualenv : Gather basic ansible facts to determine pkg_mgr] *******
Monday 04 August 2025  12:43:51 +0000 (0:00:00.022)       0:09:27.323 ********* 
skipping: [bastion]

TASK [host_virtualenv : Install virtualenv package prerequisites] **************
Monday 04 August 2025  12:43:51 +0000 (0:00:00.018)       0:09:27.341 ********* 
changed: [bastion]

TASK [host_virtualenv : Install virtualenv module system-wide for compatibility with previous behavior] ***
Monday 04 August 2025  12:44:01 +0000 (0:00:09.955)       0:09:37.297 ********* 
changed: [bastion]

TASK [host_virtualenv : Make virtualenv path] **********************************
Monday 04 August 2025  12:44:04 +0000 (0:00:02.937)       0:09:40.235 ********* 
changed: [bastion]

TASK [host_virtualenv : Write /opt/virtualenvs/k8s/host_virtualenv-requirements.txt] ***
Monday 04 August 2025  12:44:05 +0000 (0:00:00.991)       0:09:41.226 ********* 
changed: [bastion]

TASK [host_virtualenv : Set up virtualenv with updated pip] ********************
Monday 04 August 2025  12:44:07 +0000 (0:00:01.986)       0:09:43.213 ********* 
changed: [bastion]

TASK [host_virtualenv : Install requirements in virtualenv] ********************
Monday 04 August 2025  12:44:12 +0000 (0:00:05.032)       0:09:48.245 ********* 
changed: [bastion]

TASK [host_virtualenv : Ownership of files in virtualenv path] *****************
Monday 04 August 2025  12:44:59 +0000 (0:00:46.724)       0:10:34.969 ********* 
skipping: [bastion]

TASK [Setup k8s virtualenv (EL8)] **********************************************
Monday 04 August 2025  12:44:59 +0000 (0:00:00.020)       0:10:34.989 ********* 
skipping: [bastion]

PLAY [PreSoftware flight-check] ************************************************

TASK [Print debug message] *****************************************************
Monday 04 August 2025  12:44:59 +0000 (0:00:00.013)       0:10:35.003 ********* 
ok: [localhost] => {
    "msg": "Pre-Software checks completed successfully"
}

PLAY [Step 004 - Software] *****************************************************

TASK [Debug ocp4-cluster software playbook] ************************************
Monday 04 August 2025  12:44:59 +0000 (0:00:00.018)       0:10:35.022 ********* 
ok: [bastion] => {
    "msg": "ocp4-cluster Software playbook"
}

PLAY [Step 004.2 - Install OpenShift using Assisted Installer] *****************

TASK [Call Role to install OpenShift using Assisted Installer] *****************
Monday 04 August 2025  12:44:59 +0000 (0:00:00.056)       0:10:35.078 ********* 
[WARNING]: Found variable using reserved name: namespace
included: host-ocp4-assisted-installer for bastion

TASK [host-ocp4-assisted-installer : Set Ansible Python interpreter to k8s virtualenv] ***
Monday 04 August 2025  12:44:59 +0000 (0:00:00.077)       0:10:35.155 ********* 
ok: [bastion]

TASK [host-ocp4-assisted-installer : Set URLs for OpenShift GA releases (specific version)] ***
Monday 04 August 2025  12:44:59 +0000 (0:00:00.021)       0:10:35.176 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Set URLs for OpenShift GA releases (latest stable)] ***
Monday 04 August 2025  12:44:59 +0000 (0:00:00.021)       0:10:35.198 ********* 
ok: [bastion]

TASK [host-ocp4-assisted-installer : Get the OpenShift CLI] ********************
Monday 04 August 2025  12:44:59 +0000 (0:00:00.024)       0:10:35.223 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Log in (obtain access token)] *************
Monday 04 August 2025  12:45:06 +0000 (0:00:06.625)       0:10:41.849 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Add the service (type LoadBalancer) for SNO] ***
Monday 04 August 2025  12:45:06 +0000 (0:00:00.017)       0:10:41.866 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Wait for the LoadBalancer value - masters] ***
Monday 04 August 2025  12:45:07 +0000 (0:00:01.459)       0:10:43.326 ********* 
ok: [bastion]

TASK [host-ocp4-assisted-installer : Add A dns record - masters] ***************
Monday 04 August 2025  12:45:08 +0000 (0:00:01.320)       0:10:44.646 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Add A dns record - masters] ***************
Monday 04 August 2025  12:45:08 +0000 (0:00:00.024)       0:10:44.670 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Add A dns record - workers] ***************
Monday 04 August 2025  12:45:14 +0000 (0:00:05.444)       0:10:50.114 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Add A dns record - workers] ***************
Monday 04 August 2025  12:45:14 +0000 (0:00:00.024)       0:10:50.139 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Add the service (type LoadBalancer) for Full Clusters - masters] ***
Monday 04 August 2025  12:45:19 +0000 (0:00:05.308)       0:10:55.448 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Wait for the LoadBalancer value - masters] ***
Monday 04 August 2025  12:45:19 +0000 (0:00:00.020)       0:10:55.468 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Add A dns record - masters] ***************
Monday 04 August 2025  12:45:19 +0000 (0:00:00.019)       0:10:55.488 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Add A dns record - masters] ***************
Monday 04 August 2025  12:45:19 +0000 (0:00:00.019)       0:10:55.508 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Add the service (type LoadBalancer) for Full Clusters - workers] ***
Monday 04 August 2025  12:45:19 +0000 (0:00:00.018)       0:10:55.527 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Wait for the LoadBalancer value - workers] ***
Monday 04 August 2025  12:45:19 +0000 (0:00:00.018)       0:10:55.545 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Add A dns record - workers] ***************
Monday 04 August 2025  12:45:19 +0000 (0:00:00.018)       0:10:55.563 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Add A dns record - workers] ***************
Monday 04 August 2025  12:45:19 +0000 (0:00:00.018)       0:10:55.582 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Create OVN secondary network] *************
Monday 04 August 2025  12:45:19 +0000 (0:00:00.018)       0:10:55.600 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Create Assisted Installer Cluster] ********
Monday 04 August 2025  12:45:21 +0000 (0:00:01.403)       0:10:57.004 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Add etcd manifest] ************************
Monday 04 August 2025  12:45:22 +0000 (0:00:01.707)       0:10:58.712 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Add routers replicas manifest] ************
Monday 04 August 2025  12:45:24 +0000 (0:00:01.477)       0:11:00.189 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Add OVN-Kubernetes to switch to local gateway mode manifest] ***
Monday 04 August 2025  12:45:25 +0000 (0:00:01.405)       0:11:01.595 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Enable ip_forwarding for control plane] ***
Monday 04 August 2025  12:45:27 +0000 (0:00:01.310)       0:11:02.905 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Enable ip_forwarding for workers] *********
Monday 04 August 2025  12:45:28 +0000 (0:00:01.361)       0:11:04.266 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Generate mac addresses for control plane] ***
Monday 04 August 2025  12:45:29 +0000 (0:00:01.339)       0:11:05.606 ********* 
ok: [bastion] => (item=1)

TASK [host-ocp4-assisted-installer : Generate MAC addresses for control plane for attached networks] ***
Monday 04 August 2025  12:45:29 +0000 (0:00:00.041)       0:11:05.648 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Generate mac addresses for workers] *******
Monday 04 August 2025  12:45:29 +0000 (0:00:00.017)       0:11:05.665 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Generate MAC addresses for workers for attached networks] ***
Monday 04 August 2025  12:45:29 +0000 (0:00:00.020)       0:11:05.686 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Set static_network_config variable] *******
Monday 04 August 2025  12:45:29 +0000 (0:00:00.028)       0:11:05.714 ********* 
ok: [bastion]

TASK [host-ocp4-assisted-installer : Create Infrastructure environment] ********
Monday 04 August 2025  12:45:29 +0000 (0:00:00.048)       0:11:05.762 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Create PVC for the installation ISO] ******
Monday 04 August 2025  12:45:31 +0000 (0:00:01.447)       0:11:07.210 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Create a three master VMs for Full cluster] ***
Monday 04 August 2025  12:45:32 +0000 (0:00:01.396)       0:11:08.606 ********* 
included: /runner/project/ansible/roles/host-ocp4-assisted-installer/tasks/kubevirt/create_masters_etcd.yaml for bastion => (item=1)

TASK [host-ocp4-assisted-installer : Set default interfaces/networks variables] ***
Monday 04 August 2025  12:45:32 +0000 (0:00:00.038)       0:11:08.645 ********* 
ok: [bastion]

TASK [host-ocp4-assisted-installer : Add attach masters networks if defined] ***
Monday 04 August 2025  12:45:32 +0000 (0:00:00.025)       0:11:08.671 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Set default volumes/disks variables] ******
Monday 04 August 2025  12:45:32 +0000 (0:00:00.014)       0:11:08.685 ********* 
ok: [bastion]

TASK [host-ocp4-assisted-installer : Set the instances disks] ******************
Monday 04 August 2025  12:45:32 +0000 (0:00:00.038)       0:11:08.724 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Create Master virtual machine] ************
Monday 04 August 2025  12:45:32 +0000 (0:00:00.024)       0:11:08.748 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Wait till VM is running] ******************
Monday 04 August 2025  12:45:34 +0000 (0:00:01.555)       0:11:10.304 ********* 
FAILED - RETRYING: [bastion]: Wait till VM is running (120 retries left).
FAILED - RETRYING: [bastion]: Wait till VM is running (119 retries left).
FAILED - RETRYING: [bastion]: Wait till VM is running (118 retries left).
FAILED - RETRYING: [bastion]: Wait till VM is running (117 retries left).
FAILED - RETRYING: [bastion]: Wait till VM is running (116 retries left).
FAILED - RETRYING: [bastion]: Wait till VM is running (115 retries left).
ok: [bastion]

TASK [host-ocp4-assisted-installer : Create a 0 worker VMs for Full cluster] ***
Monday 04 August 2025  12:46:44 +0000 (0:01:09.952)       0:12:20.257 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Set the variable ai_configure_hosts for control-plane] ***
Monday 04 August 2025  12:46:44 +0000 (0:00:00.023)       0:12:20.280 ********* 
ok: [bastion] => (item=1)

TASK [host-ocp4-assisted-installer : Set the variable ai_configure_hosts for workers] ***
Monday 04 August 2025  12:46:44 +0000 (0:00:00.037)       0:12:20.318 ********* 
skipping: [bastion]

TASK [host-ocp4-assisted-installer : Wait for the hosts to be ready] ***********
Monday 04 August 2025  12:46:44 +0000 (0:00:00.025)       0:12:20.343 ********* 
ok: [bastion]

TASK [host-ocp4-assisted-installer : Start cluster installation] ***************
Monday 04 August 2025  12:48:54 +0000 (0:02:09.884)       0:14:30.228 ********* 
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC POLL on bastion: jid=j280184601757.16557 started=1 finished=0
ASYNC OK on bastion: jid=j280184601757.16557
ok: [bastion]

TASK [host-ocp4-assisted-installer : Obtain OpenShift cluster credentials] *****
Monday 04 August 2025  13:21:32 +0000 (0:32:38.007)       0:47:08.236 ********* 
ok: [bastion]

TASK [host-ocp4-assisted-installer : Display credentials for debugging purpose] ***
Monday 04 August 2025  13:21:33 +0000 (0:00:01.377)       0:47:09.613 ********* 
ok: [bastion] => {
    "ai_credentials.result": {
        "console_url": "https://console-openshift-console.apps.cluster-v6wwh.dynamic.redhatworkshops.io",
        "password": "[REDACTED_Secret Keyword_SECRET]",
        "username": "kubeadmin"
    }
}

TASK [host-ocp4-assisted-installer : Create directory for downloaded credential files] ***
Monday 04 August 2025  13:21:33 +0000 (0:00:00.020)       0:47:09.633 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Downloads OpenShift cluster credentials] ***
Monday 04 August 2025  13:21:34 +0000 (0:00:00.948)       0:47:10.581 ********* 
changed: [bastion] => (item=kubeadmin-password)
changed: [bastion] => (item=kubeconfig)
changed: [bastion] => (item=kubeconfig-noingress)

TASK [host-ocp4-assisted-installer : Downloads OpenShift cluster files] ********
Monday 04 August 2025  13:21:38 +0000 (0:00:04.146)       0:47:14.728 ********* 
changed: [bastion] => (item=bootstrap.ign)
changed: [bastion] => (item=master.ign)
changed: [bastion] => (item=metadata.json)
changed: [bastion] => (item=worker.ign)
changed: [bastion] => (item=install-config.yaml)
changed: [bastion] => (item=custom_manifests.json)
changed: [bastion] => (item=custom_manifests.yaml)

TASK [host-ocp4-assisted-installer : Fetch kube config] ************************
Monday 04 August 2025  13:21:50 +0000 (0:00:11.880)       0:47:26.608 ********* 
changed: [bastion] => (item=kubeconfig)
changed: [bastion] => (item=kubeadmin-password)

TASK [host-ocp4-assisted-installer : Make sure .kube directory exists for cloud-user] ***
Monday 04 August 2025  13:21:53 +0000 (0:00:02.425)       0:47:29.034 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Make sure .kube directory exists for root] ***
Monday 04 August 2025  13:21:54 +0000 (0:00:00.891)       0:47:29.925 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Copy cluster kubeconfig to /home/cloud-user/.kube/config] ***
Monday 04 August 2025  13:21:55 +0000 (0:00:00.898)       0:47:30.823 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Copy cluster kubeconfig to /root/.kube/config] ***
Monday 04 August 2025  13:21:55 +0000 (0:00:00.887)       0:47:31.711 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Make sure .kube directory exists in /home/lab-user] ***
Monday 04 August 2025  13:21:56 +0000 (0:00:00.904)       0:47:32.615 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Copy /home/cloud-user/cluster-v6wwh/auth/kubeconfig to /home/lab-user/.kube] ***
Monday 04 August 2025  13:21:57 +0000 (0:00:00.918)       0:47:33.534 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Create OpenShift Bash completion file] ****
Monday 04 August 2025  13:21:58 +0000 (0:00:00.912)       0:47:34.446 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Find installer Pods in Error Status with label app=installer] ***
Monday 04 August 2025  13:21:59 +0000 (0:00:01.045)       0:47:35.492 ********* 
ok: [bastion]

TASK [host-ocp4-assisted-installer : Delete Error Pods] ************************
Monday 04 August 2025  13:22:01 +0000 (0:00:01.552)       0:47:37.045 ********* 
changed: [bastion] => (item={'metadata': {'name': 'installer-1-control-plane-cluster-v6wwh-1', 'namespace': 'openshift-kube-apiserver', 'uid': '8016dff0-fe2a-4ea6-bf61-480cc284c087', 'resourceVersion': '12623', 'creationTimestamp': '2025-08-04T12:59:38Z', 'labels': {'app': 'installer'}, 'annotations': {'k8s.ovn.org/pod-networks': '{"default":{"ip_addresses":["10.132.0.29/23"],"mac_address":"0a:58:0a:84:00:1d","gateway_ips":["10.132.0.1"],"routes":[{"dest":"10.132.0.0/14","nextHop":"10.132.0.1"},{"dest":"172.31.0.0/16","nextHop":"10.132.0.1"},{"dest":"169.254.0.5/32","nextHop":"10.132.0.1"},{"dest":"100.64.0.0/16","nextHop":"10.132.0.1"}],"ip_address":"10.132.0.29/23","gateway_ip":"10.132.0.1","role":"primary"}}', 'k8s.v1.cni.cncf.io/network-status': '[{\\n    "name": "ovn-kubernetes",\\n    "interface": "eth0",\\n    "ips": [\\n        "10.132.0.29"\\n    ],\\n    "mac": "0a:58:0a:84:00:1d",\\n    "default": true,\\n    "dns": {}\\n}]'}, 'ownerReferences': [{'apiVersion': 'v1', 'kind': 'ConfigMap', 'name': 'revision-status-1', 'uid': 'd8603379-f799-4e07-b29c-2288e9ffcc16'}], 'managedFields': [{'manager': 'cluster-kube-apiserver-operator', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T12:59:38Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:labels': {'.': {}, 'f:app': {}}, 'f:ownerReferences': {'.': {}, 'k:{"uid":"d8603379-f799-4e07-b29c-2288e9ffcc16"}': {}}}, 'f:spec': {'f:automountServiceAccountToken': {}, 'f:containers': {'k:{"name":"installer"}': {'.': {}, 'f:args': {}, 'f:command': {}, 'f:env': {'.': {}, 'k:{"name":"NODE_NAME"}': {'.': {}, 'f:name': {}, 'f:valueFrom': {'.': {}, 'f:fieldRef': {}}}, 'k:{"name":"POD_NAME"}': {'.': {}, 'f:name': {}, 'f:valueFrom': {'.': {}, 'f:fieldRef': {}}}}, 'f:image': {}, 'f:imagePullPolicy': {}, 'f:name': {}, 'f:resources': {'.': {}, 'f:limits': {'.': {}, 'f:cpu': {}, 'f:memory': {}}, 'f:requests': {'.': {}, 'f:cpu': {}, 'f:memory': {}}}, 'f:securityContext': {'.': {}, 'f:privileged': {}, 'f:runAsUser': {}}, 'f:terminationMessagePath': {}, 'f:terminationMessagePolicy': {}, 'f:volumeMounts': {'.': {}, 'k:{"mountPath":"/etc/kubernetes/"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}}, 'k:{"mountPath":"/var/lock"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}}, 'k:{"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}, 'f:readOnly': {}}}}}, 'f:dnsPolicy': {}, 'f:enableServiceLinks': {}, 'f:nodeName': {}, 'f:priorityClassName': {}, 'f:restartPolicy': {}, 'f:schedulerName': {}, 'f:securityContext': {'.': {}, 'f:runAsUser': {}}, 'f:serviceAccount': {}, 'f:serviceAccountName': {}, 'f:terminationGracePeriodSeconds': {}, 'f:tolerations': {}, 'f:volumes': {'.': {}, 'k:{"name":"kube-api-access"}': {'.': {}, 'f:name': {}, 'f:projected': {'.': {}, 'f:defaultMode': {}, 'f:sources': {}}}, 'k:{"name":"kubelet-dir"}': {'.': {}, 'f:hostPath': {'.': {}, 'f:path': {}, 'f:type': {}}, 'f:name': {}}, 'k:{"name":"var-lock"}': {'.': {}, 'f:hostPath': {'.': {}, 'f:path': {}, 'f:type': {}}, 'f:name': {}}}}}}, {'manager': 'control-plane-cluster-v6wwh-1', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:03:03Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'.': {}, 'f:k8s.ovn.org/pod-networks': {}}}}, 'subresource': 'status'}, {'manager': 'multus-daemon', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:03:17Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'f:k8s.v1.cni.cncf.io/network-status': {}}}}, 'subresource': 'status'}, {'manager': 'kubelet', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:08:27Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:status': {'f:conditions': {'.': {}, 'k:{"type":"ContainersReady"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:reason': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"Initialized"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"PodReadyToStartContainers"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"PodScheduled"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"Ready"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:reason': {}, 'f:status': {}, 'f:type': {}}}, 'f:containerStatuses': {}, 'f:hostIP': {}, 'f:hostIPs': {}, 'f:phase': {}, 'f:startTime': {}}}, 'subresource': 'status'}]}, 'spec': {'volumes': [{'name': 'kubelet-dir', 'hostPath': {'path': '/etc/kubernetes/', 'type': ''}}, {'name': 'var-lock', 'hostPath': {'path': '/var/lock', 'type': ''}}, {'name': 'kube-api-access', 'projected': {'sources': [{'serviceAccountToken': {'expirationSeconds': 3600, 'path': 'token'}}, {'configMap': {'name': 'kube-root-ca.crt', 'items': [{'key': 'ca.crt', 'path': 'ca.crt'}]}}, {'downwardAPI': {'items': [{'path': 'namespace', 'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'metadata.namespace'}}]}}], 'defaultMode': 420}}], 'containers': [{'name': 'installer', 'image': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0aad6225a2dba6eefbbcc1a7dda3a4493a6182840ee5fbaa30c02302e55f6a5b', 'command': ['cluster-kube-apiserver-operator', 'installer'], 'args': ['-v=2', '--revision=1', '--namespace=openshift-kube-apiserver', '--pod=kube-apiserver-pod', '--resource-dir=/etc/kubernetes/static-pod-resources', '--pod-manifest-dir=/etc/kubernetes/manifests', '--configmaps=kube-apiserver-pod', '--configmaps=config', '--configmaps=kube-apiserver-cert-syncer-kubeconfig', '--optional-configmaps=oauth-metadata', '--optional-configmaps=cloud-config', '--configmaps=bound-sa-token-signing-certs', '--configmaps=etcd-serving-ca', '--optional-configmaps=kube-apiserver-server-ca', '--configmaps=kubelet-serving-ca', '--configmaps=sa-token-signing-certs', '--configmaps=kube-apiserver-audit-policies', '--secrets=etcd-client', '--optional-secrets=encryption-config', '--secrets=localhost-recovery-serving-certkey', '--secrets=localhost-recovery-client-token', '--optional-secrets=webhook-authenticator', '--cert-dir=/etc/kubernetes/static-pod-resources/kube-apiserver-certs', '--cert-configmaps=aggregator-client-ca', '--cert-configmaps=client-ca', '--optional-cert-configmaps=trusted-ca-bundle', '--cert-configmaps=control-plane-node-kubeconfig', '--cert-configmaps=check-endpoints-kubeconfig', '--cert-secrets=aggregator-client', '--cert-secrets=localhost-serving-cert-certkey', '--cert-secrets=service-network-serving-certkey', '--cert-secrets=external-loadbalancer-serving-certkey', '--cert-secrets=internal-loadbalancer-serving-certkey', '--cert-secrets=bound-service-account-signing-key', '--cert-secrets=control-plane-node-admin-client-cert-key', '--cert-secrets=check-endpoints-client-cert-key', '--cert-secrets=kubelet-client', '--cert-secrets=node-kubeconfigs', '--optional-cert-secrets=user-serving-cert', '--optional-cert-secrets=user-serving-cert-000', '--optional-cert-secrets=user-serving-cert-001', '--optional-cert-secrets=user-serving-cert-002', '--optional-cert-secrets=user-serving-cert-003', '--optional-cert-secrets=user-serving-cert-004', '--optional-cert-secrets=user-serving-cert-005', '--optional-cert-secrets=user-serving-cert-006', '--optional-cert-secrets=user-serving-cert-007', '--optional-cert-secrets=user-serving-cert-008', '--optional-cert-secrets=user-serving-cert-009'], 'env': [{'name': 'POD_NAME', 'valueFrom': {'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'metadata.name'}}}, {'name': 'NODE_NAME', 'valueFrom': {'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'spec.nodeName'}}}], 'resources': {'limits': {'cpu': '150m', 'memory': '200M'}, 'requests': {'cpu': '150m', 'memory': '200M'}}, 'volumeMounts': [{'name': 'kubelet-dir', 'mountPath': '/etc/kubernetes/'}, {'name': 'kube-api-access', 'readOnly': True, 'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount'}, {'name': 'var-lock', 'mountPath': '/var/lock'}], 'terminationMessagePath': '/dev/termination-log', 'terminationMessagePolicy': 'FallbackToLogsOnError', 'imagePullPolicy': 'IfNotPresent', 'securityContext': {'privileged': True, 'runAsUser': 0}}], 'restartPolicy': 'Never', 'terminationGracePeriodSeconds': 30, 'dnsPolicy': 'ClusterFirst', 'serviceAccountName': 'installer-sa', 'serviceAccount': 'installer-sa', 'automountServiceAccountToken': False, 'nodeName': 'control-plane-cluster-v6wwh-1', 'securityContext': {'runAsUser': 0}, 'schedulerName': 'default-scheduler', 'tolerations': [{'operator': 'Exists'}], 'priorityClassName': 'system-node-critical', 'priority': 2000001000, 'enableServiceLinks': True, 'preemptionPolicy': 'PreemptLowerPriority'}, 'status': {'phase': 'Failed', 'conditions': [{'type': 'PodReadyToStartContainers', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:06:36Z'}, {'type': 'Initialized', 'status': 'True', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T12:59:38Z'}, {'type': 'Ready', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:06:35Z', 'reason': 'PodFailed'}, {'type': 'ContainersReady', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:06:35Z', 'reason': 'PodFailed'}, {'type': 'PodScheduled', 'status': 'True', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T12:59:38Z'}], 'hostIP': '10.10.10.10', 'hostIPs': [{'ip': '10.10.10.10'}], 'startTime': '2025-08-04T12:59:38Z', 'containerStatuses': [{'name': 'installer', 'state': {'terminated': {'exitCode': 1, 'reason': 'Error', 'message': 't (get configmaps kube-apiserver-audit-policies-1)\\nI0804 13:04:30.234070       1 copy.go:52] Failed to get config map openshift-kube-apiserver/kube-apiserver-audit-policies-1: Get "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies-1?timeout=14s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\\nI0804 13:04:44.509130       1 copy.go:52] Failed to get config map openshift-kube-apiserver/kube-apiserver-audit-policies-1: the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-audit-policies-1)\\nW0804 13:04:58.509812       1 recorder.go:219] Error creating event &Event{ObjectMeta:{installer-1-control-plane-cluster-v6wwh-1.1858921781215459.8b8fef47  openshift-kube-apiserver    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Pod,Namespace:openshift-kube-apiserver,Name:installer-1-control-plane-cluster-v6wwh-1,UID:8016dff0-fe2a-4ea6-bf61-480cc284c087,APIVersion:v1,ResourceVersion:,FieldPath:,},Reason:StaticPodInstallerFailed,Message:Installing revision 1: the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-audit-policies-1),Source:EventSource{Component:static-pod-installer,Host:,},FirstTimestamp:2025-08-04 13:04:44.509156441 +0000 UTC m=+87.056116015,LastTimestamp:2025-08-04 13:04:44.509156441 +0000 UTC m=+87.056116015,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:,ReportingInstance:,}: Post "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-apiserver/events?timeout=14s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\\nF0804 13:04:58.509960       1 cmd.go:109] failed to copy: the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-audit-policies-1)\\n', 'startedAt': '2025-08-04T13:03:17Z', 'finishedAt': '2025-08-04T13:04:58Z', 'containerID': 'cri-o://b8d142a436e36dd72295e2b1100115ef556fe451f0e7ca0c881bb5f02476df33'}}, 'lastState': {}, 'ready': False, 'restartCount': 0, 'image': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0aad6225a2dba6eefbbcc1a7dda3a4493a6182840ee5fbaa30c02302e55f6a5b', 'imageID': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:0aad6225a2dba6eefbbcc1a7dda3a4493a6182840ee5fbaa30c02302e55f6a5b', 'containerID': 'cri-o://b8d142a436e36dd72295e2b1100115ef556fe451f0e7ca0c881bb5f02476df33', 'started': False, 'volumeMounts': [{'name': 'kubelet-dir', 'mountPath': '/etc/kubernetes/'}, {'name': 'kube-api-access', 'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount', 'readOnly': True, 'recursiveReadOnly': 'Disabled'}, {'name': 'var-lock', 'mountPath': '/var/lock'}]}], 'qosClass': 'Guaranteed'}, 'apiVersion': 'v1', 'kind': 'Pod'})
changed: [bastion] => (item={'metadata': {'name': 'installer-3-control-plane-cluster-v6wwh-1', 'namespace': 'openshift-kube-controller-manager', 'uid': '92685289-1fa2-4c97-b5a5-5a912a31d98e', 'resourceVersion': '12602', 'creationTimestamp': '2025-08-04T13:03:42Z', 'labels': {'app': 'installer'}, 'annotations': {'k8s.ovn.org/pod-networks': '{"default":{"ip_addresses":["10.132.0.38/23"],"mac_address":"0a:58:0a:84:00:26","gateway_ips":["10.132.0.1"],"routes":[{"dest":"10.132.0.0/14","nextHop":"10.132.0.1"},{"dest":"172.31.0.0/16","nextHop":"10.132.0.1"},{"dest":"169.254.0.5/32","nextHop":"10.132.0.1"},{"dest":"100.64.0.0/16","nextHop":"10.132.0.1"}],"ip_address":"10.132.0.38/23","gateway_ip":"10.132.0.1","role":"primary"}}', 'k8s.v1.cni.cncf.io/network-status': '[{\\n    "name": "ovn-kubernetes",\\n    "interface": "eth0",\\n    "ips": [\\n        "10.132.0.38"\\n    ],\\n    "mac": "0a:58:0a:84:00:26",\\n    "default": true,\\n    "dns": {}\\n}]'}, 'ownerReferences': [{'apiVersion': 'v1', 'kind': 'ConfigMap', 'name': 'revision-status-3', 'uid': '51a9953b-22fb-4de9-bd82-444ef854e164'}], 'managedFields': [{'manager': 'cluster-kube-controller-manager-operator', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:03:42Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:labels': {'.': {}, 'f:app': {}}, 'f:ownerReferences': {'.': {}, 'k:{"uid":"51a9953b-22fb-4de9-bd82-444ef854e164"}': {}}}, 'f:spec': {'f:automountServiceAccountToken': {}, 'f:containers': {'k:{"name":"installer"}': {'.': {}, 'f:args': {}, 'f:command': {}, 'f:env': {'.': {}, 'k:{"name":"NODE_NAME"}': {'.': {}, 'f:name': {}, 'f:valueFrom': {'.': {}, 'f:fieldRef': {}}}, 'k:{"name":"POD_NAME"}': {'.': {}, 'f:name': {}, 'f:valueFrom': {'.': {}, 'f:fieldRef': {}}}}, 'f:image': {}, 'f:imagePullPolicy': {}, 'f:name': {}, 'f:resources': {'.': {}, 'f:limits': {'.': {}, 'f:cpu': {}, 'f:memory': {}}, 'f:requests': {'.': {}, 'f:cpu': {}, 'f:memory': {}}}, 'f:securityContext': {'.': {}, 'f:privileged': {}, 'f:runAsUser': {}}, 'f:terminationMessagePath': {}, 'f:terminationMessagePolicy': {}, 'f:volumeMounts': {'.': {}, 'k:{"mountPath":"/etc/kubernetes/"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}}, 'k:{"mountPath":"/var/lock"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}}, 'k:{"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}, 'f:readOnly': {}}}}}, 'f:dnsPolicy': {}, 'f:enableServiceLinks': {}, 'f:nodeName': {}, 'f:priorityClassName': {}, 'f:restartPolicy': {}, 'f:schedulerName': {}, 'f:securityContext': {'.': {}, 'f:runAsUser': {}}, 'f:serviceAccount': {}, 'f:serviceAccountName': {}, 'f:terminationGracePeriodSeconds': {}, 'f:tolerations': {}, 'f:volumes': {'.': {}, 'k:{"name":"kube-api-access"}': {'.': {}, 'f:name': {}, 'f:projected': {'.': {}, 'f:defaultMode': {}, 'f:sources': {}}}, 'k:{"name":"kubelet-dir"}': {'.': {}, 'f:hostPath': {'.': {}, 'f:path': {}, 'f:type': {}}, 'f:name': {}}, 'k:{"name":"var-lock"}': {'.': {}, 'f:hostPath': {'.': {}, 'f:path': {}, 'f:type': {}}, 'f:name': {}}}}}}, {'manager': 'control-plane-cluster-v6wwh-1', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:03:42Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'.': {}, 'f:k8s.ovn.org/pod-networks': {}}}}, 'subresource': 'status'}, {'manager': 'multus-daemon', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:03:42Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'f:k8s.v1.cni.cncf.io/network-status': {}}}}, 'subresource': 'status'}, {'manager': 'kubelet', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:08:27Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:status': {'f:conditions': {'.': {}, 'k:{"type":"ContainersReady"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:reason': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"Initialized"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"PodReadyToStartContainers"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"PodScheduled"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"Ready"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:reason': {}, 'f:status': {}, 'f:type': {}}}, 'f:containerStatuses': {}, 'f:hostIP': {}, 'f:hostIPs': {}, 'f:phase': {}, 'f:startTime': {}}}, 'subresource': 'status'}]}, 'spec': {'volumes': [{'name': 'kubelet-dir', 'hostPath': {'path': '/etc/kubernetes/', 'type': ''}}, {'name': 'var-lock', 'hostPath': {'path': '/var/lock', 'type': ''}}, {'name': 'kube-api-access', 'projected': {'sources': [{'serviceAccountToken': {'expirationSeconds': 3600, 'path': 'token'}}, {'configMap': {'name': 'kube-root-ca.crt', 'items': [{'key': 'ca.crt', 'path': 'ca.crt'}]}}, {'downwardAPI': {'items': [{'path': 'namespace', 'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'metadata.namespace'}}]}}], 'defaultMode': 420}}], 'containers': [{'name': 'installer', 'image': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:60804b439ca12c2828f4cc859493b3d6779476886c47c853aa1c378916fbe973', 'command': ['cluster-kube-controller-manager-operator', 'installer'], 'args': ['-v=2', '--revision=3', '--namespace=openshift-kube-controller-manager', '--pod=kube-controller-manager-pod', '--resource-dir=/etc/kubernetes/static-pod-resources', '--pod-manifest-dir=/etc/kubernetes/manifests', '--configmaps=kube-controller-manager-pod', '--configmaps=config', '--configmaps=cluster-policy-controller-config', '--configmaps=controller-manager-kubeconfig', '--optional-configmaps=cloud-config', '--configmaps=kube-controller-cert-syncer-kubeconfig', '--configmaps=serviceaccount-ca', '--configmaps=service-ca', '--configmaps=recycler-config', '--secrets=service-account-private-key', '--optional-secrets=serving-cert', '--secrets=localhost-recovery-client-token', '--cert-dir=/etc/kubernetes/static-pod-resources/kube-controller-manager-certs', '--cert-configmaps=aggregator-client-ca', '--cert-configmaps=client-ca', '--optional-cert-configmaps=trusted-ca-bundle', '--cert-secrets=kube-controller-manager-client-cert-key', '--cert-secrets=csr-signer'], 'env': [{'name': 'POD_NAME', 'valueFrom': {'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'metadata.name'}}}, {'name': 'NODE_NAME', 'valueFrom': {'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'spec.nodeName'}}}], 'resources': {'limits': {'cpu': '150m', 'memory': '200M'}, 'requests': {'cpu': '150m', 'memory': '200M'}}, 'volumeMounts': [{'name': 'kubelet-dir', 'mountPath': '/etc/kubernetes/'}, {'name': 'kube-api-access', 'readOnly': True, 'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount'}, {'name': 'var-lock', 'mountPath': '/var/lock'}], 'terminationMessagePath': '/dev/termination-log', 'terminationMessagePolicy': 'FallbackToLogsOnError', 'imagePullPolicy': 'IfNotPresent', 'securityContext': {'privileged': True, 'runAsUser': 0}}], 'restartPolicy': 'Never', 'terminationGracePeriodSeconds': 30, 'dnsPolicy': 'ClusterFirst', 'serviceAccountName': 'installer-sa', 'serviceAccount': 'installer-sa', 'automountServiceAccountToken': False, 'nodeName': 'control-plane-cluster-v6wwh-1', 'securityContext': {'runAsUser': 0}, 'schedulerName': 'default-scheduler', 'tolerations': [{'operator': 'Exists'}], 'priorityClassName': 'system-node-critical', 'priority': 2000001000, 'enableServiceLinks': True, 'preemptionPolicy': 'PreemptLowerPriority'}, 'status': {'phase': 'Failed', 'conditions': [{'type': 'PodReadyToStartContainers', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:06:36Z'}, {'type': 'Initialized', 'status': 'True', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:03:42Z'}, {'type': 'Ready', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:06:35Z', 'reason': 'PodFailed'}, {'type': 'ContainersReady', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:06:35Z', 'reason': 'PodFailed'}, {'type': 'PodScheduled', 'status': 'True', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:03:42Z'}], 'hostIP': '10.10.10.10', 'hostIPs': [{'ip': '10.10.10.10'}], 'startTime': '2025-08-04T13:03:42Z', 'containerStatuses': [{'name': 'installer', 'state': {'terminated': {'exitCode': 1, 'reason': 'Error', 'message': 'ts",\\n Timeout: (time.Duration) 2m0s,\\n StaticPodManifestsLockFile: (string) "",\\n PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\\n KubeletVersion: (string) ""\\n})\\nI0804 13:03:43.257167       1 cmd.go:413] Getting controller reference for node control-plane-cluster-v6wwh-1\\nI0804 13:03:43.349480       1 cmd.go:426] Waiting for installer revisions to settle for node control-plane-cluster-v6wwh-1\\nI0804 13:03:43.349568       1 envvar.go:172] "Feature gate default state" feature="WatchListClient" enabled=false\\nI0804 13:03:43.349586       1 envvar.go:172] "Feature gate default state" feature="InformerResourceVersion" enabled=false\\nI0804 13:03:43.358496       1 cmd.go:506] Pod container: installer state for node control-plane-cluster-v6wwh-1 is not terminated, waiting\\nW0804 13:04:07.362311       1 cmd.go:470] Error getting installer pods on current node control-plane-cluster-v6wwh-1: Get "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\\nW0804 13:04:27.362778       1 cmd.go:470] Error getting installer pods on current node control-plane-cluster-v6wwh-1: Get "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": context deadline exceeded\\nW0804 13:04:47.362391       1 cmd.go:470] Error getting installer pods on current node control-plane-cluster-v6wwh-1: Get "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\\nW0804 13:05:01.363844       1 cmd.go:470] Error getting installer pods on current node control-plane-cluster-v6wwh-1: Get "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\\nF0804 13:05:01.363887       1 cmd.go:109] timed out waiting for the condition\\n', 'startedAt': '2025-08-04T13:03:42Z', 'finishedAt': '2025-08-04T13:05:01Z', 'containerID': 'cri-o://c6605d6a92b0037f2657ce7a6b4d28ebc4711473a27d1e8daa0202e3137d1f84'}}, 'lastState': {}, 'ready': False, 'restartCount': 0, 'image': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:60804b439ca12c2828f4cc859493b3d6779476886c47c853aa1c378916fbe973', 'imageID': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:60804b439ca12c2828f4cc859493b3d6779476886c47c853aa1c378916fbe973', 'containerID': 'cri-o://c6605d6a92b0037f2657ce7a6b4d28ebc4711473a27d1e8daa0202e3137d1f84', 'started': False, 'volumeMounts': [{'name': 'kubelet-dir', 'mountPath': '/etc/kubernetes/'}, {'name': 'kube-api-access', 'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount', 'readOnly': True, 'recursiveReadOnly': 'Disabled'}, {'name': 'var-lock', 'mountPath': '/var/lock'}]}], 'qosClass': 'Guaranteed'}, 'apiVersion': 'v1', 'kind': 'Pod'})
changed: [bastion] => (item={'metadata': {'name': 'installer-5-control-plane-cluster-v6wwh-1', 'namespace': 'openshift-kube-controller-manager', 'uid': 'db245124-9f94-482e-907c-af3bc55989c2', 'resourceVersion': '16154', 'creationTimestamp': '2025-08-04T13:14:20Z', 'labels': {'app': 'installer'}, 'annotations': {'k8s.ovn.org/pod-networks': '{"default":{"ip_addresses":["10.132.0.82/23"],"mac_address":"0a:58:0a:84:00:52","gateway_ips":["10.132.0.1"],"routes":[{"dest":"10.132.0.0/14","nextHop":"10.132.0.1"},{"dest":"172.31.0.0/16","nextHop":"10.132.0.1"},{"dest":"169.254.0.5/32","nextHop":"10.132.0.1"},{"dest":"100.64.0.0/16","nextHop":"10.132.0.1"}],"ip_address":"10.132.0.82/23","gateway_ip":"10.132.0.1","role":"primary"}}', 'k8s.v1.cni.cncf.io/network-status': '[{\\n    "name": "ovn-kubernetes",\\n    "interface": "eth0",\\n    "ips": [\\n        "10.132.0.82"\\n    ],\\n    "mac": "0a:58:0a:84:00:52",\\n    "default": true,\\n    "dns": {}\\n}]'}, 'ownerReferences': [{'apiVersion': 'v1', 'kind': 'ConfigMap', 'name': 'revision-status-5', 'uid': 'e76e2c04-078a-4ff2-bca0-8fe7cd60b78f'}], 'managedFields': [{'manager': 'cluster-kube-controller-manager-operator', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:14:20Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:labels': {'.': {}, 'f:app': {}}, 'f:ownerReferences': {'.': {}, 'k:{"uid":"e76e2c04-078a-4ff2-bca0-8fe7cd60b78f"}': {}}}, 'f:spec': {'f:automountServiceAccountToken': {}, 'f:containers': {'k:{"name":"installer"}': {'.': {}, 'f:args': {}, 'f:command': {}, 'f:env': {'.': {}, 'k:{"name":"NODE_NAME"}': {'.': {}, 'f:name': {}, 'f:valueFrom': {'.': {}, 'f:fieldRef': {}}}, 'k:{"name":"POD_NAME"}': {'.': {}, 'f:name': {}, 'f:valueFrom': {'.': {}, 'f:fieldRef': {}}}}, 'f:image': {}, 'f:imagePullPolicy': {}, 'f:name': {}, 'f:resources': {'.': {}, 'f:limits': {'.': {}, 'f:cpu': {}, 'f:memory': {}}, 'f:requests': {'.': {}, 'f:cpu': {}, 'f:memory': {}}}, 'f:securityContext': {'.': {}, 'f:privileged': {}, 'f:runAsUser': {}}, 'f:terminationMessagePath': {}, 'f:terminationMessagePolicy': {}, 'f:volumeMounts': {'.': {}, 'k:{"mountPath":"/etc/kubernetes/"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}}, 'k:{"mountPath":"/var/lock"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}}, 'k:{"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}, 'f:readOnly': {}}}}}, 'f:dnsPolicy': {}, 'f:enableServiceLinks': {}, 'f:nodeName': {}, 'f:priorityClassName': {}, 'f:restartPolicy': {}, 'f:schedulerName': {}, 'f:securityContext': {'.': {}, 'f:runAsUser': {}}, 'f:serviceAccount': {}, 'f:serviceAccountName': {}, 'f:terminationGracePeriodSeconds': {}, 'f:tolerations': {}, 'f:volumes': {'.': {}, 'k:{"name":"kube-api-access"}': {'.': {}, 'f:name': {}, 'f:projected': {'.': {}, 'f:defaultMode': {}, 'f:sources': {}}}, 'k:{"name":"kubelet-dir"}': {'.': {}, 'f:hostPath': {'.': {}, 'f:path': {}, 'f:type': {}}, 'f:name': {}}, 'k:{"name":"var-lock"}': {'.': {}, 'f:hostPath': {'.': {}, 'f:path': {}, 'f:type': {}}, 'f:name': {}}}}}}, {'manager': 'control-plane-cluster-v6wwh-1', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:14:20Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'.': {}, 'f:k8s.ovn.org/pod-networks': {}}}}, 'subresource': 'status'}, {'manager': 'multus-daemon', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:14:20Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'f:k8s.v1.cni.cncf.io/network-status': {}}}}, 'subresource': 'status'}, {'manager': 'kubelet', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:15:27Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:status': {'f:conditions': {'.': {}, 'k:{"type":"ContainersReady"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:reason': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"Initialized"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"PodReadyToStartContainers"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"PodScheduled"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"Ready"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:reason': {}, 'f:status': {}, 'f:type': {}}}, 'f:containerStatuses': {}, 'f:hostIP': {}, 'f:hostIPs': {}, 'f:phase': {}, 'f:podIP': {}, 'f:podIPs': {'.': {}, 'k:{"ip":"10.132.0.82"}': {'.': {}, 'f:ip': {}}}, 'f:startTime': {}}}, 'subresource': 'status'}]}, 'spec': {'volumes': [{'name': 'kubelet-dir', 'hostPath': {'path': '/etc/kubernetes/', 'type': ''}}, {'name': 'var-lock', 'hostPath': {'path': '/var/lock', 'type': ''}}, {'name': 'kube-api-access', 'projected': {'sources': [{'serviceAccountToken': {'expirationSeconds': 3600, 'path': 'token'}}, {'configMap': {'name': 'kube-root-ca.crt', 'items': [{'key': 'ca.crt', 'path': 'ca.crt'}]}}, {'downwardAPI': {'items': [{'path': 'namespace', 'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'metadata.namespace'}}]}}], 'defaultMode': 420}}], 'containers': [{'name': 'installer', 'image': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:60804b439ca12c2828f4cc859493b3d6779476886c47c853aa1c378916fbe973', 'command': ['cluster-kube-controller-manager-operator', 'installer'], 'args': ['-v=2', '--revision=5', '--namespace=openshift-kube-controller-manager', '--pod=kube-controller-manager-pod', '--resource-dir=/etc/kubernetes/static-pod-resources', '--pod-manifest-dir=/etc/kubernetes/manifests', '--configmaps=kube-controller-manager-pod', '--configmaps=config', '--configmaps=cluster-policy-controller-config', '--configmaps=controller-manager-kubeconfig', '--optional-configmaps=cloud-config', '--configmaps=kube-controller-cert-syncer-kubeconfig', '--configmaps=serviceaccount-ca', '--configmaps=service-ca', '--configmaps=recycler-config', '--secrets=service-account-private-key', '--optional-secrets=serving-cert', '--secrets=localhost-recovery-client-token', '--cert-dir=/etc/kubernetes/static-pod-resources/kube-controller-manager-certs', '--cert-configmaps=aggregator-client-ca', '--cert-configmaps=client-ca', '--optional-cert-configmaps=trusted-ca-bundle', '--cert-secrets=kube-controller-manager-client-cert-key', '--cert-secrets=csr-signer'], 'env': [{'name': 'POD_NAME', 'valueFrom': {'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'metadata.name'}}}, {'name': 'NODE_NAME', 'valueFrom': {'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'spec.nodeName'}}}], 'resources': {'limits': {'cpu': '150m', 'memory': '200M'}, 'requests': {'cpu': '150m', 'memory': '200M'}}, 'volumeMounts': [{'name': 'kubelet-dir', 'mountPath': '/etc/kubernetes/'}, {'name': 'kube-api-access', 'readOnly': True, 'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount'}, {'name': 'var-lock', 'mountPath': '/var/lock'}], 'terminationMessagePath': '/dev/termination-log', 'terminationMessagePolicy': 'FallbackToLogsOnError', 'imagePullPolicy': 'IfNotPresent', 'securityContext': {'privileged': True, 'runAsUser': 0}}], 'restartPolicy': 'Never', 'terminationGracePeriodSeconds': 30, 'dnsPolicy': 'ClusterFirst', 'serviceAccountName': 'installer-sa', 'serviceAccount': 'installer-sa', 'automountServiceAccountToken': False, 'nodeName': 'control-plane-cluster-v6wwh-1', 'securityContext': {'runAsUser': 0}, 'schedulerName': 'default-scheduler', 'tolerations': [{'operator': 'Exists'}], 'priorityClassName': 'system-node-critical', 'priority': 2000001000, 'enableServiceLinks': True, 'preemptionPolicy': 'PreemptLowerPriority'}, 'status': {'phase': 'Failed', 'conditions': [{'type': 'PodReadyToStartContainers', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:15:16Z'}, {'type': 'Initialized', 'status': 'True', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:14:20Z'}, {'type': 'Ready', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:15:12Z', 'reason': 'PodFailed'}, {'type': 'ContainersReady', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:15:12Z', 'reason': 'PodFailed'}, {'type': 'PodScheduled', 'status': 'True', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:14:20Z'}], 'hostIP': '10.10.10.10', 'hostIPs': [{'ip': '10.10.10.10'}], 'podIP': '10.132.0.82', 'podIPs': [{'ip': '10.132.0.82'}], 'startTime': '2025-08-04T13:14:20Z', 'containerStatuses': [{'name': 'installer', 'state': {'terminated': {'exitCode': 1, 'reason': 'Error', 'message': 'ud-config"\\n },\\n CertSecretNames: ([]string) (len=2 cap=2) {\\n  (string) (len=39) "kube-controller-manager-client-cert-key",\\n  (string) (len=10) "csr-signer"\\n },\\n OptionalCertSecretNamePrefixes: ([]string) <nil>,\\n CertConfigMapNamePrefixes: ([]string) (len=2 cap=2) {\\n  (string) (len=20) "aggregator-client-ca",\\n  (string) (len=9) "client-ca"\\n },\\n OptionalCertConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\\n  (string) (len=17) "trusted-ca-bundle"\\n },\\n CertDir: (string) (len=66) "/etc/kubernetes/static-pod-resources/kube-controller-manager-certs",\\n ResourceDir: (string) (len=36) "/etc/kubernetes/static-pod-resources",\\n PodManifestDir: (string) (len=25) "/etc/kubernetes/manifests",\\n Timeout: (time.Duration) 2m0s,\\n StaticPodManifestsLockFile: (string) "",\\n PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\\n KubeletVersion: (string) ""\\n})\\nI0804 13:14:21.851073       1 cmd.go:413] Getting controller reference for node control-plane-cluster-v6wwh-1\\nI0804 13:14:21.861844       1 cmd.go:426] Waiting for installer revisions to settle for node control-plane-cluster-v6wwh-1\\nI0804 13:14:21.861943       1 envvar.go:172] "Feature gate default state" feature="WatchListClient" enabled=false\\nI0804 13:14:21.861961       1 envvar.go:172] "Feature gate default state" feature="InformerResourceVersion" enabled=false\\nI0804 13:14:21.864756       1 cmd.go:506] Pod container: installer state for node control-plane-cluster-v6wwh-1 is not terminated, waiting\\nI0804 13:14:31.868517       1 cmd.go:506] Pod container: installer state for node control-plane-cluster-v6wwh-1 is not terminated, waiting\\nI0804 13:14:41.868846       1 cmd.go:518] Waiting additional period after revisions have settled for node control-plane-cluster-v6wwh-1\\nI0804 13:15:11.869276       1 cmd.go:524] Getting installer pods for node control-plane-cluster-v6wwh-1\\nF0804 13:15:11.870411       1 cmd.go:109] Get "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.31.0.1:443: connect: connection refused\\n', 'startedAt': '2025-08-04T13:14:21Z', 'finishedAt': '2025-08-04T13:15:11Z', 'containerID': 'cri-o://d5b0908e0e16db6999da559ab0f42e335254c8679a9980af6b1bf11a696f3bf4'}}, 'lastState': {}, 'ready': False, 'restartCount': 0, 'image': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:60804b439ca12c2828f4cc859493b3d6779476886c47c853aa1c378916fbe973', 'imageID': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:60804b439ca12c2828f4cc859493b3d6779476886c47c853aa1c378916fbe973', 'containerID': 'cri-o://d5b0908e0e16db6999da559ab0f42e335254c8679a9980af6b1bf11a696f3bf4', 'started': False, 'volumeMounts': [{'name': 'kubelet-dir', 'mountPath': '/etc/kubernetes/'}, {'name': 'kube-api-access', 'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount', 'readOnly': True, 'recursiveReadOnly': 'Disabled'}, {'name': 'var-lock', 'mountPath': '/var/lock'}]}], 'qosClass': 'Guaranteed'}, 'apiVersion': 'v1', 'kind': 'Pod'})
changed: [bastion] => (item={'metadata': {'name': 'installer-4-control-plane-cluster-v6wwh-1', 'namespace': 'openshift-kube-scheduler', 'uid': 'f3f67a6e-dd8a-4c5f-85e1-8125f91ec99d', 'resourceVersion': '12650', 'creationTimestamp': '2025-08-04T13:03:45Z', 'labels': {'app': 'installer'}, 'annotations': {'k8s.ovn.org/pod-networks': '{"default":{"ip_addresses":["10.132.0.40/23"],"mac_address":"0a:58:0a:84:00:28","gateway_ips":["10.132.0.1"],"routes":[{"dest":"10.132.0.0/14","nextHop":"10.132.0.1"},{"dest":"172.31.0.0/16","nextHop":"10.132.0.1"},{"dest":"169.254.0.5/32","nextHop":"10.132.0.1"},{"dest":"100.64.0.0/16","nextHop":"10.132.0.1"}],"ip_address":"10.132.0.40/23","gateway_ip":"10.132.0.1","role":"primary"}}', 'k8s.v1.cni.cncf.io/network-status': '[{\\n    "name": "ovn-kubernetes",\\n    "interface": "eth0",\\n    "ips": [\\n        "10.132.0.40"\\n    ],\\n    "mac": "0a:58:0a:84:00:28",\\n    "default": true,\\n    "dns": {}\\n}]'}, 'ownerReferences': [{'apiVersion': 'v1', 'kind': 'ConfigMap', 'name': 'revision-status-4', 'uid': '7cdcefba-a566-4e15-87bb-fb50c2ab782a'}], 'managedFields': [{'manager': 'cluster-kube-scheduler-operator', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:03:45Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:labels': {'.': {}, 'f:app': {}}, 'f:ownerReferences': {'.': {}, 'k:{"uid":"7cdcefba-a566-4e15-87bb-fb50c2ab782a"}': {}}}, 'f:spec': {'f:automountServiceAccountToken': {}, 'f:containers': {'k:{"name":"installer"}': {'.': {}, 'f:args': {}, 'f:command': {}, 'f:env': {'.': {}, 'k:{"name":"NODE_NAME"}': {'.': {}, 'f:name': {}, 'f:valueFrom': {'.': {}, 'f:fieldRef': {}}}, 'k:{"name":"POD_NAME"}': {'.': {}, 'f:name': {}, 'f:valueFrom': {'.': {}, 'f:fieldRef': {}}}}, 'f:image': {}, 'f:imagePullPolicy': {}, 'f:name': {}, 'f:resources': {'.': {}, 'f:limits': {'.': {}, 'f:cpu': {}, 'f:memory': {}}, 'f:requests': {'.': {}, 'f:cpu': {}, 'f:memory': {}}}, 'f:securityContext': {'.': {}, 'f:privileged': {}, 'f:runAsUser': {}}, 'f:terminationMessagePath': {}, 'f:terminationMessagePolicy': {}, 'f:volumeMounts': {'.': {}, 'k:{"mountPath":"/etc/kubernetes/"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}}, 'k:{"mountPath":"/var/lock"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}}, 'k:{"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}, 'f:readOnly': {}}}}}, 'f:dnsPolicy': {}, 'f:enableServiceLinks': {}, 'f:nodeName': {}, 'f:priorityClassName': {}, 'f:restartPolicy': {}, 'f:schedulerName': {}, 'f:securityContext': {'.': {}, 'f:runAsUser': {}}, 'f:serviceAccount': {}, 'f:serviceAccountName': {}, 'f:terminationGracePeriodSeconds': {}, 'f:tolerations': {}, 'f:volumes': {'.': {}, 'k:{"name":"kube-api-access"}': {'.': {}, 'f:name': {}, 'f:projected': {'.': {}, 'f:defaultMode': {}, 'f:sources': {}}}, 'k:{"name":"kubelet-dir"}': {'.': {}, 'f:hostPath': {'.': {}, 'f:path': {}, 'f:type': {}}, 'f:name': {}}, 'k:{"name":"var-lock"}': {'.': {}, 'f:hostPath': {'.': {}, 'f:path': {}, 'f:type': {}}, 'f:name': {}}}}}}, {'manager': 'control-plane-cluster-v6wwh-1', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:03:45Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'.': {}, 'f:k8s.ovn.org/pod-networks': {}}}}, 'subresource': 'status'}, {'manager': 'multus-daemon', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:03:45Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'f:k8s.v1.cni.cncf.io/network-status': {}}}}, 'subresource': 'status'}, {'manager': 'kubelet', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:08:27Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:status': {'f:conditions': {'.': {}, 'k:{"type":"ContainersReady"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:reason': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"Initialized"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"PodReadyToStartContainers"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"PodScheduled"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"Ready"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:reason': {}, 'f:status': {}, 'f:type': {}}}, 'f:containerStatuses': {}, 'f:hostIP': {}, 'f:hostIPs': {}, 'f:phase': {}, 'f:startTime': {}}}, 'subresource': 'status'}]}, 'spec': {'volumes': [{'name': 'kubelet-dir', 'hostPath': {'path': '/etc/kubernetes/', 'type': ''}}, {'name': 'var-lock', 'hostPath': {'path': '/var/lock', 'type': ''}}, {'name': 'kube-api-access', 'projected': {'sources': [{'serviceAccountToken': {'expirationSeconds': 3600, 'path': 'token'}}, {'configMap': {'name': 'kube-root-ca.crt', 'items': [{'key': 'ca.crt', 'path': 'ca.crt'}]}}, {'downwardAPI': {'items': [{'path': 'namespace', 'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'metadata.namespace'}}]}}], 'defaultMode': 420}}], 'containers': [{'name': 'installer', 'image': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f39683c4c87d179198477690033e41294f8fd6ea7bd70d7f111acc47fdf12c0b', 'command': ['cluster-kube-scheduler-operator', 'installer'], 'args': ['-v=2', '--revision=4', '--namespace=openshift-kube-scheduler', '--pod=kube-scheduler-pod', '--resource-dir=/etc/kubernetes/static-pod-resources', '--pod-manifest-dir=/etc/kubernetes/manifests', '--configmaps=kube-scheduler-pod', '--configmaps=config', '--configmaps=serviceaccount-ca', '--optional-configmaps=policy-configmap', '--configmaps=scheduler-kubeconfig', '--configmaps=kube-scheduler-cert-syncer-kubeconfig', '--optional-secrets=serving-cert', '--secrets=localhost-recovery-client-token', '--cert-dir=/etc/kubernetes/static-pod-resources/kube-scheduler-certs', '--cert-secrets=kube-scheduler-client-cert-key'], 'env': [{'name': 'POD_NAME', 'valueFrom': {'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'metadata.name'}}}, {'name': 'NODE_NAME', 'valueFrom': {'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'spec.nodeName'}}}], 'resources': {'limits': {'cpu': '150m', 'memory': '200M'}, 'requests': {'cpu': '150m', 'memory': '200M'}}, 'volumeMounts': [{'name': 'kubelet-dir', 'mountPath': '/etc/kubernetes/'}, {'name': 'kube-api-access', 'readOnly': True, 'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount'}, {'name': 'var-lock', 'mountPath': '/var/lock'}], 'terminationMessagePath': '/dev/termination-log', 'terminationMessagePolicy': 'FallbackToLogsOnError', 'imagePullPolicy': 'IfNotPresent', 'securityContext': {'privileged': True, 'runAsUser': 0}}], 'restartPolicy': 'Never', 'terminationGracePeriodSeconds': 30, 'dnsPolicy': 'ClusterFirst', 'serviceAccountName': 'installer-sa', 'serviceAccount': 'installer-sa', 'automountServiceAccountToken': False, 'nodeName': 'control-plane-cluster-v6wwh-1', 'securityContext': {'runAsUser': 0}, 'schedulerName': 'default-scheduler', 'tolerations': [{'operator': 'Exists'}], 'priorityClassName': 'system-node-critical', 'priority': 2000001000, 'enableServiceLinks': True, 'preemptionPolicy': 'PreemptLowerPriority'}, 'status': {'phase': 'Failed', 'conditions': [{'type': 'PodReadyToStartContainers', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:06:36Z'}, {'type': 'Initialized', 'status': 'True', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:03:45Z'}, {'type': 'Ready', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:06:35Z', 'reason': 'PodFailed'}, {'type': 'ContainersReady', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:06:35Z', 'reason': 'PodFailed'}, {'type': 'PodScheduled', 'status': 'True', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:03:45Z'}], 'hostIP': '10.10.10.10', 'hostIPs': [{'ip': '10.10.10.10'}], 'startTime': '2025-08-04T13:03:45Z', 'containerStatuses': [{'name': 'installer', 'state': {'terminated': {'exitCode': 1, 'reason': 'Error', 'message': ' (time.Duration) 2m0s,\\n StaticPodManifestsLockFile: (string) "",\\n PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\\n KubeletVersion: (string) ""\\n})\\nI0804 13:03:46.748830       1 cmd.go:413] Getting controller reference for node control-plane-cluster-v6wwh-1\\nI0804 13:03:46.759039       1 cmd.go:426] Waiting for installer revisions to settle for node control-plane-cluster-v6wwh-1\\nI0804 13:03:46.759102       1 envvar.go:172] "Feature gate default state" feature="InformerResourceVersion" enabled=false\\nI0804 13:03:46.759113       1 envvar.go:172] "Feature gate default state" feature="WatchListClient" enabled=false\\nI0804 13:03:46.762198       1 cmd.go:506] Pod container: installer state for node control-plane-cluster-v6wwh-1 is not terminated, waiting\\nW0804 13:04:10.766531       1 cmd.go:470] Error getting installer pods on current node control-plane-cluster-v6wwh-1: Get "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\\nW0804 13:04:30.767050       1 cmd.go:470] Error getting installer pods on current node control-plane-cluster-v6wwh-1: Get "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\\nW0804 13:04:50.766939       1 cmd.go:470] Error getting installer pods on current node control-plane-cluster-v6wwh-1: Get "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\\nW0804 13:05:04.769944       1 cmd.go:470] Error getting installer pods on current node control-plane-cluster-v6wwh-1: Get "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\\nF0804 13:05:04.770013       1 cmd.go:109] timed out waiting for the condition\\n', 'startedAt': '2025-08-04T13:03:46Z', 'finishedAt': '2025-08-04T13:05:04Z', 'containerID': 'cri-o://5e6956eda727dd14af9ba2114ab3ab6aaa4cf553ba121bc7d8ba593552758ca6'}}, 'lastState': {}, 'ready': False, 'restartCount': 0, 'image': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f39683c4c87d179198477690033e41294f8fd6ea7bd70d7f111acc47fdf12c0b', 'imageID': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f39683c4c87d179198477690033e41294f8fd6ea7bd70d7f111acc47fdf12c0b', 'containerID': 'cri-o://5e6956eda727dd14af9ba2114ab3ab6aaa4cf553ba121bc7d8ba593552758ca6', 'started': False, 'volumeMounts': [{'name': 'kubelet-dir', 'mountPath': '/etc/kubernetes/'}, {'name': 'kube-api-access', 'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount', 'readOnly': True, 'recursiveReadOnly': 'Disabled'}, {'name': 'var-lock', 'mountPath': '/var/lock'}]}], 'qosClass': 'Guaranteed'}, 'apiVersion': 'v1', 'kind': 'Pod'})
changed: [bastion] => (item={'metadata': {'name': 'installer-5-control-plane-cluster-v6wwh-1', 'namespace': 'openshift-kube-scheduler', 'uid': 'f505a9bc-a48b-4de9-8659-95a86ad7f4b8', 'resourceVersion': '16151', 'creationTimestamp': '2025-08-04T13:14:36Z', 'labels': {'app': 'installer'}, 'annotations': {'k8s.ovn.org/pod-networks': '{"default":{"ip_addresses":["10.132.0.84/23"],"mac_address":"0a:58:0a:84:00:54","gateway_ips":["10.132.0.1"],"routes":[{"dest":"10.132.0.0/14","nextHop":"10.132.0.1"},{"dest":"172.31.0.0/16","nextHop":"10.132.0.1"},{"dest":"169.254.0.5/32","nextHop":"10.132.0.1"},{"dest":"100.64.0.0/16","nextHop":"10.132.0.1"}],"ip_address":"10.132.0.84/23","gateway_ip":"10.132.0.1","role":"primary"}}', 'k8s.v1.cni.cncf.io/network-status': '[{\\n    "name": "ovn-kubernetes",\\n    "interface": "eth0",\\n    "ips": [\\n        "10.132.0.84"\\n    ],\\n    "mac": "0a:58:0a:84:00:54",\\n    "default": true,\\n    "dns": {}\\n}]'}, 'ownerReferences': [{'apiVersion': 'v1', 'kind': 'ConfigMap', 'name': 'revision-status-5', 'uid': '8f0fd67a-8c7c-499c-bdc3-47e263f54744'}], 'managedFields': [{'manager': 'cluster-kube-scheduler-operator', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:14:36Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:labels': {'.': {}, 'f:app': {}}, 'f:ownerReferences': {'.': {}, 'k:{"uid":"8f0fd67a-8c7c-499c-bdc3-47e263f54744"}': {}}}, 'f:spec': {'f:automountServiceAccountToken': {}, 'f:containers': {'k:{"name":"installer"}': {'.': {}, 'f:args': {}, 'f:command': {}, 'f:env': {'.': {}, 'k:{"name":"NODE_NAME"}': {'.': {}, 'f:name': {}, 'f:valueFrom': {'.': {}, 'f:fieldRef': {}}}, 'k:{"name":"POD_NAME"}': {'.': {}, 'f:name': {}, 'f:valueFrom': {'.': {}, 'f:fieldRef': {}}}}, 'f:image': {}, 'f:imagePullPolicy': {}, 'f:name': {}, 'f:resources': {'.': {}, 'f:limits': {'.': {}, 'f:cpu': {}, 'f:memory': {}}, 'f:requests': {'.': {}, 'f:cpu': {}, 'f:memory': {}}}, 'f:securityContext': {'.': {}, 'f:privileged': {}, 'f:runAsUser': {}}, 'f:terminationMessagePath': {}, 'f:terminationMessagePolicy': {}, 'f:volumeMounts': {'.': {}, 'k:{"mountPath":"/etc/kubernetes/"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}}, 'k:{"mountPath":"/var/lock"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}}, 'k:{"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}': {'.': {}, 'f:mountPath': {}, 'f:name': {}, 'f:readOnly': {}}}}}, 'f:dnsPolicy': {}, 'f:enableServiceLinks': {}, 'f:nodeName': {}, 'f:priorityClassName': {}, 'f:restartPolicy': {}, 'f:schedulerName': {}, 'f:securityContext': {'.': {}, 'f:runAsUser': {}}, 'f:serviceAccount': {}, 'f:serviceAccountName': {}, 'f:terminationGracePeriodSeconds': {}, 'f:tolerations': {}, 'f:volumes': {'.': {}, 'k:{"name":"kube-api-access"}': {'.': {}, 'f:name': {}, 'f:projected': {'.': {}, 'f:defaultMode': {}, 'f:sources': {}}}, 'k:{"name":"kubelet-dir"}': {'.': {}, 'f:hostPath': {'.': {}, 'f:path': {}, 'f:type': {}}, 'f:name': {}}, 'k:{"name":"var-lock"}': {'.': {}, 'f:hostPath': {'.': {}, 'f:path': {}, 'f:type': {}}, 'f:name': {}}}}}}, {'manager': 'control-plane-cluster-v6wwh-1', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:14:36Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'.': {}, 'f:k8s.ovn.org/pod-networks': {}}}}, 'subresource': 'status'}, {'manager': 'multus-daemon', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:14:37Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:annotations': {'f:k8s.v1.cni.cncf.io/network-status': {}}}}, 'subresource': 'status'}, {'manager': 'kubelet', 'operation': 'Update', 'apiVersion': 'v1', 'time': '2025-08-04T13:15:27Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:status': {'f:conditions': {'.': {}, 'k:{"type":"ContainersReady"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:reason': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"Initialized"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"PodReadyToStartContainers"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"PodScheduled"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:status': {}, 'f:type': {}}, 'k:{"type":"Ready"}': {'.': {}, 'f:lastProbeTime': {}, 'f:lastTransitionTime': {}, 'f:reason': {}, 'f:status': {}, 'f:type': {}}}, 'f:containerStatuses': {}, 'f:hostIP': {}, 'f:hostIPs': {}, 'f:phase': {}, 'f:podIP': {}, 'f:podIPs': {'.': {}, 'k:{"ip":"10.132.0.84"}': {'.': {}, 'f:ip': {}}}, 'f:startTime': {}}}, 'subresource': 'status'}]}, 'spec': {'volumes': [{'name': 'kubelet-dir', 'hostPath': {'path': '/etc/kubernetes/', 'type': ''}}, {'name': 'var-lock', 'hostPath': {'path': '/var/lock', 'type': ''}}, {'name': 'kube-api-access', 'projected': {'sources': [{'serviceAccountToken': {'expirationSeconds': 3600, 'path': 'token'}}, {'configMap': {'name': 'kube-root-ca.crt', 'items': [{'key': 'ca.crt', 'path': 'ca.crt'}]}}, {'downwardAPI': {'items': [{'path': 'namespace', 'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'metadata.namespace'}}]}}], 'defaultMode': 420}}], 'containers': [{'name': 'installer', 'image': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f39683c4c87d179198477690033e41294f8fd6ea7bd70d7f111acc47fdf12c0b', 'command': ['cluster-kube-scheduler-operator', 'installer'], 'args': ['-v=2', '--revision=5', '--namespace=openshift-kube-scheduler', '--pod=kube-scheduler-pod', '--resource-dir=/etc/kubernetes/static-pod-resources', '--pod-manifest-dir=/etc/kubernetes/manifests', '--configmaps=kube-scheduler-pod', '--configmaps=config', '--configmaps=serviceaccount-ca', '--optional-configmaps=policy-configmap', '--configmaps=scheduler-kubeconfig', '--configmaps=kube-scheduler-cert-syncer-kubeconfig', '--optional-secrets=serving-cert', '--secrets=localhost-recovery-client-token', '--cert-dir=/etc/kubernetes/static-pod-resources/kube-scheduler-certs', '--cert-secrets=kube-scheduler-client-cert-key'], 'env': [{'name': 'POD_NAME', 'valueFrom': {'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'metadata.name'}}}, {'name': 'NODE_NAME', 'valueFrom': {'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'spec.nodeName'}}}], 'resources': {'limits': {'cpu': '150m', 'memory': '200M'}, 'requests': {'cpu': '150m', 'memory': '200M'}}, 'volumeMounts': [{'name': 'kubelet-dir', 'mountPath': '/etc/kubernetes/'}, {'name': 'kube-api-access', 'readOnly': True, 'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount'}, {'name': 'var-lock', 'mountPath': '/var/lock'}], 'terminationMessagePath': '/dev/termination-log', 'terminationMessagePolicy': 'FallbackToLogsOnError', 'imagePullPolicy': 'IfNotPresent', 'securityContext': {'privileged': True, 'runAsUser': 0}}], 'restartPolicy': 'Never', 'terminationGracePeriodSeconds': 30, 'dnsPolicy': 'ClusterFirst', 'serviceAccountName': 'installer-sa', 'serviceAccount': 'installer-sa', 'automountServiceAccountToken': False, 'nodeName': 'control-plane-cluster-v6wwh-1', 'securityContext': {'runAsUser': 0}, 'schedulerName': 'default-scheduler', 'tolerations': [{'operator': 'Exists'}], 'priorityClassName': 'system-node-critical', 'priority': 2000001000, 'enableServiceLinks': True, 'preemptionPolicy': 'PreemptLowerPriority'}, 'status': {'phase': 'Failed', 'conditions': [{'type': 'PodReadyToStartContainers', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:15:16Z'}, {'type': 'Initialized', 'status': 'True', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:14:36Z'}, {'type': 'Ready', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:15:09Z', 'reason': 'PodFailed'}, {'type': 'ContainersReady', 'status': 'False', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:15:09Z', 'reason': 'PodFailed'}, {'type': 'PodScheduled', 'status': 'True', 'lastProbeTime': None, 'lastTransitionTime': '2025-08-04T13:14:36Z'}], 'hostIP': '10.10.10.10', 'hostIPs': [{'ip': '10.10.10.10'}], 'podIP': '10.132.0.84', 'podIPs': [{'ip': '10.132.0.84'}], 'startTime': '2025-08-04T13:14:36Z', 'containerStatuses': [{'name': 'installer', 'state': {'terminated': {'exitCode': 1, 'reason': 'Error', 'message': 'recovery-client-token"\\n },\\n OptionalSecretNamePrefixes: ([]string) (len=1 cap=1) {\\n  (string) (len=12) "serving-cert"\\n },\\n ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\\n  (string) (len=18) "kube-scheduler-pod",\\n  (string) (len=6) "config",\\n  (string) (len=17) "serviceaccount-ca",\\n  (string) (len=20) "scheduler-kubeconfig",\\n  (string) (len=37) "kube-scheduler-cert-syncer-kubeconfig"\\n },\\n OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\\n  (string) (len=16) "policy-configmap"\\n },\\n CertSecretNames: ([]string) (len=1 cap=1) {\\n  (string) (len=30) "kube-scheduler-client-cert-key"\\n },\\n OptionalCertSecretNamePrefixes: ([]string) <nil>,\\n CertConfigMapNamePrefixes: ([]string) <nil>,\\n OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\\n CertDir: (string) (len=57) "/etc/kubernetes/static-pod-resources/kube-scheduler-certs",\\n ResourceDir: (string) (len=36) "/etc/kubernetes/static-pod-resources",\\n PodManifestDir: (string) (len=25) "/etc/kubernetes/manifests",\\n Timeout: (time.Duration) 2m0s,\\n StaticPodManifestsLockFile: (string) "",\\n PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\\n KubeletVersion: (string) ""\\n})\\nI0804 13:14:38.057066       1 cmd.go:413] Getting controller reference for node control-plane-cluster-v6wwh-1\\nI0804 13:14:38.066922       1 cmd.go:426] Waiting for installer revisions to settle for node control-plane-cluster-v6wwh-1\\nI0804 13:14:38.066983       1 envvar.go:172] "Feature gate default state" feature="WatchListClient" enabled=false\\nI0804 13:14:38.066996       1 envvar.go:172] "Feature gate default state" feature="InformerResourceVersion" enabled=false\\nI0804 13:14:38.148733       1 cmd.go:518] Waiting additional period after revisions have settled for node control-plane-cluster-v6wwh-1\\nI0804 13:15:08.149357       1 cmd.go:524] Getting installer pods for node control-plane-cluster-v6wwh-1\\nF0804 13:15:08.152332       1 cmd.go:109] Get "https://172.31.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.31.0.1:443: connect: connection refused\\n', 'startedAt': '2025-08-04T13:14:37Z', 'finishedAt': '2025-08-04T13:15:08Z', 'containerID': 'cri-o://503e7af47dd49228311adfe5dc1778d3de7a1ce6bc78fd7a15eb46d350efe09c'}}, 'lastState': {}, 'ready': False, 'restartCount': 0, 'image': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f39683c4c87d179198477690033e41294f8fd6ea7bd70d7f111acc47fdf12c0b', 'imageID': 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f39683c4c87d179198477690033e41294f8fd6ea7bd70d7f111acc47fdf12c0b', 'containerID': 'cri-o://503e7af47dd49228311adfe5dc1778d3de7a1ce6bc78fd7a15eb46d350efe09c', 'started': False, 'volumeMounts': [{'name': 'kubelet-dir', 'mountPath': '/etc/kubernetes/'}, {'name': 'kube-api-access', 'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount', 'readOnly': True, 'recursiveReadOnly': 'Disabled'}, {'name': 'var-lock', 'mountPath': '/var/lock'}]}], 'qosClass': 'Guaranteed'}, 'apiVersion': 'v1', 'kind': 'Pod'})

TASK [host-ocp4-assisted-installer : Get kubeadmin password] *******************
Monday 04 August 2025  13:22:08 +0000 (0:00:07.066)       0:47:44.112 ********* 
ok: [bastion]

TASK [host-ocp4-assisted-installer : Set user data for kubeadmin password] *****
Monday 04 August 2025  13:22:09 +0000 (0:00:01.062)       0:47:45.174 ********* 
ok: [bastion] => {
    "changed": false,
    "data": {
        "openshift_kubeadmin_password": "[REDACTED_Secret Keyword_SECRET]"
    }
}

TASK [host-ocp4-assisted-installer : Get console route] ************************
Monday 04 August 2025  13:22:09 +0000 (0:00:00.025)       0:47:45.200 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Get Webconsole URL] ***********************
Monday 04 August 2025  13:22:10 +0000 (0:00:01.073)       0:47:46.273 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Get API URL] ******************************
Monday 04 August 2025  13:22:11 +0000 (0:00:01.035)       0:47:47.308 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Get OpenShift Ingress Domain] *************
Monday 04 August 2025  13:22:12 +0000 (0:00:01.034)       0:47:48.343 ********* 
changed: [bastion]

TASK [host-ocp4-assisted-installer : Set facts for OpenShift console and API] ***
Monday 04 August 2025  13:22:13 +0000 (0:00:01.079)       0:47:49.422 ********* 
ok: [bastion]

TASK [host-ocp4-assisted-installer : Set user data for OpenShift access] *******
Monday 04 August 2025  13:22:13 +0000 (0:00:00.020)       0:47:49.442 ********* 
ok: [bastion] => {
    "changed": false,
    "data": {
        "openshift_api_url": "https://api.cluster-v6wwh.dynamic.redhatworkshops.io:6443",
        "openshift_client_download_url": "http://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable-4.18/openshift-client-linux.tar.gz",
        "openshift_cluster_ingress_domain": "apps.cluster-v6wwh.dynamic.redhatworkshops.io",
        "openshift_console_url": "https://console-openshift-console.apps.cluster-v6wwh.dynamic.redhatworkshops.io"
    }
}

TASK [host-ocp4-assisted-installer : Show user messages for OpenShift access] ***
Monday 04 August 2025  13:22:13 +0000 (0:00:00.023)       0:47:49.466 ********* 
ok: [bastion] => {
    "changed": false,
    "msg": "user.info: OpenShift Console: https://console-openshift-console.apps.cluster-v6wwh.dynamic.redhatworkshops.io\\nOpenShift API for command line 'oc' client: https://api.cluster-v6wwh.dynamic.redhatworkshops.io:6443\\nDownload oc client from http://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable-4.18/openshift-client-linux.tar.gz"
}

PLAY [Step 005 - Post software] ************************************************

TASK [Print post software] *****************************************************
Monday 04 August 2025  13:22:13 +0000 (0:00:00.026)       0:47:49.492 ********* 
ok: [bastion] => {
    "msg": "Post-Software Steps starting"
}

TASK [Set Ansible Python interpreter to k8s virtualenv] ************************
Monday 04 August 2025  13:22:13 +0000 (0:00:00.016)       0:47:49.508 ********* 
ok: [bastion]

TASK [Setup cluster-admin service account] *************************************
Monday 04 August 2025  13:22:13 +0000 (0:00:00.014)       0:47:49.523 ********* 
skipping: [bastion]

TASK [Remove AWS Credentials from bastion] *************************************
Monday 04 August 2025  13:22:13 +0000 (0:00:00.012)       0:47:49.536 ********* 
skipping: [bastion]

TASK [Remove Azure Credentials directory from bastion] *************************
Monday 04 August 2025  13:22:13 +0000 (0:00:00.011)       0:47:49.547 ********* 
skipping: [bastion]

TASK [Remove the openshift-installer GCP Credentials directory from bastion] ***
Monday 04 August 2025  13:22:13 +0000 (0:00:00.012)       0:47:49.559 ********* 
skipping: [bastion]

TASK [Remove gcloud CLI Credentials directory from bastion] ********************
Monday 04 August 2025  13:22:13 +0000 (0:00:00.013)       0:47:49.573 ********* 
skipping: [bastion]

PLAY [Install workloads] *******************************************************

TASK [Set Ansible Python interpreter to k8s virtualenv] ************************
Monday 04 August 2025  13:22:13 +0000 (0:00:00.076)       0:47:49.649 ********* 
ok: [bastion]

TASK [Install infra workloads] *************************************************
Monday 04 August 2025  13:22:13 +0000 (0:00:00.018)       0:47:49.667 ********* 
included: ocp4_workload_authentication for bastion => (item=ocp4_workload_authentication)
included: ocp4_workload_cert_manager for bastion => (item=ocp4_workload_cert_manager)
included: ocp4_workload_external_odf for bastion => (item=ocp4_workload_external_odf)
included: ocp4_workload_openshift_gitops for bastion => (item=ocp4_workload_openshift_gitops)

TASK [ocp4_workload_authentication : Running Pre Workload Tasks] ***************
Monday 04 August 2025  13:22:13 +0000 (0:00:00.061)       0:47:49.729 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_authentication/tasks/./pre_workload.yml for bastion

TASK [ocp4_workload_authentication : pre_workload tasks complete] **************
Monday 04 August 2025  13:22:13 +0000 (0:00:00.020)       0:47:49.750 ********* 
ok: [bastion] => {
    "msg": "Pre-Workload tasks completed successfully."
}

TASK [ocp4_workload_authentication : Running Workload Tasks] *******************
Monday 04 August 2025  13:22:13 +0000 (0:00:00.018)       0:47:49.769 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_authentication/tasks/./workload.yml for bastion

TASK [ocp4_workload_authentication : Check that ocp4_workload_authentication_idm_type is defined and valid] ***
Monday 04 August 2025  13:22:13 +0000 (0:00:00.028)       0:47:49.798 ********* 
ok: [bastion] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [ocp4_workload_authentication : Retrieve OpenShift Ingress] ***************
Monday 04 August 2025  13:22:14 +0000 (0:00:00.024)       0:47:49.822 ********* 
ok: [bastion]

TASK [ocp4_workload_authentication : Retrieve API server configuration (for API endpoint)] ***
Monday 04 August 2025  13:22:15 +0000 (0:00:01.420)       0:47:51.243 ********* 
ok: [bastion]

TASK [ocp4_workload_authentication : Save OpenShift access facts] **************
Monday 04 August 2025  13:22:16 +0000 (0:00:01.376)       0:47:52.620 ********* 
ok: [bastion]

TASK [ocp4_workload_authentication : Setup htpasswd authentication] ************
Monday 04 August 2025  13:22:16 +0000 (0:00:00.025)       0:47:52.645 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_authentication/tasks/setup_htpasswd.yml for bastion

TASK [ocp4_workload_authentication : Generate cluster admin password] **********
Monday 04 August 2025  13:22:16 +0000 (0:00:00.036)       0:47:52.682 ********* 
skipping: [bastion]

TASK [ocp4_workload_authentication : Use provided admin password] **************
Monday 04 August 2025  13:22:16 +0000 (0:00:00.021)       0:47:52.703 ********* 
ok: [bastion]

TASK [ocp4_workload_authentication : Set up randomized user password array] ****
Monday 04 August 2025  13:22:16 +0000 (0:00:00.025)       0:47:52.728 ********* 
skipping: [bastion] => (item=0) 
skipping: [bastion]

TASK [ocp4_workload_authentication : Generate common user password] ************
Monday 04 August 2025  13:22:16 +0000 (0:00:00.020)       0:47:52.749 ********* 
ok: [bastion]

TASK [ocp4_workload_authentication : Use provided user password] ***************
Monday 04 August 2025  13:22:16 +0000 (0:00:00.024)       0:47:52.773 ********* 
skipping: [bastion]

TASK [ocp4_workload_authentication : Generate user passwords array for common password] ***
Monday 04 August 2025  13:22:16 +0000 (0:00:00.018)       0:47:52.792 ********* 
ok: [bastion] => (item=0)

TASK [ocp4_workload_authentication : Create temporary htpasswd file] ***********
Monday 04 August 2025  13:22:16 +0000 (0:00:00.024)       0:47:52.816 ********* 
changed: [bastion]

TASK [ocp4_workload_authentication : Add admin user to htpasswd file] **********
Monday 04 August 2025  13:22:17 +0000 (0:00:00.955)       0:47:53.772 ********* 
changed: [bastion]

TASK [ocp4_workload_authentication : Add users and passwords to htpasswd file] ***
Monday 04 August 2025  13:22:18 +0000 (0:00:01.043)       0:47:54.816 ********* 
changed: [bastion] => (item=0)

TASK [ocp4_workload_authentication : Read contents of htpasswd file] ***********
Monday 04 August 2025  13:22:19 +0000 (0:00:00.978)       0:47:55.794 ********* 
ok: [bastion]

TASK [ocp4_workload_authentication : Remove generated htpasswd file] ***********
Monday 04 August 2025  13:22:20 +0000 (0:00:00.923)       0:47:56.717 ********* 
changed: [bastion]

TASK [ocp4_workload_authentication : Ensure htpasswd Secret is absent] *********
Monday 04 August 2025  13:22:21 +0000 (0:00:00.946)       0:47:57.664 ********* 
ok: [bastion]

TASK [ocp4_workload_authentication : Create htpasswd Secret] *******************
Monday 04 August 2025  13:22:23 +0000 (0:00:01.343)       0:47:59.007 ********* 
changed: [bastion]

TASK [ocp4_workload_authentication : Update OAuth configuration] ***************
Monday 04 August 2025  13:22:24 +0000 (0:00:01.408)       0:48:00.416 ********* 
[WARNING]: unknown field "spec.identityProviders[0].challenge"
[WARNING]: unknown field "spec.identityProviders[0].login"
changed: [bastion]

TASK [ocp4_workload_authentication : Print common user information messages] ***
Monday 04 August 2025  13:22:26 +0000 (0:00:01.401)       0:48:01.817 ********* 
ok: [bastion] => {
    "changed": false,
    "msg": "user.info: Authentication via htpasswd is enabled on this cluster.\\n\\nUser `admin` with password `OTgwOTkx` is cluster admin."
}

TASK [ocp4_workload_authentication : Print user information for common password] ***
Monday 04 August 2025  13:22:26 +0000 (0:00:00.024)       0:48:01.841 ********* 
ok: [bastion] => {
    "changed": false,
    "msg": "user.info: Normal user `user1` created with password `DJ0jnoeJFdzLvNhQ`"
}

TASK [ocp4_workload_authentication : Print user information for randomized password] ***
Monday 04 August 2025  13:22:26 +0000 (0:00:00.027)       0:48:01.868 ********* 
skipping: [bastion] => (item=0) 
skipping: [bastion]

TASK [ocp4_workload_authentication : Save common user and cluster admin information] ***
Monday 04 August 2025  13:22:26 +0000 (0:00:00.031)       0:48:01.900 ********* 
ok: [bastion] => {
    "changed": false,
    "data": {
        "openshift_api_server_url": "https://api.cluster-v6wwh.dynamic.redhatworkshops.io:6443",
        "openshift_cluster_admin_password": "[REDACTED_Secret Keyword_SECRET]",
        "openshift_cluster_admin_username": "admin",
        "openshift_cluster_console_url": "https://console-openshift-console.apps.cluster-v6wwh.dynamic.redhatworkshops.io",
        "openshift_cluster_num_users": 1,
        "openshift_cluster_user_base": "user",
        "openshift_cluster_user_count": 1
    }
}

TASK [ocp4_workload_authentication : Save user name for single user configuration] ***
Monday 04 August 2025  13:22:26 +0000 (0:00:00.036)       0:48:01.937 ********* 
ok: [bastion] => {
    "changed": false,
    "data": {
        "openshift_cluster_user_name": "user1"
    }
}

TASK [ocp4_workload_authentication : Save common user password if not randomized] ***
Monday 04 August 2025  13:22:26 +0000 (0:00:00.033)       0:48:01.970 ********* 
ok: [bastion] => {
    "changed": false,
    "data": {
        "openshift_cluster_user_password": "[REDACTED_Secret Keyword_SECRET]"
    }
}

TASK [ocp4_workload_authentication : Save user information for user access] ****
Monday 04 August 2025  13:22:26 +0000 (0:00:00.036)       0:48:02.007 ********* 
ok: [bastion] => (item=0) => {
    "ansible_loop_var": "n",
    "changed": false,
    "data": {
        "console_url": "https://console-openshift-console.apps.cluster-v6wwh.dynamic.redhatworkshops.io",
        "login_command": "oc login --insecure-skip-tls-verify=false -u user1  https://api.cluster-v6wwh.dynamic.redhatworkshops.io:6443",
        "openshift_cluster_ingress_domain": "apps.cluster-v6wwh.dynamic.redhatworkshops.io",
        "openshift_console_url": "https://console-openshift-console.apps.cluster-v6wwh.dynamic.redhatworkshops.io",
        "password": "[REDACTED_Secret Keyword_SECRET]",
        "user": "user1"
    },
    "n": 0,
    "user": "user1"
}

TASK [ocp4_workload_authentication : Setup LDAP authentication] ****************
Monday 04 August 2025  13:22:26 +0000 (0:00:00.036)       0:48:02.043 ********* 
skipping: [bastion]

TASK [ocp4_workload_authentication : Set up cluster admin users] ***************
Monday 04 August 2025  13:22:26 +0000 (0:00:00.014)       0:48:02.057 ********* 
changed: [bastion]

TASK [ocp4_workload_authentication : Remove kubeadmin user] ********************
Monday 04 August 2025  13:22:27 +0000 (0:00:01.448)       0:48:03.506 ********* 
changed: [bastion]

TASK [ocp4_workload_authentication : workload tasks complete] ******************
Monday 04 August 2025  13:22:29 +0000 (0:00:01.383)       0:48:04.890 ********* 
ok: [bastion] => {
    "msg": "Workload Tasks completed successfully."
}

TASK [ocp4_workload_authentication : Running Post Workload Tasks] **************
Monday 04 August 2025  13:22:29 +0000 (0:00:00.020)       0:48:04.910 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_authentication/tasks/./post_workload.yml for bastion

TASK [ocp4_workload_authentication : post_workload tasks complete] *************
Monday 04 August 2025  13:22:29 +0000 (0:00:00.022)       0:48:04.933 ********* 
ok: [bastion] => {
    "msg": "Post-Workload Tasks completed successfully."
}

TASK [ocp4_workload_authentication : Running Workload removal Tasks] ***********
Monday 04 August 2025  13:22:29 +0000 (0:00:00.018)       0:48:04.951 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Running Pre Workload Tasks] *****************
Monday 04 August 2025  13:22:29 +0000 (0:00:00.019)       0:48:04.970 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_cert_manager/tasks/./pre_workload.yml for bastion

TASK [ocp4_workload_cert_manager : Pre_workload tasks complete] ****************
Monday 04 August 2025  13:22:29 +0000 (0:00:00.020)       0:48:04.991 ********* 
ok: [bastion] => {
    "msg": "Pre-Workload tasks completed successfully."
}

TASK [ocp4_workload_cert_manager : Running Workload Tasks] *********************
Monday 04 August 2025  13:22:29 +0000 (0:00:00.020)       0:48:05.011 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_cert_manager/tasks/./workload.yml for bastion

TASK [ocp4_workload_cert_manager : Setting up workload for user] ***************
Monday 04 August 2025  13:22:29 +0000 (0:00:00.034)       0:48:05.046 ********* 
ok: [bastion] => {
    "msg": "Setting up workload for user ocp_username = system:admin"
}

TASK [Install Red Hat Cert Manager operator] ***********************************
Monday 04 August 2025  13:22:29 +0000 (0:00:00.018)       0:48:05.064 ********* 
included: install_operator for bastion

TASK [install_operator : openshift-cert-manager-operator - Install the operator] ***
Monday 04 August 2025  13:22:29 +0000 (0:00:00.029)       0:48:05.094 ********* 
included: /runner/project/ansible/roles/install_operator/tasks/install.yml for bastion

TASK [install_operator : Check that operator name has been provided] ***********
Monday 04 August 2025  13:22:29 +0000 (0:00:00.037)       0:48:05.131 ********* 
ok: [bastion] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [install_operator : Ensure Namespace exists (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:29 +0000 (0:00:00.032)       0:48:05.164 ********* 
changed: [bastion]

TASK [install_operator : Ensure OperatorGroup exists (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:30 +0000 (0:00:01.452)       0:48:06.616 ********* 
changed: [bastion]

TASK [install_operator : Create CatalogSource for use with catalog snapshot (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:32 +0000 (0:00:01.416)       0:48:08.033 ********* 
skipping: [bastion]

TASK [install_operator : Set subscription channel to provided channel (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:32 +0000 (0:00:00.020)       0:48:08.053 ********* 
ok: [bastion]

TASK [install_operator : Get cluster version] **********************************
Monday 04 August 2025  13:22:32 +0000 (0:00:00.024)       0:48:08.078 ********* 
skipping: [bastion]

TASK [install_operator : Get PackageManifest for the operator (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:32 +0000 (0:00:00.020)       0:48:08.098 ********* 
skipping: [bastion]

TASK [install_operator : Set operator channel (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:32 +0000 (0:00:00.018)       0:48:08.116 ********* 
skipping: [bastion]

TASK [install_operator : Print operator channel to be installed (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:32 +0000 (0:00:00.019)       0:48:08.136 ********* 
ok: [bastion] => {
    "msg": "Operator channel to be installed: stable-v1.15"
}

TASK [install_operator : Create operator subscription (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:32 +0000 (0:00:00.026)       0:48:08.163 ********* 
changed: [bastion]

TASK [install_operator : Wait until InstallPlan is created (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:33 +0000 (0:00:01.436)       0:48:09.599 ********* 
FAILED - RETRYING: [bastion]: Wait until InstallPlan is created (openshift-cert-manager-operator) (100 retries left).
ok: [bastion]

TASK [install_operator : Set InstallPlan name (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:46 +0000 (0:00:12.754)       0:48:22.353 ********* 
ok: [bastion]

TASK [install_operator : Print InstallPlan (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:46 +0000 (0:00:00.034)       0:48:22.388 ********* 
ok: [bastion] => {
    "msg": "InstallPlan: install-2snqb"
}

TASK [install_operator : Get InstallPlan (openshift-cert-manager-operator)] ****
Monday 04 August 2025  13:22:46 +0000 (0:00:00.018)       0:48:22.407 ********* 
ok: [bastion]

TASK [install_operator : Approve InstallPlan if necessary (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:47 +0000 (0:00:01.368)       0:48:23.775 ********* 
skipping: [bastion]

TASK [install_operator : Get Installed CSV (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:47 +0000 (0:00:00.020)       0:48:23.795 ********* 
ok: [bastion]

TASK [install_operator : Print CSV version to be installed (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:49 +0000 (0:00:01.342)       0:48:25.138 ********* 
ok: [bastion] => {
    "msg": "Starting CSV: "
}

TASK [install_operator : Wait until CSV is installed (openshift-cert-manager-operator)] ***
Monday 04 August 2025  13:22:49 +0000 (0:00:00.024)       0:48:25.163 ********* 
FAILED - RETRYING: [bastion]: Wait until CSV is installed (openshift-cert-manager-operator) (10 retries left).
ok: [bastion]

TASK [install_operator : openshift-cert-manager-operator - Remove the operator] ***
Monday 04 August 2025  13:23:22 +0000 (0:00:32.789)       0:48:57.952 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Update CertManager for EC2/GCP/Azure to use external DNS] ***
Monday 04 August 2025  13:23:22 +0000 (0:00:00.019)       0:48:57.971 ********* 
changed: [bastion]

TASK [ocp4_workload_cert_manager : Determine API server URL] *******************
Monday 04 August 2025  13:23:23 +0000 (0:00:01.436)       0:48:59.407 ********* 
ok: [bastion]

TASK [ocp4_workload_cert_manager : Determine cluster wildcard domain] **********
Monday 04 August 2025  13:23:24 +0000 (0:00:01.362)       0:49:00.770 ********* 
ok: [bastion]

TASK [ocp4_workload_cert_manager : Set DNS facts] ******************************
Monday 04 August 2025  13:23:26 +0000 (0:00:01.388)       0:49:02.158 ********* 
ok: [bastion]

TASK [ocp4_workload_cert_manager : Print API and wildcard domain] **************
Monday 04 August 2025  13:23:26 +0000 (0:00:00.019)       0:49:02.178 ********* 
ok: [bastion] => {
    "msg": "API: api.cluster-v6wwh.dynamic.redhatworkshops.io, Wildcard Domain: *.apps.cluster-v6wwh.dynamic.redhatworkshops.io"
}

TASK [ocp4_workload_cert_manager : Wait until CertManager is ready] ************
Monday 04 August 2025  13:23:26 +0000 (0:00:00.018)       0:49:02.196 ********* 
ok: [bastion]

TASK [ocp4_workload_cert_manager : Create ZeroSSL credentials secret for cert manager] ***
Monday 04 August 2025  13:23:27 +0000 (0:00:01.395)       0:49:03.592 ********* 
changed: [bastion]

TASK [ocp4_workload_cert_manager : Set up cloud provider specific prerequisites for cert manager] ***
Monday 04 August 2025  13:23:29 +0000 (0:00:01.430)       0:49:05.022 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_cert_manager/tasks/cert_manager_ec2.yml for bastion

TASK [ocp4_workload_cert_manager : Use provided HostedZoneID] ******************
Monday 04 August 2025  13:23:29 +0000 (0:00:00.030)       0:49:05.053 ********* 
ok: [bastion]

TASK [ocp4_workload_cert_manager : Get HostedZoneID] ***************************
Monday 04 August 2025  13:23:29 +0000 (0:00:00.041)       0:49:05.095 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Set HostedZoneID fact] **********************
Monday 04 August 2025  13:23:29 +0000 (0:00:00.027)       0:49:05.123 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Print HostedZoneID] *************************
Monday 04 August 2025  13:23:29 +0000 (0:00:00.029)       0:49:05.152 ********* 
ok: [bastion] => {
    "msg": "HostedZoneID: Z009829317DQYBBJZ02ZU"
}

TASK [ocp4_workload_cert_manager : Create AWS credentials secret for cert manager] ***
Monday 04 August 2025  13:23:29 +0000 (0:00:00.019)       0:49:05.171 ********* 
changed: [bastion]

TASK [ocp4_workload_cert_manager : Set up ClusterIssuer and request certificates] ***
Monday 04 August 2025  13:23:30 +0000 (0:00:01.417)       0:49:06.589 ********* 
changed: [bastion] => (item=clusterissuer.yaml.j2)
changed: [bastion] => (item=certificate-ingress.yaml.j2)
changed: [bastion] => (item=certificate-api.yaml.j2)

TASK [ocp4_workload_cert_manager : Set Up ClusterIssuer fallback if defined] ***
Monday 04 August 2025  13:23:35 +0000 (0:00:04.344)       0:49:10.933 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Run ingress controller certificate check task] ***
Monday 04 August 2025  13:23:35 +0000 (0:00:00.015)       0:49:10.948 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_cert_manager/tasks/cert_manager_ingress_cert_check.yml for bastion => (item=0)
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_cert_manager/tasks/cert_manager_ingress_cert_check.yml for bastion => (item=1)
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_cert_manager/tasks/cert_manager_ingress_cert_check.yml for bastion => (item=2)
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_cert_manager/tasks/cert_manager_ingress_cert_check.yml for bastion => (item=3)

TASK [ocp4_workload_cert_manager : Wait until Ingress Certificate is ready] ****
Monday 04 August 2025  13:23:35 +0000 (0:00:00.059)       0:49:11.008 ********* 
ok: [bastion]

TASK [ocp4_workload_cert_manager : Mark cert ready] ****************************
Monday 04 August 2025  13:30:07 +0000 (0:06:32.150)       0:55:43.158 ********* 
ok: [bastion]

TASK [ocp4_workload_cert_manager : Wait until Ingress Certificate is ready] ****
Monday 04 August 2025  13:30:07 +0000 (0:00:00.022)       0:55:43.180 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Mark cert ready] ****************************
Monday 04 August 2025  13:30:07 +0000 (0:00:00.016)       0:55:43.197 ********* 
ok: [bastion]

TASK [ocp4_workload_cert_manager : Wait until Ingress Certificate is ready] ****
Monday 04 August 2025  13:30:07 +0000 (0:00:00.020)       0:55:43.218 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Mark cert ready] ****************************
Monday 04 August 2025  13:30:07 +0000 (0:00:00.016)       0:55:43.234 ********* 
ok: [bastion]

TASK [ocp4_workload_cert_manager : Wait until Ingress Certificate is ready] ****
Monday 04 August 2025  13:30:07 +0000 (0:00:00.023)       0:55:43.258 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Mark cert ready] ****************************
Monday 04 August 2025  13:30:07 +0000 (0:00:00.020)       0:55:43.279 ********* 
ok: [bastion]

TASK [ocp4_workload_cert_manager : Update Ingress controller to use certificate] ***
Monday 04 August 2025  13:30:07 +0000 (0:00:00.022)       0:55:43.302 ********* 
changed: [bastion]

TASK [ocp4_workload_cert_manager : Run API certificate check task] *************
Monday 04 August 2025  13:30:09 +0000 (0:00:01.535)       0:55:44.837 ********* 
skipping: [bastion] => (item=0) 
skipping: [bastion] => (item=1) 
skipping: [bastion] => (item=2) 
skipping: [bastion] => (item=3) 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Update API server to use certificate] *******
Monday 04 August 2025  13:30:09 +0000 (0:00:00.028)       0:55:44.865 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Wait for Cluster Operator kube-apiserver to finish rolling out] ***
Monday 04 August 2025  13:30:09 +0000 (0:00:00.016)       0:55:44.881 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Find all Kube Configs] **********************
Monday 04 August 2025  13:30:09 +0000 (0:00:00.017)       0:55:44.899 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Fix Kube Configs] ***************************
Monday 04 August 2025  13:30:09 +0000 (0:00:00.021)       0:55:44.921 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Make sure API calls succeed] ****************
Monday 04 August 2025  13:30:09 +0000 (0:00:00.018)       0:55:44.939 ********* 
skipping: [bastion]

TASK [ocp4_workload_cert_manager : Workload tasks complete] ********************
Monday 04 August 2025  13:30:09 +0000 (0:00:00.017)       0:55:44.956 ********* 
ok: [bastion] => {
    "msg": "Workload Tasks completed successfully."
}

TASK [ocp4_workload_cert_manager : Running Post Workload Tasks] ****************
Monday 04 August 2025  13:30:09 +0000 (0:00:00.021)       0:55:44.977 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_cert_manager/tasks/./post_workload.yml for bastion

TASK [ocp4_workload_cert_manager : Post_workload tasks complete] ***************
Monday 04 August 2025  13:30:09 +0000 (0:00:00.028)       0:55:45.006 ********* 
ok: [bastion] => {
    "msg": "Post-Workload Tasks completed successfully."
}

TASK [ocp4_workload_cert_manager : Running Workload removal Tasks] *************
Monday 04 August 2025  13:30:09 +0000 (0:00:00.019)       0:55:45.025 ********* 
skipping: [bastion]

TASK [ocp4_workload_external_odf : Running workload provision tasks] ***********
Monday 04 August 2025  13:30:09 +0000 (0:00:00.016)       0:55:45.041 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_external_odf/tasks/workload.yml for bastion

TASK [ocp4_workload_external_odf : Set up ODF operator namespace and operator group] ***
Monday 04 August 2025  13:30:09 +0000 (0:00:00.027)       0:55:45.068 ********* 
changed: [bastion] => (item=odf-ns.yaml)
changed: [bastion] => (item=odf-og.yaml)

TASK [ocp4_workload_external_odf : Set up ODF operator subscription] ***********
Monday 04 August 2025  13:30:11 +0000 (0:00:02.732)       0:55:47.801 ********* 
changed: [bastion]

TASK [ocp4_workload_external_odf : Wait for the CRD storagecluster to become available] ***
Monday 04 August 2025  13:30:13 +0000 (0:00:01.458)       0:55:49.259 ********* 
FAILED - RETRYING: [bastion]: Wait for the CRD storagecluster to become available (200 retries left).
FAILED - RETRYING: [bastion]: Wait for the CRD storagecluster to become available (199 retries left).
FAILED - RETRYING: [bastion]: Wait for the CRD storagecluster to become available (198 retries left).
FAILED - RETRYING: [bastion]: Wait for the CRD storagecluster to become available (197 retries left).
FAILED - RETRYING: [bastion]: Wait for the CRD storagecluster to become available (196 retries left).
FAILED - RETRYING: [bastion]: Wait for the CRD storagecluster to become available (195 retries left).
FAILED - RETRYING: [bastion]: Wait for the CRD storagecluster to become available (194 retries left).
ok: [bastion]

TASK [ocp4_workload_external_odf : Set up StorageCluster] **********************
Monday 04 August 2025  13:31:34 +0000 (0:01:21.387)       0:57:10.647 ********* 
changed: [bastion] => (item=secret.yaml.j2)
changed: [bastion] => (item=storagecluster.yaml.j2)
changed: [bastion] => (item=storageclass.yaml.j2)

TASK [ocp4_workload_external_odf : Add a immediate SC if default volume_binding_mode is default value] ***
Monday 04 August 2025  13:31:39 +0000 (0:00:04.274)       0:57:14.921 ********* 
changed: [bastion]

TASK [ocp4_workload_external_odf : Wait for StorageCluster to be available] ****
Monday 04 August 2025  13:31:40 +0000 (0:00:01.401)       0:57:16.323 ********* 
ok: [bastion]

TASK [ocp4_workload_external_odf : Create PVC for image registry] **************
Monday 04 August 2025  13:39:22 +0000 (0:07:42.063)       1:04:58.386 ********* 
changed: [bastion]

TASK [ocp4_workload_external_odf : Configure registry] *************************
Monday 04 August 2025  13:39:24 +0000 (0:00:01.530)       1:04:59.917 ********* 
changed: [bastion]

TASK [ocp4_workload_external_odf : Enable ODF console plugin] ******************
Monday 04 August 2025  13:39:25 +0000 (0:00:01.388)       1:05:01.305 ********* 
changed: [bastion]

TASK [ocp4_workload_external_odf : Wait until BackingStore is available] *******
Monday 04 August 2025  13:39:26 +0000 (0:00:01.428)       1:05:02.733 ********* 
ok: [bastion]

TASK [ocp4_workload_external_odf : Change BackingStore numVolumes in pvPool] ***
Monday 04 August 2025  13:39:28 +0000 (0:00:01.391)       1:05:04.125 ********* 
changed: [bastion]

TASK [ocp4_workload_external_odf : Change default BackingStore resources] ******
Monday 04 August 2025  13:39:29 +0000 (0:00:01.386)       1:05:05.511 ********* 
skipping: [bastion]

TASK [ocp4_workload_external_odf : Running workload removal tasks] *************
Monday 04 August 2025  13:39:29 +0000 (0:00:00.016)       1:05:05.528 ********* 
skipping: [bastion]

TASK [ocp4_workload_openshift_gitops : Running Pre Workload Tasks] *************
Monday 04 August 2025  13:39:29 +0000 (0:00:00.017)       1:05:05.545 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_openshift_gitops/tasks/./pre_workload.yml for bastion

TASK [ocp4_workload_openshift_gitops : Pre_workload tasks complete] ************
Monday 04 August 2025  13:39:29 +0000 (0:00:00.020)       1:05:05.565 ********* 
ok: [bastion] => {
    "msg": "Pre-Workload tasks completed successfully."
}

TASK [ocp4_workload_openshift_gitops : Running Workload Tasks] *****************
Monday 04 August 2025  13:39:29 +0000 (0:00:00.019)       1:05:05.585 ********* 
included: /runner/project/ansible/roles_ocp_workloads/ocp4_workload_openshift_gitops/tasks/./workload.yml for bastion

TASK [ocp4_workload_openshift_gitops : Get IngressController] ******************
Monday 04 August 2025  13:39:29 +0000 (0:00:00.028)       1:05:05.613 ********* 
ok: [bastion]

TASK [ocp4_workload_openshift_gitops : Set _ocp4_workload_openshift_gitops_domain] ***
Monday 04 August 2025  13:39:31 +0000 (0:00:01.382)       1:05:06.996 ********* 
ok: [bastion]

TASK [Install OpenShift GitOps operator] ***************************************
Monday 04 August 2025  13:39:31 +0000 (0:00:00.020)       1:05:07.016 ********* 
included: install_operator for bastion

TASK [install_operator : openshift-gitops-operator - Install the operator] *****
Monday 04 August 2025  13:39:31 +0000 (0:00:00.028)       1:05:07.045 ********* 
included: /runner/project/ansible/roles/install_operator/tasks/install.yml for bastion

TASK [install_operator : Check that operator name has been provided] ***********
Monday 04 August 2025  13:39:31 +0000 (0:00:00.035)       1:05:07.080 ********* 
ok: [bastion] => {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [install_operator : Ensure Namespace exists (openshift-gitops-operator)] ***
Monday 04 August 2025  13:39:31 +0000 (0:00:00.022)       1:05:07.103 ********* 
skipping: [bastion]

TASK [install_operator : Ensure OperatorGroup exists (openshift-gitops-operator)] ***
Monday 04 August 2025  13:39:31 +0000 (0:00:00.024)       1:05:07.127 ********* 
skipping: [bastion]

TASK [install_operator : Create CatalogSource for use with catalog snapshot (openshift-gitops-operator)] ***
Monday 04 August 2025  13:39:31 +0000 (0:00:00.025)       1:05:07.153 ********* 
skipping: [bastion]

TASK [install_operator : Set subscription channel to provided channel (openshift-gitops-operator)] ***
Monday 04 August 2025  13:39:31 +0000 (0:00:00.030)       1:05:07.183 ********* 
ok: [bastion]

TASK [install_operator : Get cluster version] **********************************
Monday 04 August 2025  13:39:31 +0000 (0:00:00.031)       1:05:07.214 ********* 
skipping: [bastion]

TASK [install_operator : Get PackageManifest for the operator (openshift-gitops-operator)] ***
Monday 04 August 2025  13:39:31 +0000 (0:00:00.022)       1:05:07.236 ********* 
skipping: [bastion]

TASK [install_operator : Set operator channel (openshift-gitops-operator)] *****
Monday 04 August 2025  13:39:31 +0000 (0:00:00.019)       1:05:07.256 ********* 
skipping: [bastion]

TASK [install_operator : Print operator channel to be installed (openshift-gitops-operator)] ***
Monday 04 August 2025  13:39:31 +0000 (0:00:00.020)       1:05:07.277 ********* 
ok: [bastion] => {
    "msg": "Operator channel to be installed: gitops-1.15"
}

TASK [install_operator : Create operator subscription (openshift-gitops-operator)] ***
Monday 04 August 2025  13:39:31 +0000 (0:00:00.020)       1:05:07.297 ********* 
changed: [bastion]

TASK [install_operator : Wait until InstallPlan is created (openshift-gitops-operator)] ***
Monday 04 August 2025  13:39:32 +0000 (0:00:01.496)       1:05:08.794 ********* 
FAILED - RETRYING: [bastion]: Wait until InstallPlan is created (openshift-gitops-operator) (100 retries left).
FAILED - RETRYING: [bastion]: Wait until InstallPlan is created (openshift-gitops-operator) (99 retries left).
ok: [bastion]

TASK [install_operator : Set InstallPlan name (openshift-gitops-operator)] *****
Monday 04 August 2025  13:39:57 +0000 (0:00:24.325)       1:05:33.120 ********* 
ok: [bastion]

TASK [install_operator : Print InstallPlan (openshift-gitops-operator)] ********
Monday 04 August 2025  13:39:57 +0000 (0:00:00.036)       1:05:33.157 ********* 
ok: [bastion] => {
    "msg": "InstallPlan: install-f8tb6"
}

TASK [install_operator : Get InstallPlan (openshift-gitops-operator)] **********
Monday 04 August 2025  13:39:57 +0000 (0:00:00.020)       1:05:33.177 ********* 
ok: [bastion]

TASK [install_operator : Approve InstallPlan if necessary (openshift-gitops-operator)] ***
Monday 04 August 2025  13:39:58 +0000 (0:00:01.466)       1:05:34.644 ********* 
skipping: [bastion]

TASK [install_operator : Get Installed CSV (openshift-gitops-operator)] ********
Monday 04 August 2025  13:39:58 +0000 (0:00:00.025)       1:05:34.669 ********* 
ok: [bastion]

TASK [install_operator : Print CSV version to be installed (openshift-gitops-operator)] ***
Monday 04 August 2025  13:40:00 +0000 (0:00:01.423)       1:05:36.093 ********* 
ok: [bastion] => {
    "msg": "Starting CSV: "
}

TASK [install_operator : Wait until CSV is installed (openshift-gitops-operator)] ***
Monday 04 August 2025  13:40:00 +0000 (0:00:00.030)       1:05:36.124 ********* 
FAILED - RETRYING: [bastion]: Wait until CSV is installed (openshift-gitops-operator) (10 retries left).
ok: [bastion]

TASK [install_operator : openshift-gitops-operator - Remove the operator] ******
Monday 04 August 2025  13:40:33 +0000 (0:00:32.898)       1:06:09.022 ********* 
skipping: [bastion]

TASK [ocp4_workload_openshift_gitops : Grant cluster-admin permissions to Gitops Service account] ***
Monday 04 August 2025  13:40:33 +0000 (0:00:00.020)       1:06:09.042 ********* 
fatal: [bastion]: FAILED! => {"changed": false, "msg": "HTTPSConnectionPool(host='api.cluster-v6wwh.dynamic.redhatworkshops.io', port=6443): Max retries exceeded with url: /apis/rbac.authorization.k8s.io/v1 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9334e3f610>: Failed to establish a new connection: [Errno 111] Connection refused'))"}

PLAY RECAP *********************************************************************
bastion                    : ok=237  changed=103  unreachable=0    failed=1    skipped=99   rescued=0    ignored=0   
localhost                  : ok=77   changed=24   unreachable=0    failed=0    skipped=55   rescued=0    ignored=0   

TASKS RECAP ********************************************************************
Monday 04 August 2025  13:40:34 +0000 (0:00:01.362)       1:06:10.406 ********* 
=============================================================================== 
host-ocp4-assisted-installer : Start cluster installation ------------ 1958.01s
ocp4_workload_external_odf : Wait for StorageCluster to be available -- 462.06s
ocp4_workload_cert_manager : Wait until Ingress Certificate is ready -- 392.15s
common : Update all packages ------------------------------------------ 310.52s
host-ocp4-assisted-installer : Wait for the hosts to be ready --------- 129.88s
ocp4_workload_external_odf : Wait for the CRD storagecluster to become available -- 81.39s
common : install common packages for RHEL 9 ---------------------------- 75.65s
host-ocp4-assisted-installer : Wait till VM is running ----------------- 69.95s
host_virtualenv : Install requirements in virtualenv ------------------- 46.72s
common : Reboot all VMs ------------------------------------------------ 32.94s
install_operator : Wait until CSV is installed (openshift-gitops-operator) -- 32.90s
install_operator : Wait until CSV is installed (openshift-cert-manager-operator) -- 32.79s
infra-generic-wait_for_linux_hosts : wait for linux host to be available -- 32.29s
install_operator : Wait until InstallPlan is created (openshift-gitops-operator) -- 24.33s
infra-openshift-cnv-resources : Wait till VM is running ---------------- 22.13s
install_operator : Wait until InstallPlan is created (openshift-cert-manager-operator) -- 12.75s
host-ocp4-assisted-installer : Downloads OpenShift cluster files ------- 11.88s
host_virtualenv : Install virtualenv package prerequisites -------------- 9.96s
host-ocp4-assisted-installer : Delete Error Pods ------------------------ 7.07s
host-ocp4-assisted-installer : Get the OpenShift CLI -------------------- 6.63s
